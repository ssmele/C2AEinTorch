{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from C2AE import C2AE, save_model, load_model, Fe, Fx, Fd, eval_metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import hamming_loss, accuracy_score, f1_score, precision_score, recall_score\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from skmultilearn.dataset import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mediamill:train - exists, not redownloading\n",
      "mediamill:test - exists, not redownloading\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "train_x, train_y, feat_names, label_names = load_dataset('mediamill', 'train')\n",
    "test_x, test_y, _, _ = load_dataset('mediamill', 'test')\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(train_x.todense(), device=device, dtype=torch.float),torch.tensor(train_y.todense(), device=device,dtype=torch.float))\n",
    "test_dataset = TensorDataset(torch.tensor(test_x.todense(), device=device, dtype=torch.float), torch.tensor(test_y.todense(), device=device, dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([30993, 120]),\n",
       " torch.Size([30993, 101]),\n",
       " torch.Size([12914, 120]),\n",
       " torch.Size([12914, 101]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[:][0].shape, train_dataset[:][1].shape, test_dataset[:][0].shape, test_dataset[:][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def micro_r(y_t, y_p):\n",
    "    return recall_score(y_t, y_p, average='micro')\n",
    "def macro_r(y_t, y_p):\n",
    "    return recall_score(y_t, y_p, average='macro')\n",
    "def micro_p(y_t, y_p):\n",
    "    return precision_score(y_t, y_p, average='micro')\n",
    "def macro_p(y_t, y_p):\n",
    "    return precision_score(y_t, y_p, average='macro')\n",
    "def micro_f1(y_t, y_p):\n",
    "    return f1_score(y_t, y_p, average='micro')\n",
    "def macro_f1(y_t, y_p):\n",
    "    return f1_score(y_t, y_p, average='macro')\n",
    "def ham_los(*args, **kwargs):\n",
    "    return hamming_loss(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configs.\n",
    "num_epochs = 1000\n",
    "batch_size = 32\n",
    "lr = 0.001\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# # Scene config\n",
    "feat_dim = 120\n",
    "num_labels = 101\n",
    "latent_dim = 50\n",
    "fx_h_dim=110\n",
    "fe_h_dim=105\n",
    "fd_h_dim=105\n",
    "\n",
    "# Scene models.\n",
    "Fx_tmc = Fx(feat_dim, fx_h_dim, fx_h_dim, latent_dim)\n",
    "Fe_tmc = Fe(num_labels, fe_h_dim, latent_dim)\n",
    "Fd_tmc = Fd(latent_dim, fd_h_dim, num_labels, fin_act=torch.sigmoid)\n",
    "               \n",
    "# Initializing net.\n",
    "net = C2AE(Fx_tmc, Fe_tmc, Fd_tmc, beta=0.01, alpha=40, emb_lambda=0.01, latent_dim=latent_dim, device=device)\n",
    "net = net.to(device)\n",
    "\n",
    "\n",
    "# Doing weight_decay here is eqiv to adding the L2 norm.\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "writer = SummaryWriter(comment='mediamill-4c2ae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training!\n",
      "Epoch: 0, Loss: 9605.383268356323,  L-Loss: 3741.042100429535, C-Loss: 239.19932079315186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stone\\miniconda3\\envs\\torch_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 9789.852140426636,  L-Loss: 2743.5333018302917, C-Loss: 244.06042009592056\n",
      "Epoch: 2, Loss: 10016.533346176147,  L-Loss: 2283.5240881443024, C-Loss: 249.84245246648788\n",
      "Epoch: 3, Loss: 9950.966569900513,  L-Loss: 1715.6772162914276, C-Loss: 248.34524548053741\n",
      "Epoch: 4, Loss: 9896.89337348938,  L-Loss: 1516.278756260872, C-Loss: 247.04326450824738\n",
      "Epoch: 5, Loss: 9978.80080986023,  L-Loss: 1355.9878435134888, C-Loss: 249.131023645401\n",
      "Epoch: 6, Loss: 9980.269666671753,  L-Loss: 1210.139478445053, C-Loss: 249.20420688390732\n",
      "Epoch: 7, Loss: 9951.54649925232,  L-Loss: 1157.1998167037964, C-Loss: 248.49936228990555\n",
      "Epoch: 8, Loss: 10125.19736289978,  L-Loss: 936.8685793876648, C-Loss: 252.8957164287567\n",
      "Epoch: 9, Loss: 9956.332695007324,  L-Loss: 807.5172189474106, C-Loss: 248.70643770694733\n",
      "Epoch: 10, Loss: 9878.29787826538,  L-Loss: 771.1928068399429, C-Loss: 246.76464849710464\n",
      "Epoch: 11, Loss: 10346.298871994019,  L-Loss: 721.2692561149597, C-Loss: 258.47715455293655\n",
      "Epoch: 12, Loss: 10066.217763900757,  L-Loss: 884.6606900691986, C-Loss: 251.4342783689499\n",
      "Epoch: 13, Loss: 10275.40383720398,  L-Loss: 860.2172492742538, C-Loss: 256.67004173994064\n",
      "Epoch: 14, Loss: 10005.337316513062,  L-Loss: 807.2887941598892, C-Loss: 249.93161022663116\n",
      "Epoch: 15, Loss: 9842.476541519165,  L-Loss: 711.744219660759, C-Loss: 245.8839766383171\n",
      "Epoch: 16, Loss: 10015.48861503601,  L-Loss: 627.1678424477577, C-Loss: 250.2304230928421\n",
      "Epoch: 17, Loss: 10168.327587127686,  L-Loss: 552.6023108363152, C-Loss: 254.07004010677338\n",
      "Epoch: 18, Loss: 10002.234104156494,  L-Loss: 558.0140929222107, C-Loss: 249.91634905338287\n",
      "Epoch: 19, Loss: 10224.199438095093,  L-Loss: 609.5049421191216, C-Loss: 255.45261007547379\n",
      "Epoch: 20, Loss: 9933.459945678711,  L-Loss: 540.9270407557487, C-Loss: 248.20126670598984\n",
      "Epoch: 21, Loss: 10069.125839233398,  L-Loss: 507.4190801978111, C-Loss: 251.6012910604477\n",
      "Epoch: 22, Loss: 10101.566925048828,  L-Loss: 475.17115437984467, C-Loss: 252.42038121819496\n",
      "Epoch: 23, Loss: 9870.595054626465,  L-Loss: 486.6104261279106, C-Loss: 246.64322316646576\n",
      "Epoch: 24, Loss: 10200.510601043701,  L-Loss: 552.241898059845, C-Loss: 254.8747044801712\n",
      "Epoch: 25, Loss: 10138.594509124756,  L-Loss: 462.3981346487999, C-Loss: 253.34926295280457\n",
      "Epoch: 26, Loss: 9998.493980407715,  L-Loss: 430.94427794218063, C-Loss: 249.8546143770218\n",
      "Epoch: 27, Loss: 10040.263664245605,  L-Loss: 417.45682352781296, C-Loss: 250.90222734212875\n",
      "Epoch: 28, Loss: 10006.209953308105,  L-Loss: 462.03543615341187, C-Loss: 250.03974080085754\n",
      "Epoch: 29, Loss: 10112.918674468994,  L-Loss: 406.45099329948425, C-Loss: 252.72135436534882\n",
      "Epoch: 30, Loss: 10221.095338821411,  L-Loss: 399.1819518506527, C-Loss: 255.42758756875992\n",
      "Epoch: 31, Loss: 9785.432920455933,  L-Loss: 436.92682349681854, C-Loss: 244.52659133076668\n",
      "Epoch: 32, Loss: 10051.214126586914,  L-Loss: 372.74167439341545, C-Loss: 251.18716794252396\n",
      "Epoch: 33, Loss: 10002.595407485962,  L-Loss: 389.11015951633453, C-Loss: 249.9676078557968\n",
      "Epoch: 34, Loss: 9921.090887069702,  L-Loss: 379.6864598095417, C-Loss: 247.9323506951332\n",
      "Epoch: 35, Loss: 10002.889087677002,  L-Loss: 408.43624198436737, C-Loss: 249.97011768817902\n",
      "Epoch: 36, Loss: 10199.86211013794,  L-Loss: 340.0933529138565, C-Loss: 254.91152954101562\n",
      "Epoch: 37, Loss: 10200.576742172241,  L-Loss: 339.0491496026516, C-Loss: 254.92965632677078\n",
      "Epoch: 38, Loss: 10049.848728179932,  L-Loss: 332.93075731396675, C-Loss: 251.16298431158066\n",
      "Epoch: 39, Loss: 9984.063077926636,  L-Loss: 374.32088243961334, C-Loss: 249.50799742341042\n",
      "Epoch: 40, Loss: 10119.504695892334,  L-Loss: 304.5907429456711, C-Loss: 252.91146969795227\n",
      "Epoch: 41, Loss: 9883.222421646118,  L-Loss: 354.81629341840744, C-Loss: 246.9918560385704\n",
      "Epoch: 42, Loss: 10046.005361557007,  L-Loss: 327.789160490036, C-Loss: 251.06818687915802\n",
      "Epoch: 43, Loss: 10027.617450714111,  L-Loss: 338.47899797558784, C-Loss: 250.6058166027069\n",
      "Epoch: 44, Loss: 9885.472486495972,  L-Loss: 307.9510340690613, C-Loss: 247.05982398986816\n",
      "Epoch: 45, Loss: 10184.162704467773,  L-Loss: 301.22736114263535, C-Loss: 254.52876061201096\n",
      "Epoch: 46, Loss: 10078.667373657227,  L-Loss: 332.67928087711334, C-Loss: 251.88351547718048\n",
      "Epoch: 47, Loss: 10038.145292282104,  L-Loss: 316.3303209543228, C-Loss: 250.8745497763157\n",
      "Epoch: 48, Loss: 10000.703672409058,  L-Loss: 275.441975325346, C-Loss: 249.94873124361038\n",
      "Epoch: 49, Loss: 10112.52515220642,  L-Loss: 265.97488871216774, C-Loss: 252.74663570523262\n",
      "Epoch: 50, Loss: 10050.267719268799,  L-Loss: 323.2368487715721, C-Loss: 251.17588394880295\n",
      "Epoch: 51, Loss: 9962.004665374756,  L-Loss: 310.2733062207699, C-Loss: 248.9725484251976\n",
      "Epoch: 52, Loss: 9942.649673461914,  L-Loss: 311.2355731725693, C-Loss: 248.48843240737915\n",
      "Epoch: 53, Loss: 10094.602975845337,  L-Loss: 281.1150672733784, C-Loss: 252.294795691967\n",
      "Epoch: 54, Loss: 9942.042673110962,  L-Loss: 259.1500325202942, C-Loss: 248.48627823591232\n",
      "Epoch: 55, Loss: 10016.315711975098,  L-Loss: 253.4378150999546, C-Loss: 250.34453397989273\n",
      "Epoch: 56, Loss: 10030.649841308594,  L-Loss: 327.55165246129036, C-Loss: 250.6843580007553\n",
      "Epoch: 57, Loss: 10065.202156066895,  L-Loss: 283.3211631178856, C-Loss: 251.5592239499092\n",
      "Epoch: 58, Loss: 10103.563863754272,  L-Loss: 277.1809606850147, C-Loss: 252.51980143785477\n",
      "Epoch: 59, Loss: 9953.48936843872,  L-Loss: 272.36237478256226, C-Loss: 248.76914358139038\n",
      "Epoch: 60, Loss: 10131.007001876831,  L-Loss: 230.48186865448952, C-Loss: 253.21755394339561\n",
      "Epoch: 61, Loss: 10147.26441192627,  L-Loss: 273.77835753560066, C-Loss: 253.61316552758217\n",
      "Epoch: 62, Loss: 10045.650568008423,  L-Loss: 273.45914855599403, C-Loss: 251.07289934158325\n",
      "Epoch: 63, Loss: 10075.547666549683,  L-Loss: 269.82965183258057, C-Loss: 251.82123392820358\n",
      "Epoch: 64, Loss: 9979.145236968994,  L-Loss: 253.97066865861416, C-Loss: 249.41513818502426\n",
      "Epoch: 65, Loss: 10104.862829208374,  L-Loss: 274.02265110611916, C-Loss: 252.55306524038315\n",
      "Epoch: 66, Loss: 10175.417970657349,  L-Loss: 315.10062086582184, C-Loss: 254.30667448043823\n",
      "Epoch: 67, Loss: 9988.927066802979,  L-Loss: 305.45971524715424, C-Loss: 249.64681160449982\n",
      "Epoch: 68, Loss: 10197.034648895264,  L-Loss: 279.3711395263672, C-Loss: 254.85602337121964\n",
      "Epoch: 69, Loss: 10063.291906356812,  L-Loss: 261.8758129775524, C-Loss: 251.5168288052082\n",
      "Epoch: 70, Loss: 10080.885614395142,  L-Loss: 281.3312880694866, C-Loss: 251.95180732011795\n",
      "Epoch: 71, Loss: 9803.615537643433,  L-Loss: 275.3332470357418, C-Loss: 245.02155548334122\n",
      "Epoch: 72, Loss: 9994.115234375,  L-Loss: 223.90332251787186, C-Loss: 249.79690444469452\n",
      "Epoch: 73, Loss: 10084.924591064453,  L-Loss: 245.50333830714226, C-Loss: 252.06173872947693\n",
      "Epoch: 74, Loss: 10175.557256698608,  L-Loss: 297.5097109079361, C-Loss: 254.31455391645432\n",
      "Epoch: 75, Loss: 9871.68907546997,  L-Loss: 268.96395269036293, C-Loss: 246.72498577833176\n",
      "Epoch: 76, Loss: 10000.187368392944,  L-Loss: 265.30224522948265, C-Loss: 249.9383583664894\n",
      "Epoch: 77, Loss: 9806.857530593872,  L-Loss: 283.0756735801697, C-Loss: 245.10067051649094\n",
      "Epoch: 78, Loss: 10040.840782165527,  L-Loss: 246.26921939849854, C-Loss: 250.95945277810097\n",
      "Epoch: 79, Loss: 9973.415168762207,  L-Loss: 261.18648716807365, C-Loss: 249.270082116127\n",
      "Epoch: 80, Loss: 9948.199617385864,  L-Loss: 227.11119735240936, C-Loss: 248.64821329712868\n",
      "Epoch: 81, Loss: 10085.990056991577,  L-Loss: 260.5749251842499, C-Loss: 252.08460786938667\n",
      "Epoch: 82, Loss: 10004.18565940857,  L-Loss: 231.55368781089783, C-Loss: 250.04675313830376\n",
      "Epoch: 83, Loss: 10109.493026733398,  L-Loss: 243.38051560521126, C-Loss: 252.67648011446\n",
      "Epoch: 84, Loss: 10061.1708278656,  L-Loss: 233.930795699358, C-Loss: 251.4707880616188\n",
      "Epoch: 85, Loss: 9978.722269058228,  L-Loss: 263.1154537498951, C-Loss: 249.40227806568146\n",
      "Epoch: 86, Loss: 10234.816904067993,  L-Loss: 218.09144791960716, C-Loss: 255.81589931249619\n",
      "Epoch: 87, Loss: 10020.252527236938,  L-Loss: 250.5416086614132, C-Loss: 250.44367760419846\n",
      "Epoch: 88, Loss: 10134.101760864258,  L-Loss: 250.801303088665, C-Loss: 253.28984361886978\n",
      "Epoch: 89, Loss: 9874.373224258423,  L-Loss: 248.75811234116554, C-Loss: 246.7971413731575\n",
      "Epoch: 90, Loss: 10052.611982345581,  L-Loss: 238.01610735058784, C-Loss: 251.2557953596115\n",
      "Epoch: 91, Loss: 10197.32656288147,  L-Loss: 241.3155875056982, C-Loss: 254.87283504009247\n",
      "Epoch: 92, Loss: 9941.300270080566,  L-Loss: 245.99217733740807, C-Loss: 248.47100871801376\n",
      "Epoch: 93, Loss: 9873.592693328857,  L-Loss: 252.0315439403057, C-Loss: 246.77680918574333\n",
      "Epoch: 94, Loss: 10027.20587348938,  L-Loss: 222.776550039649, C-Loss: 250.6244530081749\n",
      "Epoch: 95, Loss: 10039.44151687622,  L-Loss: 232.82194957137108, C-Loss: 250.92783254384995\n",
      "Epoch: 96, Loss: 10081.92615890503,  L-Loss: 220.9386458992958, C-Loss: 251.99291902780533\n",
      "Epoch: 97, Loss: 9899.537330627441,  L-Loss: 230.29934149980545, C-Loss: 247.43085825443268\n",
      "Epoch: 98, Loss: 10214.290147781372,  L-Loss: 235.02094492316246, C-Loss: 255.29849761724472\n",
      "Epoch: 99, Loss: 10146.198766708374,  L-Loss: 232.6302436888218, C-Loss: 253.59681230783463\n",
      "Epoch: 100, Loss: 9886.842233657837,  L-Loss: 255.00693693757057, C-Loss: 247.10730409622192\n",
      "Epoch: 101, Loss: 10168.120040893555,  L-Loss: 239.04603171348572, C-Loss: 254.14324009418488\n",
      "Epoch: 102, Loss: 9953.361303329468,  L-Loss: 241.24173140525818, C-Loss: 248.773721575737\n",
      "Epoch: 103, Loss: 10074.754625320435,  L-Loss: 221.42262643575668, C-Loss: 251.81351047754288\n",
      "Epoch: 104, Loss: 9957.746208190918,  L-Loss: 223.40597335994244, C-Loss: 248.88780343532562\n",
      "Epoch: 105, Loss: 9886.67824935913,  L-Loss: 215.08913525938988, C-Loss: 247.11318400502205\n",
      "Epoch: 106, Loss: 10060.86082649231,  L-Loss: 245.78704515099525, C-Loss: 251.46007454395294\n",
      "Epoch: 107, Loss: 9902.15477180481,  L-Loss: 217.94631963968277, C-Loss: 247.4993832707405\n",
      "Epoch: 108, Loss: 10139.80337715149,  L-Loss: 232.10411536693573, C-Loss: 253.4370585680008\n",
      "Epoch: 109, Loss: 9898.342102050781,  L-Loss: 207.64513847231865, C-Loss: 247.4066403210163\n",
      "Epoch: 110, Loss: 10089.51523399353,  L-Loss: 223.40399877727032, C-Loss: 252.1820303797722\n",
      "Epoch: 111, Loss: 10068.236957550049,  L-Loss: 214.61887694895267, C-Loss: 251.65227007865906\n",
      "Epoch: 112, Loss: 9916.351863861084,  L-Loss: 212.62950631976128, C-Loss: 247.85563963651657\n",
      "Epoch: 113, Loss: 10066.19499206543,  L-Loss: 260.64531460404396, C-Loss: 251.589713037014\n",
      "Epoch: 114, Loss: 9979.058332443237,  L-Loss: 238.25104394555092, C-Loss: 249.41689532995224\n",
      "Epoch: 115, Loss: 10119.586071014404,  L-Loss: 213.08332327008247, C-Loss: 252.9363807439804\n",
      "Epoch: 116, Loss: 9829.830717086792,  L-Loss: 242.27713933587074, C-Loss: 245.6851987838745\n",
      "Epoch: 117, Loss: 10048.014678955078,  L-Loss: 255.12695011496544, C-Loss: 251.13658559322357\n",
      "Epoch: 118, Loss: 9783.19716835022,  L-Loss: 248.416748046875, C-Loss: 244.51782488822937\n",
      "Epoch: 119, Loss: 10012.373100280762,  L-Loss: 225.49518010020256, C-Loss: 250.25295466184616\n",
      "Epoch: 120, Loss: 9907.838933944702,  L-Loss: 203.94938132166862, C-Loss: 247.64498591423035\n",
      "Epoch: 121, Loss: 10119.622018814087,  L-Loss: 217.68353766202927, C-Loss: 252.93612933158875\n",
      "Epoch: 122, Loss: 9904.309099197388,  L-Loss: 203.6128311008215, C-Loss: 247.55682364106178\n",
      "Epoch: 123, Loss: 10305.013711929321,  L-Loss: 231.92878639698029, C-Loss: 257.56736010313034\n",
      "Epoch: 124, Loss: 10151.8233127594,  L-Loss: 213.68225812911987, C-Loss: 253.74216276407242\n",
      "Epoch: 125, Loss: 10018.785818099976,  L-Loss: 221.3398560732603, C-Loss: 250.41431099176407\n",
      "Epoch: 126, Loss: 9968.613809585571,  L-Loss: 219.3494090139866, C-Loss: 249.16050779819489\n",
      "Epoch: 127, Loss: 9977.80576133728,  L-Loss: 213.76822610199451, C-Loss: 249.39170238375664\n",
      "Epoch: 128, Loss: 10157.061595916748,  L-Loss: 197.11351391673088, C-Loss: 253.87726163864136\n",
      "Epoch: 129, Loss: 9934.571447372437,  L-Loss: 205.58853590488434, C-Loss: 248.31288886070251\n",
      "Epoch: 130, Loss: 10111.501932144165,  L-Loss: 223.54982042312622, C-Loss: 252.73166072368622\n",
      "Epoch: 131, Loss: 10178.692018508911,  L-Loss: 283.309556633234, C-Loss: 254.39647364616394\n",
      "Epoch: 132, Loss: 9911.795267105103,  L-Loss: 318.6137203872204, C-Loss: 247.71522855758667\n",
      "Epoch: 133, Loss: 10183.100130081177,  L-Loss: 256.74217396974564, C-Loss: 254.5133175253868\n",
      "Epoch: 134, Loss: 10204.05830001831,  L-Loss: 260.96420881152153, C-Loss: 255.03621649742126\n",
      "Epoch: 135, Loss: 10176.71688079834,  L-Loss: 267.4747650027275, C-Loss: 254.3510529100895\n",
      "Epoch: 136, Loss: 10333.573474884033,  L-Loss: 215.14942809939384, C-Loss: 258.2855493426323\n",
      "Epoch: 137, Loss: 10240.29022026062,  L-Loss: 243.10473853349686, C-Loss: 255.9464790225029\n",
      "Epoch: 138, Loss: 10162.146987915039,  L-Loss: 281.0855317413807, C-Loss: 253.9834036231041\n",
      "Epoch: 139, Loss: 9904.703311920166,  L-Loss: 259.3184188604355, C-Loss: 247.55275332927704\n",
      "Epoch: 140, Loss: 9954.471797943115,  L-Loss: 246.87292340397835, C-Loss: 248.80007576942444\n",
      "Epoch: 141, Loss: 10291.211208343506,  L-Loss: 281.83012542128563, C-Loss: 257.20982283353806\n",
      "Epoch: 142, Loss: 10147.445949554443,  L-Loss: 272.0126351714134, C-Loss: 253.61814540624619\n",
      "Epoch: 143, Loss: 10109.390590667725,  L-Loss: 256.3978588283062, C-Loss: 252.67066514492035\n",
      "Epoch: 144, Loss: 10464.585803985596,  L-Loss: 222.74201026558876, C-Loss: 261.5589600801468\n",
      "Epoch: 145, Loss: 10214.668476104736,  L-Loss: 250.61772191524506, C-Loss: 255.30405789613724\n",
      "Epoch: 146, Loss: 9900.400032043457,  L-Loss: 282.47764229774475, C-Loss: 247.4393807053566\n",
      "Epoch: 147, Loss: 10310.37240600586,  L-Loss: 241.9508671760559, C-Loss: 257.6988228559494\n",
      "Epoch: 148, Loss: 10339.993040084839,  L-Loss: 260.55233216285706, C-Loss: 258.4346871972084\n",
      "Epoch: 149, Loss: 10214.242408752441,  L-Loss: 257.0364031493664, C-Loss: 255.2918008863926\n",
      "Epoch: 150, Loss: 10040.988256454468,  L-Loss: 280.77779680490494, C-Loss: 250.95451188087463\n",
      "Epoch: 151, Loss: 10026.876699447632,  L-Loss: 244.22918590903282, C-Loss: 250.61086064577103\n",
      "Epoch: 152, Loss: 10240.683336257935,  L-Loss: 226.064101010561, C-Loss: 255.96056720614433\n",
      "Epoch: 153, Loss: 10180.488786697388,  L-Loss: 244.42190325260162, C-Loss: 254.45111429691315\n",
      "Epoch: 154, Loss: 10181.956150054932,  L-Loss: 249.96593818068504, C-Loss: 254.48641270399094\n",
      "Epoch: 155, Loss: 10415.99630355835,  L-Loss: 235.40734189748764, C-Loss: 260.341056227684\n",
      "Epoch: 156, Loss: 10068.23853302002,  L-Loss: 253.3937550187111, C-Loss: 251.64261475205421\n",
      "Epoch: 157, Loss: 10354.646488189697,  L-Loss: 231.45315870642662, C-Loss: 258.8082990050316\n",
      "Epoch: 158, Loss: 10349.4186668396,  L-Loss: 242.90508863329887, C-Loss: 258.674740254879\n",
      "Epoch: 159, Loss: 9973.830976486206,  L-Loss: 286.4553299844265, C-Loss: 249.27416110038757\n",
      "Epoch: 160, Loss: 10144.704992294312,  L-Loss: 256.1125231385231, C-Loss: 253.55359613895416\n",
      "Epoch: 161, Loss: 10169.917432785034,  L-Loss: 238.66095772385597, C-Loss: 254.18827027082443\n",
      "Epoch: 162, Loss: 10091.022331237793,  L-Loss: 253.31204640865326, C-Loss: 252.21223032474518\n",
      "Epoch: 163, Loss: 10206.446529388428,  L-Loss: 254.2044386267662, C-Loss: 255.0976122021675\n",
      "Epoch: 164, Loss: 10041.210639953613,  L-Loss: 245.48705272376537, C-Loss: 250.96889400482178\n",
      "Epoch: 165, Loss: 10097.223764419556,  L-Loss: 224.57311643660069, C-Loss: 252.3744507431984\n",
      "Epoch: 166, Loss: 9918.880758285522,  L-Loss: 228.1589983701706, C-Loss: 247.9149788916111\n",
      "Epoch: 167, Loss: 10369.082344055176,  L-Loss: 238.6631402671337, C-Loss: 259.1673917770386\n",
      "Epoch: 168, Loss: 9867.901266098022,  L-Loss: 224.21436056494713, C-Loss: 246.6414777636528\n",
      "Epoch: 169, Loss: 10321.16932106018,  L-Loss: 236.20197039842606, C-Loss: 257.97018215060234\n",
      "Epoch: 170, Loss: 10265.37071800232,  L-Loss: 223.65796214342117, C-Loss: 256.57835364341736\n",
      "Epoch: 171, Loss: 10060.726877212524,  L-Loss: 232.9311294555664, C-Loss: 251.45993840694427\n",
      "Epoch: 172, Loss: 9977.754802703857,  L-Loss: 243.78952953219414, C-Loss: 249.3829224705696\n",
      "Epoch: 173, Loss: 10122.555995941162,  L-Loss: 239.46680560708046, C-Loss: 253.00403353571892\n",
      "Epoch: 174, Loss: 10084.067111968994,  L-Loss: 245.29259115457535, C-Loss: 252.04035460948944\n",
      "Epoch: 175, Loss: 10186.275253295898,  L-Loss: 233.4566075503826, C-Loss: 254.59851709008217\n",
      "Epoch: 176, Loss: 10037.571863174438,  L-Loss: 214.01298621296883, C-Loss: 250.88579285144806\n",
      "Epoch: 177, Loss: 10090.33271598816,  L-Loss: 221.67032554745674, C-Loss: 252.20290005207062\n",
      "Epoch: 178, Loss: 9924.542123794556,  L-Loss: 250.9723604619503, C-Loss: 248.05081003904343\n",
      "Epoch: 179, Loss: 9913.352487564087,  L-Loss: 252.59549155831337, C-Loss: 247.77066272497177\n",
      "Epoch: 180, Loss: 10218.01276397705,  L-Loss: 221.4012297987938, C-Loss: 255.39496886730194\n",
      "Epoch: 181, Loss: 10069.494340896606,  L-Loss: 251.69757941365242, C-Loss: 251.67443442344666\n",
      "Epoch: 182, Loss: 10383.378192901611,  L-Loss: 227.41865256428719, C-Loss: 259.52760085463524\n",
      "Epoch: 183, Loss: 9981.927778244019,  L-Loss: 266.1985411942005, C-Loss: 249.48164477944374\n",
      "Epoch: 184, Loss: 9916.85061454773,  L-Loss: 251.68751588463783, C-Loss: 247.8583441376686\n",
      "Epoch: 185, Loss: 10105.336145401001,  L-Loss: 236.66140043735504, C-Loss: 252.5742375254631\n",
      "Epoch: 186, Loss: 9964.726058959961,  L-Loss: 227.7242567241192, C-Loss: 249.061220318079\n",
      "Epoch: 187, Loss: 9999.378204345703,  L-Loss: 241.20401313900948, C-Loss: 249.92415422201157\n",
      "Epoch: 188, Loss: 10306.097133636475,  L-Loss: 240.15025946497917, C-Loss: 257.5923904776573\n",
      "Epoch: 189, Loss: 10108.016780853271,  L-Loss: 232.20019213855267, C-Loss: 252.642369389534\n",
      "Epoch: 190, Loss: 10193.96948814392,  L-Loss: 244.39382913708687, C-Loss: 254.78813916444778\n",
      "Epoch: 191, Loss: 10088.496698379517,  L-Loss: 239.01078522205353, C-Loss: 252.15266454219818\n",
      "Epoch: 192, Loss: 10033.599418640137,  L-Loss: 276.22968769073486, C-Loss: 250.77092811465263\n",
      "Epoch: 193, Loss: 10030.87100982666,  L-Loss: 241.69446468353271, C-Loss: 250.71135067939758\n",
      "Epoch: 194, Loss: 10129.75881767273,  L-Loss: 209.1627620458603, C-Loss: 253.1916795372963\n",
      "Epoch: 195, Loss: 10120.62964439392,  L-Loss: 248.75776255130768, C-Loss: 252.95355105400085\n",
      "Epoch: 196, Loss: 10145.961111068726,  L-Loss: 216.57771772146225, C-Loss: 253.59488314390182\n",
      "Epoch: 197, Loss: 9963.087198257446,  L-Loss: 241.845623254776, C-Loss: 249.01671820878983\n",
      "Epoch: 198, Loss: 10057.280004501343,  L-Loss: 253.9568561911583, C-Loss: 251.3685109615326\n",
      "Epoch: 199, Loss: 10217.27162361145,  L-Loss: 228.31838846206665, C-Loss: 255.37471109628677\n",
      "Epoch: 200, Loss: 10083.771957397461,  L-Loss: 209.66927754878998, C-Loss: 252.04188114404678\n",
      "Epoch: 201, Loss: 10018.009084701538,  L-Loss: 249.9860316514969, C-Loss: 250.38773012161255\n",
      "Epoch: 202, Loss: 10135.132158279419,  L-Loss: 215.88373443484306, C-Loss: 253.32433313131332\n",
      "Epoch: 203, Loss: 10216.754697799683,  L-Loss: 207.5767868757248, C-Loss: 255.36697340011597\n",
      "Epoch: 204, Loss: 10081.775455474854,  L-Loss: 228.07239097356796, C-Loss: 251.98736855387688\n",
      "Epoch: 205, Loss: 9910.991092681885,  L-Loss: 249.37553983926773, C-Loss: 247.7124338746071\n",
      "Epoch: 206, Loss: 9960.48087310791,  L-Loss: 229.46654126048088, C-Loss: 248.95465502142906\n",
      "Epoch: 207, Loss: 10094.581783294678,  L-Loss: 232.1018262207508, C-Loss: 252.30651879310608\n",
      "Epoch: 208, Loss: 10115.333478927612,  L-Loss: 265.60672077536583, C-Loss: 252.81693530082703\n",
      "Epoch: 209, Loss: 10043.123620986938,  L-Loss: 207.7432173639536, C-Loss: 251.0261544585228\n",
      "Epoch: 210, Loss: 10048.4784450531,  L-Loss: 212.5961498618126, C-Loss: 251.15881204605103\n",
      "Epoch: 211, Loss: 10008.67265510559,  L-Loss: 234.790109410882, C-Loss: 250.15811955928802\n",
      "Epoch: 212, Loss: 10053.57042312622,  L-Loss: 266.3019167780876, C-Loss: 251.27268505096436\n",
      "Epoch: 213, Loss: 10340.208925247192,  L-Loss: 235.61682778596878, C-Loss: 258.4463190436363\n",
      "Epoch: 214, Loss: 10150.888288497925,  L-Loss: 232.94533360004425, C-Loss: 253.71397107839584\n",
      "Epoch: 215, Loss: 10016.566883087158,  L-Loss: 240.20234763622284, C-Loss: 250.3541211783886\n",
      "Epoch: 216, Loss: 9828.530044555664,  L-Loss: 242.61273702979088, C-Loss: 245.65259811282158\n",
      "Epoch: 217, Loss: 10118.742998123169,  L-Loss: 232.86305245757103, C-Loss: 252.91035941243172\n",
      "Epoch: 218, Loss: 10056.147272109985,  L-Loss: 201.70870359241962, C-Loss: 251.3532544374466\n",
      "Epoch: 219, Loss: 9806.529697418213,  L-Loss: 227.19032549858093, C-Loss: 245.1064445078373\n",
      "Epoch: 220, Loss: 10021.016319274902,  L-Loss: 215.984927713871, C-Loss: 250.47141137719154\n",
      "Epoch: 221, Loss: 10003.785484313965,  L-Loss: 247.91892832517624, C-Loss: 250.03265738487244\n",
      "Epoch: 222, Loss: 10092.343578338623,  L-Loss: 236.12369221448898, C-Loss: 252.24955880641937\n",
      "Epoch: 223, Loss: 10270.124835968018,  L-Loss: 232.4515915811062, C-Loss: 256.6950079202652\n",
      "Epoch: 224, Loss: 10098.977001190186,  L-Loss: 221.96643924713135, C-Loss: 252.41893261671066\n",
      "Epoch: 225, Loss: 9753.215270996094,  L-Loss: 244.11698576807976, C-Loss: 243.76935267448425\n",
      "Epoch: 226, Loss: 9600.812351226807,  L-Loss: 249.4212327003479, C-Loss: 239.95795339345932\n",
      "Epoch: 227, Loss: 10266.467237472534,  L-Loss: 239.5396799594164, C-Loss: 256.60179567337036\n",
      "Epoch: 228, Loss: 10105.10200881958,  L-Loss: 228.49429455399513, C-Loss: 252.5704272389412\n",
      "Epoch: 229, Loss: 9990.46106338501,  L-Loss: 227.92125245928764, C-Loss: 249.70454621315002\n",
      "Epoch: 230, Loss: 9989.73644065857,  L-Loss: 224.50504404306412, C-Loss: 249.68728438019753\n",
      "Epoch: 231, Loss: 9984.340059280396,  L-Loss: 237.2860183119774, C-Loss: 249.5491799712181\n",
      "Epoch: 232, Loss: 10102.622699737549,  L-Loss: 239.57473254203796, C-Loss: 252.50567388534546\n",
      "Epoch: 233, Loss: 10155.916061401367,  L-Loss: 226.95621845126152, C-Loss: 253.84116196632385\n",
      "Epoch: 234, Loss: 9803.446813583374,  L-Loss: 227.49368046224117, C-Loss: 245.02929717302322\n",
      "Epoch: 235, Loss: 9980.612190246582,  L-Loss: 240.83023178577423, C-Loss: 249.45509713888168\n",
      "Epoch: 236, Loss: 9886.345012664795,  L-Loss: 235.97568118572235, C-Loss: 247.09963166713715\n",
      "Epoch: 237, Loss: 9941.617208480835,  L-Loss: 240.8829311132431, C-Loss: 248.48020938038826\n",
      "Epoch: 238, Loss: 9893.581161499023,  L-Loss: 242.3756078183651, C-Loss: 247.2789346575737\n",
      "Epoch: 239, Loss: 9803.001941680908,  L-Loss: 195.782041400671, C-Loss: 245.02610355615616\n",
      "Epoch: 240, Loss: 9822.93539237976,  L-Loss: 226.35341304540634, C-Loss: 245.51679709553719\n",
      "Epoch: 241, Loss: 9969.327478408813,  L-Loss: 240.2891440242529, C-Loss: 249.17311465740204\n",
      "Epoch: 242, Loss: 9997.198348999023,  L-Loss: 214.39102533459663, C-Loss: 249.87636095285416\n",
      "Epoch: 243, Loss: 9931.010112762451,  L-Loss: 213.60752771794796, C-Loss: 248.22185099124908\n",
      "Epoch: 244, Loss: 9763.540977478027,  L-Loss: 220.27953819930553, C-Loss: 244.03345465660095\n",
      "Epoch: 245, Loss: 9861.168781280518,  L-Loss: 240.88035982847214, C-Loss: 246.46899938583374\n",
      "Epoch: 246, Loss: 9867.887447357178,  L-Loss: 237.0924118757248, C-Loss: 246.63791382312775\n",
      "Epoch: 247, Loss: 10054.698873519897,  L-Loss: 213.1432904601097, C-Loss: 251.31418651342392\n",
      "Epoch: 248, Loss: 10041.48119544983,  L-Loss: 219.1524491906166, C-Loss: 250.98224180936813\n",
      "Epoch: 249, Loss: 9952.080030441284,  L-Loss: 222.89813202619553, C-Loss: 248.7462765276432\n",
      "Epoch: 250, Loss: 9942.405700683594,  L-Loss: 223.8929784297943, C-Loss: 248.50416857004166\n",
      "Epoch: 251, Loss: 10069.330522537231,  L-Loss: 204.38704550266266, C-Loss: 251.6821661889553\n",
      "Epoch: 252, Loss: 9995.237758636475,  L-Loss: 235.88852886855602, C-Loss: 249.82197201251984\n",
      "Epoch: 253, Loss: 9952.98069190979,  L-Loss: 207.86223486065865, C-Loss: 248.7725515961647\n",
      "Epoch: 254, Loss: 10043.724298477173,  L-Loss: 224.03755035996437, C-Loss: 251.03709870576859\n",
      "Epoch: 255, Loss: 9963.69483757019,  L-Loss: 241.20814895629883, C-Loss: 249.03206899762154\n",
      "Epoch: 256, Loss: 9926.495262145996,  L-Loss: 225.4561512619257, C-Loss: 248.10601729154587\n",
      "Epoch: 257, Loss: 10145.623819351196,  L-Loss: 216.04809442162514, C-Loss: 253.5865831375122\n",
      "Epoch: 258, Loss: 10030.30611038208,  L-Loss: 233.29457464814186, C-Loss: 250.69932889938354\n",
      "Epoch: 259, Loss: 9916.521541595459,  L-Loss: 254.4125193655491, C-Loss: 247.84943568706512\n",
      "Epoch: 260, Loss: 10001.173519134521,  L-Loss: 235.61851599812508, C-Loss: 249.97043377161026\n",
      "Epoch: 261, Loss: 9900.12696647644,  L-Loss: 236.7307917624712, C-Loss: 247.44399094581604\n",
      "Epoch: 262, Loss: 9848.013439178467,  L-Loss: 231.15487146377563, C-Loss: 246.14254742860794\n",
      "Epoch: 263, Loss: 9907.668941497803,  L-Loss: 220.10168120265007, C-Loss: 247.63669809699059\n",
      "Epoch: 264, Loss: 9838.670791625977,  L-Loss: 212.83080062270164, C-Loss: 245.9135622382164\n",
      "Epoch: 265, Loss: 9887.596323013306,  L-Loss: 199.5423709601164, C-Loss: 247.1400226354599\n",
      "Epoch: 266, Loss: 9933.808059692383,  L-Loss: 225.27977319061756, C-Loss: 248.28888103365898\n",
      "Epoch: 267, Loss: 9856.316581726074,  L-Loss: 227.38816384971142, C-Loss: 246.35106772184372\n",
      "Epoch: 268, Loss: 9824.303224563599,  L-Loss: 214.58912986516953, C-Loss: 245.55393281579018\n",
      "Epoch: 269, Loss: 9911.098920822144,  L-Loss: 231.98867446184158, C-Loss: 247.71947607398033\n",
      "Epoch: 270, Loss: 10108.395641326904,  L-Loss: 211.4002685546875, C-Loss: 252.65704149007797\n",
      "Epoch: 271, Loss: 9982.12409210205,  L-Loss: 205.17079496383667, C-Loss: 249.50180953741074\n",
      "Epoch: 272, Loss: 9764.242113113403,  L-Loss: 214.53757399320602, C-Loss: 244.05241805315018\n",
      "Epoch: 273, Loss: 9971.973239898682,  L-Loss: 215.39304542541504, C-Loss: 249.24548250436783\n",
      "Epoch: 274, Loss: 10201.476091384888,  L-Loss: 196.31714263558388, C-Loss: 254.98782235383987\n",
      "Epoch: 275, Loss: 9916.368043899536,  L-Loss: 215.0618768632412, C-Loss: 247.8554349541664\n",
      "Epoch: 276, Loss: 10036.941534042358,  L-Loss: 225.62283554673195, C-Loss: 250.86713236570358\n",
      "Epoch: 277, Loss: 9871.125394821167,  L-Loss: 206.41100192070007, C-Loss: 246.72653245925903\n",
      "Epoch: 278, Loss: 10048.483331680298,  L-Loss: 232.94413042068481, C-Loss: 251.15384703874588\n",
      "Epoch: 279, Loss: 10119.046127319336,  L-Loss: 215.74444571137428, C-Loss: 252.92221647500992\n",
      "Epoch: 280, Loss: 9875.96215248108,  L-Loss: 224.86941903829575, C-Loss: 246.8428366780281\n",
      "Epoch: 281, Loss: 9753.346586227417,  L-Loss: 230.52809217572212, C-Loss: 243.77603244781494\n",
      "Epoch: 282, Loss: 10054.283451080322,  L-Loss: 201.41876792907715, C-Loss: 251.30673158168793\n",
      "Epoch: 283, Loss: 9815.216524124146,  L-Loss: 215.56414514780045, C-Loss: 245.32652181386948\n",
      "Epoch: 284, Loss: 9956.239109039307,  L-Loss: 211.94638861715794, C-Loss: 248.8529914021492\n",
      "Epoch: 285, Loss: 9922.058683395386,  L-Loss: 191.12747053802013, C-Loss: 248.0036854147911\n",
      "Epoch: 286, Loss: 9975.312351226807,  L-Loss: 189.46507994830608, C-Loss: 249.3354434967041\n",
      "Epoch: 287, Loss: 10082.789672851562,  L-Loss: 254.50510147213936, C-Loss: 252.00611519813538\n",
      "Epoch: 288, Loss: 10030.765058517456,  L-Loss: 215.2994890511036, C-Loss: 250.71530085802078\n",
      "Epoch: 289, Loss: 10068.998582839966,  L-Loss: 187.85618124902248, C-Loss: 251.678000330925\n",
      "Epoch: 290, Loss: 9914.289278030396,  L-Loss: 218.8511807024479, C-Loss: 247.80251795053482\n",
      "Epoch: 291, Loss: 10025.127292633057,  L-Loss: 197.52426424622536, C-Loss: 250.5788009762764\n",
      "Epoch: 292, Loss: 9932.684911727905,  L-Loss: 231.16014596819878, C-Loss: 248.25933268666267\n",
      "Epoch: 293, Loss: 9905.666076660156,  L-Loss: 200.10593628883362, C-Loss: 247.5916251540184\n",
      "Epoch: 294, Loss: 10179.281703948975,  L-Loss: 191.98441126942635, C-Loss: 254.43404614925385\n",
      "Epoch: 295, Loss: 9838.026168823242,  L-Loss: 214.79292008280754, C-Loss: 245.89695596694946\n",
      "Epoch: 296, Loss: 9852.345663070679,  L-Loss: 204.66023071110249, C-Loss: 246.25747615098953\n",
      "Epoch: 297, Loss: 9912.124160766602,  L-Loss: 210.12808486819267, C-Loss: 247.75057211518288\n",
      "Epoch: 298, Loss: 9825.162225723267,  L-Loss: 204.97559666633606, C-Loss: 245.57781171798706\n",
      "Epoch: 299, Loss: 10093.726057052612,  L-Loss: 179.41549889743328, C-Loss: 252.2982976436615\n",
      "Epoch: 300, Loss: 10040.512977600098,  L-Loss: 204.52800326049328, C-Loss: 250.9616922736168\n",
      "Epoch: 301, Loss: 10066.78112411499,  L-Loss: 245.54760605096817, C-Loss: 251.60814163088799\n",
      "Epoch: 302, Loss: 9754.612028121948,  L-Loss: 210.29246127605438, C-Loss: 243.8127276301384\n",
      "Epoch: 303, Loss: 10063.209558486938,  L-Loss: 206.27527168393135, C-Loss: 251.5286700129509\n",
      "Epoch: 304, Loss: 9850.153547286987,  L-Loss: 201.36006689071655, C-Loss: 246.20349824428558\n",
      "Epoch: 305, Loss: 9939.065305709839,  L-Loss: 215.07803452014923, C-Loss: 248.4228628873825\n",
      "Epoch: 306, Loss: 10037.794441223145,  L-Loss: 215.59121271967888, C-Loss: 250.89096355438232\n",
      "Epoch: 307, Loss: 9805.575960159302,  L-Loss: 206.32005831599236, C-Loss: 245.0878186225891\n",
      "Epoch: 308, Loss: 9865.523475646973,  L-Loss: 204.7277716398239, C-Loss: 246.5869047343731\n",
      "Epoch: 309, Loss: 9872.06269645691,  L-Loss: 194.12333430349827, C-Loss: 246.753035902977\n",
      "Epoch: 310, Loss: 9683.610893249512,  L-Loss: 198.68317839503288, C-Loss: 242.0406011044979\n",
      "Epoch: 311, Loss: 9975.555345535278,  L-Loss: 184.80822178721428, C-Loss: 249.34268075227737\n",
      "Epoch: 312, Loss: 9815.587154388428,  L-Loss: 195.06081260740757, C-Loss: 245.34091344475746\n",
      "Epoch: 313, Loss: 10134.380275726318,  L-Loss: 199.51717644929886, C-Loss: 253.30962738394737\n",
      "Epoch: 314, Loss: 9971.106262207031,  L-Loss: 209.41747334599495, C-Loss: 249.2253023982048\n",
      "Epoch: 315, Loss: 9886.170551300049,  L-Loss: 219.2815450578928, C-Loss: 247.09944343566895\n",
      "Epoch: 316, Loss: 9838.682891845703,  L-Loss: 202.74660736322403, C-Loss: 245.91638526320457\n",
      "Epoch: 317, Loss: 9697.129364013672,  L-Loss: 191.53557762503624, C-Loss: 242.38035050034523\n",
      "Epoch: 318, Loss: 9995.832397460938,  L-Loss: 182.90826155245304, C-Loss: 249.85008177161217\n",
      "Epoch: 319, Loss: 9705.532335281372,  L-Loss: 211.68324330449104, C-Loss: 242.5853874385357\n",
      "Epoch: 320, Loss: 9918.722118377686,  L-Loss: 178.20373241603374, C-Loss: 247.9235019683838\n",
      "Epoch: 321, Loss: 9953.563674926758,  L-Loss: 191.38567478954792, C-Loss: 248.79124519228935\n",
      "Epoch: 322, Loss: 10036.24526977539,  L-Loss: 176.28323443233967, C-Loss: 250.86206048727036\n",
      "Epoch: 323, Loss: 9831.934492111206,  L-Loss: 189.72676160931587, C-Loss: 245.75093054771423\n",
      "Epoch: 324, Loss: 9703.1018409729,  L-Loss: 200.5108941346407, C-Loss: 242.5274184346199\n",
      "Epoch: 325, Loss: 9845.666757583618,  L-Loss: 181.5279615521431, C-Loss: 246.0962875187397\n",
      "Epoch: 326, Loss: 10164.92601776123,  L-Loss: 182.86267310380936, C-Loss: 254.0774348974228\n",
      "Epoch: 327, Loss: 9749.12000656128,  L-Loss: 179.0920883566141, C-Loss: 243.68322724103928\n",
      "Epoch: 328, Loss: 9862.084239959717,  L-Loss: 198.86624360084534, C-Loss: 246.5023884177208\n",
      "Epoch: 329, Loss: 9878.508308410645,  L-Loss: 191.62618324160576, C-Loss: 246.91480112075806\n",
      "Epoch: 330, Loss: 10169.588975906372,  L-Loss: 192.62591695785522, C-Loss: 254.19156789779663\n",
      "Epoch: 331, Loss: 9900.911979675293,  L-Loss: 173.87098751962185, C-Loss: 247.47933155298233\n",
      "Epoch: 332, Loss: 9814.283422470093,  L-Loss: 182.72863498330116, C-Loss: 245.31140330433846\n",
      "Epoch: 333, Loss: 9922.96294593811,  L-Loss: 186.52193918824196, C-Loss: 248.02744311094284\n",
      "Epoch: 334, Loss: 9949.117240905762,  L-Loss: 192.51715007424355, C-Loss: 248.67980149388313\n",
      "Epoch: 335, Loss: 9757.250406265259,  L-Loss: 165.20364733040333, C-Loss: 243.88995936512947\n",
      "Epoch: 336, Loss: 9712.666339874268,  L-Loss: 201.89828845858574, C-Loss: 242.7661838531494\n",
      "Epoch: 337, Loss: 10002.187969207764,  L-Loss: 197.84023973345757, C-Loss: 250.0052388906479\n",
      "Epoch: 338, Loss: 9778.88763999939,  L-Loss: 172.88703407347202, C-Loss: 244.42896938323975\n",
      "Epoch: 339, Loss: 9773.672998428345,  L-Loss: 195.01064270734787, C-Loss: 244.29307252168655\n",
      "Epoch: 340, Loss: 9941.590913772583,  L-Loss: 177.56564503908157, C-Loss: 248.4953818321228\n",
      "Epoch: 341, Loss: 9732.741262435913,  L-Loss: 187.01783683896065, C-Loss: 243.2717768549919\n",
      "Epoch: 342, Loss: 9892.495519638062,  L-Loss: 200.01032806932926, C-Loss: 247.26238489151\n",
      "Epoch: 343, Loss: 9849.276084899902,  L-Loss: 185.7757896333933, C-Loss: 246.18545764684677\n",
      "Epoch: 344, Loss: 9755.354984283447,  L-Loss: 172.91661144793034, C-Loss: 243.84064614772797\n",
      "Epoch: 345, Loss: 9879.727743148804,  L-Loss: 166.77699978649616, C-Loss: 246.95149910449982\n",
      "Epoch: 346, Loss: 9859.00725364685,  L-Loss: 174.09596534073353, C-Loss: 246.43165808916092\n",
      "Epoch: 347, Loss: 9949.562158584595,  L-Loss: 156.55504767596722, C-Loss: 248.6999151110649\n",
      "Epoch: 348, Loss: 9866.27865600586,  L-Loss: 154.2612739354372, C-Loss: 246.6184010207653\n",
      "Epoch: 349, Loss: 9990.141981124878,  L-Loss: 163.49084797501564, C-Loss: 249.71267652511597\n",
      "Epoch: 350, Loss: 9893.256872177124,  L-Loss: 169.21013069152832, C-Loss: 247.2891189455986\n",
      "Epoch: 351, Loss: 9786.3016872406,  L-Loss: 161.01406748592854, C-Loss: 244.61728847026825\n",
      "Epoch: 352, Loss: 10036.913835525513,  L-Loss: 163.15571209788322, C-Loss: 250.88205629587173\n",
      "Epoch: 353, Loss: 9854.158369064331,  L-Loss: 153.72952342033386, C-Loss: 246.3155272603035\n",
      "Epoch: 354, Loss: 9959.413911819458,  L-Loss: 164.4645486176014, C-Loss: 248.94423180818558\n",
      "Epoch: 355, Loss: 9892.57035446167,  L-Loss: 160.52323032915592, C-Loss: 247.2741282582283\n",
      "Epoch: 356, Loss: 9780.792556762695,  L-Loss: 173.99017000198364, C-Loss: 244.47631564736366\n",
      "Epoch: 357, Loss: 10020.486278533936,  L-Loss: 166.58948050439358, C-Loss: 250.47050994634628\n",
      "Epoch: 358, Loss: 9914.151607513428,  L-Loss: 178.66541002690792, C-Loss: 247.80912345647812\n",
      "Epoch: 359, Loss: 9786.073638916016,  L-Loss: 169.32030029594898, C-Loss: 244.60951083898544\n",
      "Epoch: 360, Loss: 9830.473104476929,  L-Loss: 179.77853977680206, C-Loss: 245.7168830037117\n",
      "Epoch: 361, Loss: 9837.086465835571,  L-Loss: 162.46532054245472, C-Loss: 245.88654559850693\n",
      "Epoch: 362, Loss: 9899.485061645508,  L-Loss: 164.7568589746952, C-Loss: 247.4459381699562\n",
      "Epoch: 363, Loss: 9859.689443588257,  L-Loss: 149.81301203370094, C-Loss: 246.45478305220604\n",
      "Epoch: 364, Loss: 9841.357526779175,  L-Loss: 149.93348729610443, C-Loss: 245.99645578861237\n",
      "Epoch: 365, Loss: 9939.7555809021,  L-Loss: 163.57529266178608, C-Loss: 248.452996134758\n",
      "Epoch: 366, Loss: 10011.653379440308,  L-Loss: 164.83584865927696, C-Loss: 250.2501259446144\n",
      "Epoch: 367, Loss: 9847.008903503418,  L-Loss: 158.02249538898468, C-Loss: 246.13571652770042\n",
      "Epoch: 368, Loss: 9830.827215194702,  L-Loss: 172.2236549705267, C-Loss: 245.72762370109558\n",
      "Epoch: 369, Loss: 10021.78190612793,  L-Loss: 156.83511093258858, C-Loss: 250.5053390264511\n",
      "Epoch: 370, Loss: 10010.82140159607,  L-Loss: 145.94739976525307, C-Loss: 250.23404824733734\n",
      "Epoch: 371, Loss: 9845.154808044434,  L-Loss: 170.71506433188915, C-Loss: 246.08619129657745\n",
      "Epoch: 372, Loss: 9827.456729888916,  L-Loss: 183.41021075844765, C-Loss: 245.6405652165413\n",
      "Epoch: 373, Loss: 9889.090549468994,  L-Loss: 157.730691999197, C-Loss: 247.18783062696457\n",
      "Epoch: 374, Loss: 9664.77184677124,  L-Loss: 166.07656399905682, C-Loss: 241.5777759552002\n",
      "Epoch: 375, Loss: 9953.22929763794,  L-Loss: 165.44119438529015, C-Loss: 248.78937140107155\n",
      "Epoch: 376, Loss: 9823.968194961548,  L-Loss: 159.95228317379951, C-Loss: 245.55921685695648\n",
      "Epoch: 377, Loss: 9991.012102127075,  L-Loss: 147.522394657135, C-Loss: 249.73842257261276\n",
      "Epoch: 378, Loss: 9788.250122070312,  L-Loss: 154.65390533208847, C-Loss: 244.66758960485458\n",
      "Epoch: 379, Loss: 9759.15703010559,  L-Loss: 159.735545784235, C-Loss: 243.9389918744564\n",
      "Epoch: 380, Loss: 9873.789337158203,  L-Loss: 149.046362221241, C-Loss: 246.8074718117714\n",
      "Epoch: 381, Loss: 9870.048364639282,  L-Loss: 145.51202565431595, C-Loss: 246.71483087539673\n",
      "Epoch: 382, Loss: 10100.480920791626,  L-Loss: 144.57357148826122, C-Loss: 252.47587925195694\n",
      "Epoch: 383, Loss: 9902.942735671997,  L-Loss: 158.18931260704994, C-Loss: 247.53402084112167\n",
      "Epoch: 384, Loss: 9983.944858551025,  L-Loss: 140.25032456219196, C-Loss: 249.56355845928192\n",
      "Epoch: 385, Loss: 9956.61023902893,  L-Loss: 140.6255564391613, C-Loss: 248.8800995349884\n",
      "Epoch: 386, Loss: 9861.074073791504,  L-Loss: 148.60421411693096, C-Loss: 246.48970073461533\n",
      "Epoch: 387, Loss: 9734.20862197876,  L-Loss: 155.65468521416187, C-Loss: 243.31630167365074\n",
      "Epoch: 388, Loss: 10027.911838531494,  L-Loss: 154.77828577160835, C-Loss: 250.65910178422928\n",
      "Epoch: 389, Loss: 9954.88705253601,  L-Loss: 173.94893677532673, C-Loss: 248.82868891954422\n",
      "Epoch: 390, Loss: 10060.572631835938,  L-Loss: 155.58559276163578, C-Loss: 251.47541922330856\n",
      "Epoch: 391, Loss: 9653.282836914062,  L-Loss: 151.10735745728016, C-Loss: 241.29429414868355\n",
      "Epoch: 392, Loss: 9497.314779281616,  L-Loss: 191.90583655238152, C-Loss: 237.38489332795143\n",
      "Epoch: 393, Loss: 9728.254247665405,  L-Loss: 181.25379008054733, C-Loss: 243.16104248166084\n",
      "Epoch: 394, Loss: 9711.783990859985,  L-Loss: 153.4772251546383, C-Loss: 242.75623109936714\n",
      "Epoch: 395, Loss: 9834.97694015503,  L-Loss: 162.74721166491508, C-Loss: 245.83373621106148\n",
      "Epoch: 396, Loss: 9995.74377822876,  L-Loss: 150.35610614717007, C-Loss: 249.85600513219833\n",
      "Epoch: 397, Loss: 9816.02416419983,  L-Loss: 189.65644426643848, C-Loss: 245.35319024324417\n",
      "Epoch: 398, Loss: 10018.50510597229,  L-Loss: 172.3240523636341, C-Loss: 250.41954624652863\n",
      "Epoch: 399, Loss: 10211.909240722656,  L-Loss: 150.0489621013403, C-Loss: 255.2602179646492\n",
      "Epoch: 400, Loss: 10207.551961898804,  L-Loss: 156.51612846553326, C-Loss: 255.1496695280075\n",
      "Epoch: 401, Loss: 10021.115715026855,  L-Loss: 170.39804965257645, C-Loss: 250.48529344797134\n",
      "Epoch: 402, Loss: 9951.837327957153,  L-Loss: 156.1444891244173, C-Loss: 248.75689667463303\n",
      "Epoch: 403, Loss: 10053.023941040039,  L-Loss: 156.6715525984764, C-Loss: 251.2864310145378\n",
      "Epoch: 404, Loss: 9804.937711715698,  L-Loss: 168.8175707012415, C-Loss: 245.08123797178268\n",
      "Epoch: 405, Loss: 10257.254270553589,  L-Loss: 149.3522872030735, C-Loss: 256.3940183520317\n",
      "Epoch: 406, Loss: 9988.871677398682,  L-Loss: 170.30248077213764, C-Loss: 249.67921674251556\n",
      "Epoch: 407, Loss: 9968.748977661133,  L-Loss: 152.65603046119213, C-Loss: 249.18056070804596\n",
      "Epoch: 408, Loss: 10109.799198150635,  L-Loss: 145.04610747098923, C-Loss: 252.70871829986572\n",
      "Epoch: 409, Loss: 10314.425189971924,  L-Loss: 155.7936802059412, C-Loss: 257.82168090343475\n",
      "Epoch: 410, Loss: 10073.445280075073,  L-Loss: 165.40302996337414, C-Loss: 251.79478174448013\n",
      "Epoch: 411, Loss: 9970.705402374268,  L-Loss: 166.4113550633192, C-Loss: 249.22603273391724\n",
      "Epoch: 412, Loss: 10321.14384651184,  L-Loss: 151.81029352545738, C-Loss: 257.9906436800957\n",
      "Epoch: 413, Loss: 10268.66197013855,  L-Loss: 199.5048517882824, C-Loss: 256.66667330265045\n",
      "Epoch: 414, Loss: 10208.29273033142,  L-Loss: 195.79131290316582, C-Loss: 255.15837055444717\n",
      "Epoch: 415, Loss: 9986.083684921265,  L-Loss: 223.827881783247, C-Loss: 249.59613543748856\n",
      "Epoch: 416, Loss: 10331.837915420532,  L-Loss: 200.46757808327675, C-Loss: 258.24583089351654\n",
      "Epoch: 417, Loss: 10558.373725891113,  L-Loss: 203.7413221001625, C-Loss: 263.9084081053734\n",
      "Epoch: 418, Loss: 10744.106113433838,  L-Loss: 187.81856293976307, C-Loss: 268.55569791793823\n",
      "Epoch: 419, Loss: 10750.626234054565,  L-Loss: 183.58087082207203, C-Loss: 268.7197602391243\n",
      "Epoch: 420, Loss: 10736.798990249634,  L-Loss: 190.16598565876484, C-Loss: 268.37243366241455\n",
      "Epoch: 421, Loss: 10879.214677810669,  L-Loss: 184.67703430354595, C-Loss: 271.9341975450516\n",
      "Epoch: 422, Loss: 10763.852516174316,  L-Loss: 179.5611070394516, C-Loss: 269.0514225959778\n",
      "Epoch: 423, Loss: 10489.960502624512,  L-Loss: 182.02211451530457, C-Loss: 262.2035076916218\n",
      "Epoch: 424, Loss: 10386.018396377563,  L-Loss: 204.70023876428604, C-Loss: 259.59928447008133\n",
      "Epoch: 425, Loss: 10587.444566726685,  L-Loss: 181.43649902939796, C-Loss: 264.64075499773026\n",
      "Epoch: 426, Loss: 10593.4760055542,  L-Loss: 167.86841547489166, C-Loss: 264.7949321269989\n",
      "Epoch: 427, Loss: 10629.923406600952,  L-Loss: 163.35300110280514, C-Loss: 265.70724672079086\n",
      "Epoch: 428, Loss: 10448.566078186035,  L-Loss: 159.4855892956257, C-Loss: 261.17428055405617\n",
      "Epoch: 429, Loss: 10448.321430206299,  L-Loss: 168.44409170746803, C-Loss: 261.16592502593994\n",
      "Epoch: 430, Loss: 10544.876251220703,  L-Loss: 165.40941908955574, C-Loss: 263.5805540084839\n",
      "Epoch: 431, Loss: 10545.026567459106,  L-Loss: 161.79035076498985, C-Loss: 263.5852161049843\n",
      "Epoch: 432, Loss: 10344.031591415405,  L-Loss: 154.53137031197548, C-Loss: 258.5621575117111\n",
      "Epoch: 433, Loss: 10746.634534835815,  L-Loss: 144.1972711533308, C-Loss: 268.62981420755386\n",
      "Epoch: 434, Loss: 10284.146125793457,  L-Loss: 148.49500705301762, C-Loss: 257.0665292143822\n",
      "Epoch: 435, Loss: 10348.96090888977,  L-Loss: 147.0886998474598, C-Loss: 258.6872502565384\n",
      "Epoch: 436, Loss: 10312.979290008545,  L-Loss: 143.1331875026226, C-Loss: 257.78869915008545\n",
      "Epoch: 437, Loss: 10416.847345352173,  L-Loss: 151.012900441885, C-Loss: 260.38343065977097\n",
      "Epoch: 438, Loss: 10432.477407455444,  L-Loss: 147.42855674028397, C-Loss: 260.77507722377777\n",
      "Epoch: 439, Loss: 10239.464248657227,  L-Loss: 147.52877442538738, C-Loss: 255.94972452521324\n",
      "Epoch: 440, Loss: 10344.003408432007,  L-Loss: 158.16743180155754, C-Loss: 258.5605426430702\n",
      "Epoch: 441, Loss: 10118.165307998657,  L-Loss: 149.77631399035454, C-Loss: 252.9166882634163\n",
      "Epoch: 442, Loss: 10222.86086654663,  L-Loss: 157.11870276927948, C-Loss: 255.53224259614944\n",
      "Epoch: 443, Loss: 10331.54472732544,  L-Loss: 155.29104290902615, C-Loss: 258.24979519844055\n",
      "Epoch: 444, Loss: 10415.952096939087,  L-Loss: 135.47330123186111, C-Loss: 260.3649345636368\n",
      "Epoch: 445, Loss: 10384.88825416565,  L-Loss: 136.51747870445251, C-Loss: 259.5880768895149\n",
      "Epoch: 446, Loss: 10330.158203125,  L-Loss: 156.4501005858183, C-Loss: 258.21484261751175\n",
      "Epoch: 447, Loss: 10321.14706993103,  L-Loss: 143.12266525626183, C-Loss: 257.9928955435753\n",
      "Epoch: 448, Loss: 10553.934827804565,  L-Loss: 143.34799082577229, C-Loss: 263.81253373622894\n",
      "Epoch: 449, Loss: 10277.35710144043,  L-Loss: 139.14566203951836, C-Loss: 256.8991407752037\n",
      "Epoch: 450, Loss: 10418.288654327393,  L-Loss: 126.36143316328526, C-Loss: 260.42562651634216\n",
      "Epoch: 451, Loss: 10504.999959945679,  L-Loss: 126.98741410672665, C-Loss: 262.59325259923935\n",
      "Epoch: 452, Loss: 10424.396017074585,  L-Loss: 142.29181072115898, C-Loss: 260.57432705163956\n",
      "Epoch: 453, Loss: 10379.966928482056,  L-Loss: 150.48183979094028, C-Loss: 259.4615529179573\n",
      "Epoch: 454, Loss: 10312.986030578613,  L-Loss: 152.35001334547997, C-Loss: 257.78656297922134\n",
      "Epoch: 455, Loss: 10139.088703155518,  L-Loss: 141.84553976356983, C-Loss: 253.44175612926483\n",
      "Epoch: 456, Loss: 10398.840768814087,  L-Loss: 141.80997875332832, C-Loss: 259.93556690216064\n",
      "Epoch: 457, Loss: 10559.23814201355,  L-Loss: 137.74170741438866, C-Loss: 263.9465175271034\n",
      "Epoch: 458, Loss: 10225.900835037231,  L-Loss: 131.08395682275295, C-Loss: 255.61474949121475\n",
      "Epoch: 459, Loss: 10399.11403465271,  L-Loss: 119.79141187667847, C-Loss: 259.9479039013386\n",
      "Epoch: 460, Loss: 10194.764686584473,  L-Loss: 127.70897184312344, C-Loss: 254.8371906876564\n",
      "Epoch: 461, Loss: 10176.219537734985,  L-Loss: 131.73605042696, C-Loss: 254.3725544810295\n",
      "Epoch: 462, Loss: 10236.806369781494,  L-Loss: 135.1517035216093, C-Loss: 255.88637155294418\n",
      "Epoch: 463, Loss: 10335.715169906616,  L-Loss: 129.13452230393887, C-Loss: 258.360595703125\n",
      "Epoch: 464, Loss: 10265.692226409912,  L-Loss: 140.1862918883562, C-Loss: 256.6072590947151\n",
      "Epoch: 465, Loss: 10222.791236877441,  L-Loss: 136.22046099603176, C-Loss: 255.53572565317154\n",
      "Epoch: 466, Loss: 10320.439559936523,  L-Loss: 132.13360913097858, C-Loss: 257.9779552221298\n",
      "Epoch: 467, Loss: 10234.29448890686,  L-Loss: 121.25109983980656, C-Loss: 255.82705014944077\n",
      "Epoch: 468, Loss: 10251.109580993652,  L-Loss: 118.05398268997669, C-Loss: 256.24822622537613\n",
      "Epoch: 469, Loss: 10181.632551193237,  L-Loss: 111.99723498523235, C-Loss: 254.5128135383129\n",
      "Epoch: 470, Loss: 10371.065603256226,  L-Loss: 130.2254058867693, C-Loss: 259.24408435821533\n",
      "Epoch: 471, Loss: 10106.588663101196,  L-Loss: 125.3313422203064, C-Loss: 252.63338404893875\n",
      "Epoch: 472, Loss: 10367.808319091797,  L-Loss: 128.3381831049919, C-Loss: 259.16312396526337\n",
      "Epoch: 473, Loss: 10525.79655456543,  L-Loss: 119.72248685359955, C-Loss: 263.11498296260834\n",
      "Epoch: 474, Loss: 10214.077239990234,  L-Loss: 127.21052570641041, C-Loss: 255.32012861967087\n",
      "Epoch: 475, Loss: 10389.473098754883,  L-Loss: 116.28111150860786, C-Loss: 259.70775723457336\n",
      "Epoch: 476, Loss: 10413.674886703491,  L-Loss: 128.96199156343937, C-Loss: 260.30963122844696\n",
      "Epoch: 477, Loss: 10384.980680465698,  L-Loss: 126.66413527727127, C-Loss: 259.59285044670105\n",
      "Epoch: 478, Loss: 10327.276054382324,  L-Loss: 116.40446780622005, C-Loss: 258.15280044078827\n",
      "Epoch: 479, Loss: 10354.897829055786,  L-Loss: 111.53481605648994, C-Loss: 258.8445616364479\n",
      "Epoch: 480, Loss: 10213.169445037842,  L-Loss: 111.57699447870255, C-Loss: 255.3013418316841\n",
      "Epoch: 481, Loss: 10340.68480682373,  L-Loss: 110.57572948932648, C-Loss: 258.48947632312775\n",
      "Epoch: 482, Loss: 10182.463411331177,  L-Loss: 135.1237322986126, C-Loss: 254.5278046131134\n",
      "Epoch: 483, Loss: 10142.957117080688,  L-Loss: 136.3839834779501, C-Loss: 253.53983229398727\n",
      "Epoch: 484, Loss: 10332.637285232544,  L-Loss: 126.25300242006779, C-Loss: 258.2843686938286\n",
      "Epoch: 485, Loss: 10189.64694595337,  L-Loss: 120.0752344429493, C-Loss: 254.71115481853485\n",
      "Epoch: 486, Loss: 10178.746551513672,  L-Loss: 120.29634399712086, C-Loss: 254.4385895729065\n",
      "Epoch: 487, Loss: 10221.470499038696,  L-Loss: 117.12762142717838, C-Loss: 255.5074800848961\n",
      "Epoch: 488, Loss: 10328.813835144043,  L-Loss: 107.59210987389088, C-Loss: 258.1934478878975\n",
      "Epoch: 489, Loss: 10333.805961608887,  L-Loss: 105.71587109565735, C-Loss: 258.3187202811241\n",
      "Epoch: 490, Loss: 10196.06949043274,  L-Loss: 100.04993925988674, C-Loss: 254.87672501802444\n",
      "Epoch: 491, Loss: 10421.036918640137,  L-Loss: 112.18705973029137, C-Loss: 260.49787598848343\n",
      "Epoch: 492, Loss: 10084.13468170166,  L-Loss: 119.28409744799137, C-Loss: 252.07354593276978\n",
      "Epoch: 493, Loss: 10684.223178863525,  L-Loss: 106.84079259634018, C-Loss: 267.07886868715286\n",
      "Epoch: 494, Loss: 10256.423992156982,  L-Loss: 102.57468590140343, C-Loss: 256.3849564194679\n",
      "Epoch: 495, Loss: 10347.870470046997,  L-Loss: 93.08818604052067, C-Loss: 258.6734898984432\n",
      "Epoch: 496, Loss: 10197.763948440552,  L-Loss: 107.32690365612507, C-Loss: 254.91726630926132\n",
      "Epoch: 497, Loss: 10464.010835647583,  L-Loss: 111.15655367076397, C-Loss: 261.5724815130234\n",
      "Epoch: 498, Loss: 10108.515501022339,  L-Loss: 114.75662116706371, C-Loss: 252.68419834971428\n",
      "Epoch: 499, Loss: 10309.447050094604,  L-Loss: 94.21112796664238, C-Loss: 257.7126230895519\n",
      "Epoch: 500, Loss: 10141.420957565308,  L-Loss: 95.11679735779762, C-Loss: 253.5117444396019\n",
      "Epoch: 501, Loss: 10189.195434570312,  L-Loss: 95.52166777849197, C-Loss: 254.7060055732727\n",
      "Epoch: 502, Loss: 10077.965353012085,  L-Loss: 105.39412696659565, C-Loss: 251.92278409004211\n",
      "Epoch: 503, Loss: 10219.777585983276,  L-Loss: 97.2284595221281, C-Loss: 255.47013300657272\n",
      "Epoch: 504, Loss: 10191.493753433228,  L-Loss: 100.94102577865124, C-Loss: 254.7621083855629\n",
      "Epoch: 505, Loss: 10288.400062561035,  L-Loss: 101.51661863923073, C-Loss: 257.1846227645874\n",
      "Epoch: 506, Loss: 10392.178266525269,  L-Loss: 95.00898262113333, C-Loss: 259.7807042002678\n",
      "Epoch: 507, Loss: 10054.126964569092,  L-Loss: 93.99720405042171, C-Loss: 251.32967549562454\n",
      "Epoch: 508, Loss: 10054.632682800293,  L-Loss: 123.97163547575474, C-Loss: 251.3348242342472\n",
      "Epoch: 509, Loss: 10093.026620864868,  L-Loss: 108.80089354515076, C-Loss: 252.2984653711319\n",
      "Epoch: 510, Loss: 10213.529378890991,  L-Loss: 95.05377446860075, C-Loss: 255.31447112560272\n",
      "Epoch: 511, Loss: 10291.650121688843,  L-Loss: 89.46437031030655, C-Loss: 257.2688866853714\n",
      "Epoch: 512, Loss: 10260.34768295288,  L-Loss: 99.18689306080341, C-Loss: 256.48389559984207\n",
      "Epoch: 513, Loss: 10114.19648361206,  L-Loss: 98.9366293400526, C-Loss: 252.8301780819893\n",
      "Epoch: 514, Loss: 10608.56358718872,  L-Loss: 90.14202776551247, C-Loss: 265.1915541291237\n",
      "Epoch: 515, Loss: 10142.075538635254,  L-Loss: 100.89210060238838, C-Loss: 253.52666568756104\n",
      "Epoch: 516, Loss: 10487.405616760254,  L-Loss: 89.58926137536764, C-Loss: 262.16274255514145\n",
      "Epoch: 517, Loss: 10522.82996559143,  L-Loss: 88.6394976079464, C-Loss: 263.0485897064209\n",
      "Epoch: 518, Loss: 10198.659366607666,  L-Loss: 99.3962204605341, C-Loss: 254.94163513183594\n",
      "Epoch: 519, Loss: 10134.278078079224,  L-Loss: 98.60722191631794, C-Loss: 253.33230006694794\n",
      "Epoch: 520, Loss: 10549.35478591919,  L-Loss: 93.98852579295635, C-Loss: 263.71037220954895\n",
      "Epoch: 521, Loss: 10212.610975265503,  L-Loss: 93.62913509458303, C-Loss: 255.29186779260635\n",
      "Epoch: 522, Loss: 10219.561546325684,  L-Loss: 87.49670065194368, C-Loss: 255.46716451644897\n",
      "Epoch: 523, Loss: 10566.474924087524,  L-Loss: 85.2230234965682, C-Loss: 264.1405673623085\n",
      "Epoch: 524, Loss: 10342.43881034851,  L-Loss: 94.28913193941116, C-Loss: 258.5373982191086\n",
      "Epoch: 525, Loss: 10225.125398635864,  L-Loss: 105.09619978070259, C-Loss: 255.6018614768982\n",
      "Epoch: 526, Loss: 10195.45643043518,  L-Loss: 96.27667580544949, C-Loss: 254.86234149336815\n",
      "Epoch: 527, Loss: 10202.203525543213,  L-Loss: 90.53559985011816, C-Loss: 255.03245443105698\n",
      "Epoch: 528, Loss: 10139.831056594849,  L-Loss: 86.33647083491087, C-Loss: 253.47419303655624\n",
      "Epoch: 529, Loss: 10479.946952819824,  L-Loss: 87.22958049178123, C-Loss: 261.9768661260605\n",
      "Epoch: 530, Loss: 10139.918169021606,  L-Loss: 80.74918816238642, C-Loss: 253.4777669608593\n",
      "Epoch: 531, Loss: 10115.544466018677,  L-Loss: 102.13543404638767, C-Loss: 252.86307787895203\n",
      "Epoch: 532, Loss: 10147.068487167358,  L-Loss: 98.57905924320221, C-Loss: 253.65206837654114\n",
      "Epoch: 533, Loss: 10129.312599182129,  L-Loss: 102.54018630087376, C-Loss: 253.20717948675156\n",
      "Epoch: 534, Loss: 10407.980039596558,  L-Loss: 92.15658743679523, C-Loss: 260.1764614582062\n",
      "Epoch: 535, Loss: 10537.803932189941,  L-Loss: 86.77306493371725, C-Loss: 263.4234055876732\n",
      "Epoch: 536, Loss: 10450.09641456604,  L-Loss: 83.78677973151207, C-Loss: 261.2314636707306\n",
      "Epoch: 537, Loss: 10361.421686172485,  L-Loss: 107.5492002516985, C-Loss: 259.0086535811424\n",
      "Epoch: 538, Loss: 10185.353427886963,  L-Loss: 105.85106557607651, C-Loss: 254.60737282037735\n",
      "Epoch: 539, Loss: 10185.602071762085,  L-Loss: 116.96781465411186, C-Loss: 254.6108102798462\n",
      "Epoch: 540, Loss: 10088.887035369873,  L-Loss: 99.78493393212557, C-Loss: 252.1972298026085\n",
      "Epoch: 541, Loss: 10199.868963241577,  L-Loss: 97.28317251801491, C-Loss: 254.9724034667015\n",
      "Epoch: 542, Loss: 10212.77914237976,  L-Loss: 90.54302935302258, C-Loss: 255.29684275388718\n",
      "Epoch: 543, Loss: 10031.102634429932,  L-Loss: 81.33169128000736, C-Loss: 250.75723266601562\n",
      "Epoch: 544, Loss: 9831.155195236206,  L-Loss: 96.01115752011538, C-Loss: 245.75487706065178\n",
      "Epoch: 545, Loss: 9862.107614517212,  L-Loss: 99.34519532322884, C-Loss: 246.5278544127941\n",
      "Epoch: 546, Loss: 10120.021478652954,  L-Loss: 109.79756359755993, C-Loss: 252.97308778762817\n",
      "Epoch: 547, Loss: 10297.200540542603,  L-Loss: 103.67898494005203, C-Loss: 257.4040940999985\n",
      "Epoch: 548, Loss: 10083.700588226318,  L-Loss: 106.28176906704903, C-Loss: 252.0659437775612\n",
      "Epoch: 549, Loss: 10344.700685501099,  L-Loss: 109.59804072976112, C-Loss: 258.59011739492416\n",
      "Epoch: 550, Loss: 10015.718515396118,  L-Loss: 94.00997292995453, C-Loss: 250.36945924162865\n",
      "Epoch: 551, Loss: 10221.707027435303,  L-Loss: 90.67029064148664, C-Loss: 255.52000832557678\n",
      "Epoch: 552, Loss: 10141.268922805786,  L-Loss: 82.84542529284954, C-Loss: 253.51101154088974\n",
      "Epoch: 553, Loss: 10361.336042404175,  L-Loss: 89.50274147838354, C-Loss: 259.0110253691673\n",
      "Epoch: 554, Loss: 10250.05417251587,  L-Loss: 95.63775084912777, C-Loss: 256.2274444103241\n",
      "Epoch: 555, Loss: 9991.454231262207,  L-Loss: 106.17775696516037, C-Loss: 249.75981158018112\n",
      "Epoch: 556, Loss: 9998.72844696045,  L-Loss: 107.74843760579824, C-Loss: 249.94127449393272\n",
      "Epoch: 557, Loss: 9889.232919692993,  L-Loss: 105.85475614666939, C-Loss: 247.20436042547226\n",
      "Epoch: 558, Loss: 10213.630012512207,  L-Loss: 97.4319942817092, C-Loss: 255.31639289855957\n",
      "Epoch: 559, Loss: 10394.773237228394,  L-Loss: 93.15431858599186, C-Loss: 259.84604290127754\n",
      "Epoch: 560, Loss: 10245.651706695557,  L-Loss: 91.24756420403719, C-Loss: 256.1184803843498\n",
      "Epoch: 561, Loss: 10046.130542755127,  L-Loss: 110.10346359014511, C-Loss: 251.12573808431625\n",
      "Epoch: 562, Loss: 10241.041006088257,  L-Loss: 102.37734194099903, C-Loss: 256.00043177604675\n",
      "Epoch: 563, Loss: 10279.105195999146,  L-Loss: 98.4180187433958, C-Loss: 256.9530259370804\n",
      "Epoch: 564, Loss: 10233.607465744019,  L-Loss: 101.6324105784297, C-Loss: 255.81477838754654\n",
      "Epoch: 565, Loss: 9867.902185440063,  L-Loss: 103.5165897756815, C-Loss: 246.67167553305626\n",
      "Epoch: 566, Loss: 9991.193731307983,  L-Loss: 109.06685101985931, C-Loss: 249.75257754325867\n",
      "Epoch: 567, Loss: 10171.917808532715,  L-Loss: 108.76071708649397, C-Loss: 254.27075517177582\n",
      "Epoch: 568, Loss: 10086.070989608765,  L-Loss: 99.34241117537022, C-Loss: 252.12693858146667\n",
      "Epoch: 569, Loss: 10061.974952697754,  L-Loss: 97.44279615581036, C-Loss: 251.52501332759857\n",
      "Epoch: 570, Loss: 10079.750192642212,  L-Loss: 86.21475560218096, C-Loss: 251.97220170497894\n",
      "Epoch: 571, Loss: 10213.90472984314,  L-Loss: 100.54385158419609, C-Loss: 255.32248270511627\n",
      "Epoch: 572, Loss: 10232.6374168396,  L-Loss: 95.63453719764948, C-Loss: 255.7920265197754\n",
      "Epoch: 573, Loss: 10157.321449279785,  L-Loss: 89.64348913729191, C-Loss: 253.91062551736832\n",
      "Epoch: 574, Loss: 10148.197982788086,  L-Loss: 79.37981892377138, C-Loss: 253.6851054430008\n",
      "Epoch: 575, Loss: 10368.19224357605,  L-Loss: 91.31667584180832, C-Loss: 259.1819769144058\n",
      "Epoch: 576, Loss: 10232.861097335815,  L-Loss: 92.42489643394947, C-Loss: 255.79842138290405\n",
      "Epoch: 577, Loss: 10039.43447303772,  L-Loss: 102.02904836833477, C-Loss: 250.96035438776016\n",
      "Epoch: 578, Loss: 10432.383714675903,  L-Loss: 97.55753087997437, C-Loss: 260.7852038741112\n",
      "Epoch: 579, Loss: 9978.385320663452,  L-Loss: 91.29015356302261, C-Loss: 249.43681073188782\n",
      "Epoch: 580, Loss: 10338.491455078125,  L-Loss: 96.95131023973227, C-Loss: 258.4380489587784\n",
      "Epoch: 581, Loss: 10443.212255477905,  L-Loss: 99.11690917611122, C-Loss: 261.0555278658867\n",
      "Epoch: 582, Loss: 10151.154180526733,  L-Loss: 93.75924127548933, C-Loss: 253.7554144859314\n",
      "Epoch: 583, Loss: 10303.958353042603,  L-Loss: 104.30714681744576, C-Loss: 257.57288229465485\n",
      "Epoch: 584, Loss: 10111.671489715576,  L-Loss: 112.63679338991642, C-Loss: 252.76362839341164\n",
      "Epoch: 585, Loss: 10011.217796325684,  L-Loss: 126.34998355805874, C-Loss: 250.24885696172714\n",
      "Epoch: 586, Loss: 10174.55262374878,  L-Loss: 123.2985578328371, C-Loss: 254.33299067616463\n",
      "Epoch: 587, Loss: 10375.786588668823,  L-Loss: 121.9794961437583, C-Loss: 259.36416989564896\n",
      "Epoch: 588, Loss: 10392.216661453247,  L-Loss: 119.57975283265114, C-Loss: 259.77552157640457\n",
      "Epoch: 589, Loss: 10224.429483413696,  L-Loss: 101.02929436415434, C-Loss: 255.5854794383049\n",
      "Epoch: 590, Loss: 10221.161779403687,  L-Loss: 96.34385892003775, C-Loss: 255.5049591064453\n",
      "Epoch: 591, Loss: 10023.4915599823,  L-Loss: 115.72913599014282, C-Loss: 250.55835688114166\n",
      "Epoch: 592, Loss: 10396.169427871704,  L-Loss: 105.63316623866558, C-Loss: 259.8778278827667\n",
      "Epoch: 593, Loss: 10035.529151916504,  L-Loss: 107.87414837628603, C-Loss: 250.86126071214676\n",
      "Epoch: 594, Loss: 10192.757308959961,  L-Loss: 110.56762617081404, C-Loss: 254.79129076004028\n",
      "Epoch: 595, Loss: 10239.558731079102,  L-Loss: 102.21199763566256, C-Loss: 255.96341532468796\n",
      "Epoch: 596, Loss: 10070.855949401855,  L-Loss: 95.91418404877186, C-Loss: 251.74742051959038\n",
      "Epoch: 597, Loss: 9799.05309677124,  L-Loss: 105.98087686300278, C-Loss: 244.94983240962029\n",
      "Epoch: 598, Loss: 10135.589637756348,  L-Loss: 106.3316067904234, C-Loss: 253.3631579875946\n",
      "Epoch: 599, Loss: 9970.776411056519,  L-Loss: 110.27200891077518, C-Loss: 249.241841673851\n",
      "Epoch: 600, Loss: 10028.935606002808,  L-Loss: 106.44342124462128, C-Loss: 250.6967794895172\n",
      "Epoch: 601, Loss: 10075.265129089355,  L-Loss: 100.79007650911808, C-Loss: 251.85643038153648\n",
      "Epoch: 602, Loss: 10266.096338272095,  L-Loss: 101.40673147141933, C-Loss: 256.62705659866333\n",
      "Epoch: 603, Loss: 9844.07029914856,  L-Loss: 107.23812579363585, C-Loss: 246.07494750618935\n",
      "Epoch: 604, Loss: 10169.144065856934,  L-Loss: 103.65636346489191, C-Loss: 254.20268714427948\n",
      "Epoch: 605, Loss: 10324.618560791016,  L-Loss: 96.58824263513088, C-Loss: 258.09131717681885\n",
      "Epoch: 606, Loss: 10259.7818069458,  L-Loss: 99.71243831515312, C-Loss: 256.46961706876755\n",
      "Epoch: 607, Loss: 10190.48949432373,  L-Loss: 99.91703234612942, C-Loss: 254.73725819587708\n",
      "Epoch: 608, Loss: 10059.65396308899,  L-Loss: 96.33508253842592, C-Loss: 251.46726459264755\n",
      "Epoch: 609, Loss: 9692.448602676392,  L-Loss: 105.50427113473415, C-Loss: 242.284838616848\n",
      "Epoch: 610, Loss: 9858.905963897705,  L-Loss: 104.8423417955637, C-Loss: 246.44643825292587\n",
      "Epoch: 611, Loss: 9825.669103622437,  L-Loss: 97.57828725129366, C-Loss: 245.6173329949379\n",
      "Epoch: 612, Loss: 10114.452018737793,  L-Loss: 92.70391654223204, C-Loss: 252.83812433481216\n",
      "Epoch: 613, Loss: 10135.033487319946,  L-Loss: 105.20740551501513, C-Loss: 253.34953486919403\n",
      "Epoch: 614, Loss: 9998.225757598877,  L-Loss: 109.56498654186726, C-Loss: 249.92825311422348\n",
      "Epoch: 615, Loss: 9898.817338943481,  L-Loss: 105.28196389228106, C-Loss: 247.4441128373146\n",
      "Epoch: 616, Loss: 10018.487478256226,  L-Loss: 113.41192109137774, C-Loss: 250.43383392691612\n",
      "Epoch: 617, Loss: 10059.84139251709,  L-Loss: 104.591179959476, C-Loss: 251.4698867201805\n",
      "Epoch: 618, Loss: 10199.748558044434,  L-Loss: 106.65924249589443, C-Loss: 254.96704882383347\n",
      "Epoch: 619, Loss: 10359.748178482056,  L-Loss: 97.09471203386784, C-Loss: 258.9694324731827\n",
      "Epoch: 620, Loss: 10089.763341903687,  L-Loss: 103.20054565370083, C-Loss: 252.21828418970108\n",
      "Epoch: 621, Loss: 10577.89748764038,  L-Loss: 108.30318256467581, C-Loss: 264.42036187648773\n",
      "Epoch: 622, Loss: 10208.643287658691,  L-Loss: 100.80323592573404, C-Loss: 255.19088065624237\n",
      "Epoch: 623, Loss: 10380.112106323242,  L-Loss: 93.9052819609642, C-Loss: 259.4793263077736\n",
      "Epoch: 624, Loss: 10281.956344604492,  L-Loss: 85.2343615591526, C-Loss: 257.0275990962982\n",
      "Epoch: 625, Loss: 10058.072414398193,  L-Loss: 82.4332912787795, C-Loss: 251.43120205402374\n",
      "Epoch: 626, Loss: 10638.71639251709,  L-Loss: 93.98707935214043, C-Loss: 265.9444128870964\n",
      "Epoch: 627, Loss: 9967.786148071289,  L-Loss: 96.95728147774935, C-Loss: 249.17041450738907\n",
      "Epoch: 628, Loss: 9961.372114181519,  L-Loss: 101.63720121979713, C-Loss: 249.00889384746552\n",
      "Epoch: 629, Loss: 10184.059627532959,  L-Loss: 103.5860393345356, C-Loss: 254.57559430599213\n",
      "Epoch: 630, Loss: 10291.295429229736,  L-Loss: 97.49369033426046, C-Loss: 257.2580127120018\n",
      "Epoch: 631, Loss: 10355.876140594482,  L-Loss: 129.6786554530263, C-Loss: 258.8644837141037\n",
      "Epoch: 632, Loss: 10046.56900024414,  L-Loss: 117.87080255150795, C-Loss: 251.13475680351257\n",
      "Epoch: 633, Loss: 10136.493249893188,  L-Loss: 140.23814069479704, C-Loss: 253.37727081775665\n",
      "Epoch: 634, Loss: 10101.55493736267,  L-Loss: 121.23042222857475, C-Loss: 252.50856572389603\n",
      "Epoch: 635, Loss: 10182.781217575073,  L-Loss: 131.79317778348923, C-Loss: 254.53658309578896\n",
      "Epoch: 636, Loss: 10142.119701385498,  L-Loss: 128.1641699373722, C-Loss: 253.52095171809196\n",
      "Epoch: 637, Loss: 10469.993078231812,  L-Loss: 127.70757487416267, C-Loss: 261.71789997816086\n",
      "Epoch: 638, Loss: 10476.73907661438,  L-Loss: 127.99736814200878, C-Loss: 261.8864767551422\n",
      "Epoch: 639, Loss: 10140.327646255493,  L-Loss: 119.59502367675304, C-Loss: 253.4782926440239\n",
      "Epoch: 640, Loss: 10148.725637435913,  L-Loss: 132.4130294919014, C-Loss: 253.6850379705429\n",
      "Epoch: 641, Loss: 9890.663864135742,  L-Loss: 137.96693916618824, C-Loss: 247.23210489749908\n",
      "Epoch: 642, Loss: 10151.622537612915,  L-Loss: 135.23726481199265, C-Loss: 253.7567531466484\n",
      "Epoch: 643, Loss: 9955.806789398193,  L-Loss: 118.5070821121335, C-Loss: 248.86554276943207\n",
      "Epoch: 644, Loss: 10074.288970947266,  L-Loss: 120.43010636419058, C-Loss: 251.82711616158485\n",
      "Epoch: 645, Loss: 10058.099500656128,  L-Loss: 133.7680343091488, C-Loss: 251.41904640197754\n",
      "Epoch: 646, Loss: 10078.423360824585,  L-Loss: 116.6707329005003, C-Loss: 251.93141669034958\n",
      "Epoch: 647, Loss: 10170.871919631958,  L-Loss: 115.5591164380312, C-Loss: 254.24290817975998\n",
      "Epoch: 648, Loss: 10193.987615585327,  L-Loss: 109.48520368337631, C-Loss: 254.822319149971\n",
      "Epoch: 649, Loss: 10029.870601654053,  L-Loss: 103.8273181244731, C-Loss: 250.72080904245377\n",
      "Epoch: 650, Loss: 9592.989074707031,  L-Loss: 145.16074895858765, C-Loss: 239.7884365618229\n",
      "Epoch: 651, Loss: 9940.36547279358,  L-Loss: 137.5994824618101, C-Loss: 248.4747371673584\n",
      "Epoch: 652, Loss: 9884.232746124268,  L-Loss: 140.0053482428193, C-Loss: 247.07081747055054\n",
      "Epoch: 653, Loss: 10075.421283721924,  L-Loss: 153.8631450459361, C-Loss: 251.8470658659935\n",
      "Epoch: 654, Loss: 10220.65054321289,  L-Loss: 147.42486952990294, C-Loss: 255.47940707206726\n",
      "Epoch: 655, Loss: 9949.066883087158,  L-Loss: 141.8591596931219, C-Loss: 248.6912081837654\n",
      "Epoch: 656, Loss: 10239.67011833191,  L-Loss: 122.12362694740295, C-Loss: 255.9612219929695\n",
      "Epoch: 657, Loss: 9873.580513000488,  L-Loss: 121.30162639915943, C-Loss: 246.80918663740158\n",
      "Epoch: 658, Loss: 9866.588481903076,  L-Loss: 132.57320731133223, C-Loss: 246.63156855106354\n",
      "Epoch: 659, Loss: 10003.628057479858,  L-Loss: 138.33951592445374, C-Loss: 250.05611646175385\n",
      "Epoch: 660, Loss: 10262.509435653687,  L-Loss: 150.2765200957656, C-Loss: 256.5251665711403\n",
      "Epoch: 661, Loss: 10109.338466644287,  L-Loss: 147.98201340436935, C-Loss: 252.69646602869034\n",
      "Epoch: 662, Loss: 10138.761386871338,  L-Loss: 131.10041911900043, C-Loss: 253.43626007437706\n",
      "Epoch: 663, Loss: 10055.627922058105,  L-Loss: 130.11572103202343, C-Loss: 251.35816967487335\n",
      "Epoch: 664, Loss: 10138.654817581177,  L-Loss: 131.55166991055012, C-Loss: 253.43348288536072\n",
      "Epoch: 665, Loss: 10024.276044845581,  L-Loss: 123.23944226652384, C-Loss: 250.57609057426453\n",
      "Epoch: 666, Loss: 10169.571891784668,  L-Loss: 116.31692631542683, C-Loss: 254.21021831035614\n",
      "Epoch: 667, Loss: 10092.785385131836,  L-Loss: 179.28974236547947, C-Loss: 252.27481192350388\n",
      "Epoch: 668, Loss: 9947.145044326782,  L-Loss: 189.12289065122604, C-Loss: 248.63134557008743\n",
      "Epoch: 669, Loss: 10078.369384765625,  L-Loss: 178.56566300988197, C-Loss: 251.9145917892456\n",
      "Epoch: 670, Loss: 9803.23902130127,  L-Loss: 134.10321661829948, C-Loss: 245.04744976758957\n",
      "Epoch: 671, Loss: 10306.950855255127,  L-Loss: 133.89413204044104, C-Loss: 257.6402976512909\n",
      "Epoch: 672, Loss: 10190.206434249878,  L-Loss: 155.06468414515257, C-Loss: 254.7163943052292\n",
      "Epoch: 673, Loss: 10123.60700416565,  L-Loss: 175.0020937845111, C-Loss: 253.04642447829247\n",
      "Epoch: 674, Loss: 10223.656742095947,  L-Loss: 199.1957644149661, C-Loss: 255.54161989688873\n",
      "Epoch: 675, Loss: 10041.327856063843,  L-Loss: 195.34042885154486, C-Loss: 250.98436164855957\n",
      "Epoch: 676, Loss: 10273.17046546936,  L-Loss: 193.53639859706163, C-Loss: 256.78087705373764\n",
      "Epoch: 677, Loss: 10181.698692321777,  L-Loss: 206.0119607374072, C-Loss: 254.4909638762474\n",
      "Epoch: 678, Loss: 10079.488498687744,  L-Loss: 248.72124100476503, C-Loss: 251.92503249645233\n",
      "Epoch: 679, Loss: 10207.866661071777,  L-Loss: 220.60611384361982, C-Loss: 255.14151495695114\n",
      "Epoch: 680, Loss: 10166.863447189331,  L-Loss: 218.13100935518742, C-Loss: 254.11705321073532\n",
      "Epoch: 681, Loss: 9866.899885177612,  L-Loss: 195.58618963509798, C-Loss: 246.62359982728958\n",
      "Epoch: 682, Loss: 9931.652347564697,  L-Loss: 267.35120971500874, C-Loss: 248.22447097301483\n",
      "Epoch: 683, Loss: 10004.235496520996,  L-Loss: 233.2961392328143, C-Loss: 250.04756224155426\n",
      "Epoch: 684, Loss: 9990.31922340393,  L-Loss: 222.8041576296091, C-Loss: 249.70227992534637\n",
      "Epoch: 685, Loss: 10121.745946884155,  L-Loss: 235.2810654938221, C-Loss: 252.984827876091\n",
      "Epoch: 686, Loss: 9897.850816726685,  L-Loss: 203.89051891118288, C-Loss: 247.39529752731323\n",
      "Epoch: 687, Loss: 9931.05082321167,  L-Loss: 186.50667913258076, C-Loss: 248.22964376211166\n",
      "Epoch: 688, Loss: 10177.950847625732,  L-Loss: 174.45467502623796, C-Loss: 254.40515732765198\n",
      "Epoch: 689, Loss: 9851.32223701477,  L-Loss: 170.75441290438175, C-Loss: 246.2403681576252\n",
      "Epoch: 690, Loss: 10208.808795928955,  L-Loss: 169.96784774959087, C-Loss: 255.17772841453552\n",
      "Epoch: 691, Loss: 10344.681051254272,  L-Loss: 158.80649358779192, C-Loss: 258.57732433080673\n",
      "Epoch: 692, Loss: 9934.566944122314,  L-Loss: 156.45584192872047, C-Loss: 248.32505947351456\n",
      "Epoch: 693, Loss: 10497.735971450806,  L-Loss: 175.1475116237998, C-Loss: 262.39961248636246\n",
      "Epoch: 694, Loss: 9889.718864440918,  L-Loss: 170.791730158031, C-Loss: 247.20027336478233\n",
      "Epoch: 695, Loss: 9975.821998596191,  L-Loss: 144.89441980421543, C-Loss: 249.3593262732029\n",
      "Epoch: 696, Loss: 10194.713684082031,  L-Loss: 139.71353401243687, C-Loss: 254.83291405439377\n",
      "Epoch: 697, Loss: 10157.319658279419,  L-Loss: 163.88769432902336, C-Loss: 253.89201974868774\n",
      "Epoch: 698, Loss: 10341.292903900146,  L-Loss: 149.1226278990507, C-Loss: 258.49504178762436\n",
      "Epoch: 699, Loss: 9783.762063980103,  L-Loss: 266.2571984529495, C-Loss: 244.52748715877533\n",
      "Epoch: 700, Loss: 9963.218078613281,  L-Loss: 238.93355125933886, C-Loss: 249.02071839571\n",
      "Epoch: 701, Loss: 10120.887832641602,  L-Loss: 222.70013856887817, C-Loss: 252.96652072668076\n",
      "Epoch: 702, Loss: 9988.86985206604,  L-Loss: 204.65399096161127, C-Loss: 249.67058327794075\n",
      "Epoch: 703, Loss: 9864.007528305054,  L-Loss: 228.11808186769485, C-Loss: 246.54315933585167\n",
      "Epoch: 704, Loss: 10161.362089157104,  L-Loss: 235.65049513429403, C-Loss: 253.9751397371292\n",
      "Epoch: 705, Loss: 9961.578790664673,  L-Loss: 237.93081010133028, C-Loss: 248.97998744249344\n",
      "Epoch: 706, Loss: 10266.71265411377,  L-Loss: 221.26278774440289, C-Loss: 256.61250108480453\n",
      "Epoch: 707, Loss: 10049.94848060608,  L-Loss: 222.8753472045064, C-Loss: 251.19299310445786\n",
      "Epoch: 708, Loss: 9909.102746963501,  L-Loss: 250.97223314642906, C-Loss: 247.66482537984848\n",
      "Epoch: 709, Loss: 10127.50837135315,  L-Loss: 347.039750918746, C-Loss: 253.10094982385635\n",
      "Epoch: 710, Loss: 10090.06715965271,  L-Loss: 280.8742306679487, C-Loss: 252.181460916996\n",
      "Epoch: 711, Loss: 10417.127376556396,  L-Loss: 249.85711587965488, C-Loss: 260.3657200932503\n",
      "Epoch: 712, Loss: 10109.517263412476,  L-Loss: 298.5286434814334, C-Loss: 252.6632986664772\n",
      "Epoch: 713, Loss: 9869.919790267944,  L-Loss: 262.810188382864, C-Loss: 246.6822921037674\n",
      "Epoch: 714, Loss: 10111.586574554443,  L-Loss: 366.7274507731199, C-Loss: 252.69798201322556\n",
      "Epoch: 715, Loss: 10035.722597122192,  L-Loss: 353.1213483661413, C-Loss: 250.80478477478027\n",
      "Epoch: 716, Loss: 10192.7954788208,  L-Loss: 316.1490313485265, C-Loss: 254.7408497929573\n",
      "Epoch: 717, Loss: 10178.81100845337,  L-Loss: 246.19043631851673, C-Loss: 254.40872782468796\n",
      "Epoch: 718, Loss: 10182.165746688843,  L-Loss: 274.5779366567731, C-Loss: 254.48549938201904\n",
      "Epoch: 719, Loss: 10084.866479873657,  L-Loss: 319.1546851247549, C-Loss: 252.04187342524529\n",
      "Epoch: 720, Loss: 10564.261667251587,  L-Loss: 311.88659504801035, C-Loss: 264.02856981754303\n",
      "Epoch: 721, Loss: 10147.22951889038,  L-Loss: 244.4861657395959, C-Loss: 253.61961668729782\n",
      "Epoch: 722, Loss: 10186.830492019653,  L-Loss: 262.53955298662186, C-Loss: 254.60512733459473\n",
      "Epoch: 723, Loss: 10170.60079574585,  L-Loss: 250.48979464173317, C-Loss: 254.2023976445198\n",
      "Epoch: 724, Loss: 9778.797063827515,  L-Loss: 248.78178012371063, C-Loss: 244.40773046016693\n",
      "Epoch: 725, Loss: 9939.051094055176,  L-Loss: 246.23512959480286, C-Loss: 248.4147186279297\n",
      "Epoch: 726, Loss: 10058.635019302368,  L-Loss: 345.63051076233387, C-Loss: 251.37946873903275\n",
      "Epoch: 727, Loss: 10281.535343170166,  L-Loss: 320.3406874164939, C-Loss: 256.9582990407944\n",
      "Epoch: 728, Loss: 9874.098415374756,  L-Loss: 290.028254725039, C-Loss: 246.77995362877846\n",
      "Epoch: 729, Loss: 9742.397075653076,  L-Loss: 276.91948253661394, C-Loss: 243.490697234869\n",
      "Epoch: 730, Loss: 9823.489683151245,  L-Loss: 217.423939332366, C-Loss: 245.53288623690605\n",
      "Epoch: 731, Loss: 10119.608150482178,  L-Loss: 239.33776408433914, C-Loss: 252.93036890029907\n",
      "Epoch: 732, Loss: 9792.203779220581,  L-Loss: 318.2582314610481, C-Loss: 244.7255297601223\n",
      "Epoch: 733, Loss: 9938.959274291992,  L-Loss: 278.8326973989606, C-Loss: 248.40427434444427\n",
      "Epoch: 734, Loss: 9849.738555908203,  L-Loss: 303.13663832098246, C-Loss: 246.16768020391464\n",
      "Epoch: 735, Loss: 9601.476055145264,  L-Loss: 241.10904766619205, C-Loss: 239.97662448883057\n",
      "Epoch: 736, Loss: 10149.447486877441,  L-Loss: 296.9349221289158, C-Loss: 253.66195392608643\n",
      "Epoch: 737, Loss: 10149.385272979736,  L-Loss: 302.3150512948632, C-Loss: 253.65905314683914\n",
      "Epoch: 738, Loss: 10074.9531955719,  L-Loss: 262.21592884510756, C-Loss: 251.80827575922012\n",
      "Epoch: 739, Loss: 10143.16541481018,  L-Loss: 265.6353851109743, C-Loss: 253.51272654533386\n",
      "Epoch: 740, Loss: 10088.635541915894,  L-Loss: 241.2335309162736, C-Loss: 252.15558078885078\n",
      "Epoch: 741, Loss: 10138.282026290894,  L-Loss: 253.1922239139676, C-Loss: 253.393752515316\n",
      "Epoch: 742, Loss: 10056.91381263733,  L-Loss: 233.9192957803607, C-Loss: 251.3643655180931\n",
      "Epoch: 743, Loss: 9941.336292266846,  L-Loss: 253.07262175530195, C-Loss: 248.47013920545578\n",
      "Epoch: 744, Loss: 10016.67791557312,  L-Loss: 211.36965685337782, C-Loss: 250.36410549283028\n",
      "Epoch: 745, Loss: 10300.071020126343,  L-Loss: 204.5344714000821, C-Loss: 257.4506416916847\n",
      "Epoch: 746, Loss: 10032.69801902771,  L-Loss: 241.0817910283804, C-Loss: 250.7571800351143\n",
      "Epoch: 747, Loss: 10262.283805847168,  L-Loss: 270.8419212922454, C-Loss: 256.489383995533\n",
      "Epoch: 748, Loss: 10324.17547416687,  L-Loss: 291.0891659334302, C-Loss: 258.0316143631935\n",
      "Epoch: 749, Loss: 9946.458158493042,  L-Loss: 346.7913363426924, C-Loss: 248.574756026268\n",
      "Epoch: 750, Loss: 9994.194917678833,  L-Loss: 325.3788096383214, C-Loss: 249.7735277414322\n",
      "Epoch: 751, Loss: 10105.86988067627,  L-Loss: 343.22202757000923, C-Loss: 252.5609411895275\n",
      "Epoch: 752, Loss: 10120.314281463623,  L-Loss: 312.8940788432956, C-Loss: 252.9296333193779\n",
      "Epoch: 753, Loss: 10093.497282028198,  L-Loss: 323.1966933235526, C-Loss: 252.25663340091705\n",
      "Epoch: 754, Loss: 10147.79190826416,  L-Loss: 311.15383127331734, C-Loss: 253.6170099377632\n",
      "Epoch: 755, Loss: 10071.645673751831,  L-Loss: 371.8251538872719, C-Loss: 251.69818538427353\n",
      "Epoch: 756, Loss: 10218.161893844604,  L-Loss: 309.81199668347836, C-Loss: 255.3765953183174\n",
      "Epoch: 757, Loss: 10247.694940567017,  L-Loss: 337.3638295829296, C-Loss: 256.1080318391323\n",
      "Epoch: 758, Loss: 9870.858213424683,  L-Loss: 421.86091896891594, C-Loss: 246.66599014401436\n",
      "Epoch: 759, Loss: 9907.076671600342,  L-Loss: 390.4738605543971, C-Loss: 247.57929864525795\n",
      "Epoch: 760, Loss: 10042.528732299805,  L-Loss: 491.8495569974184, C-Loss: 250.94025552272797\n",
      "Epoch: 761, Loss: 10007.512189865112,  L-Loss: 326.5154874101281, C-Loss: 250.10617625713348\n",
      "Epoch: 762, Loss: 10378.289972305298,  L-Loss: 303.3611918091774, C-Loss: 259.38140881061554\n",
      "Epoch: 763, Loss: 9969.44556427002,  L-Loss: 340.80987717956305, C-Loss: 249.1509366631508\n",
      "Epoch: 764, Loss: 10299.629024505615,  L-Loss: 395.7191188186407, C-Loss: 257.3917953670025\n",
      "Epoch: 765, Loss: 10328.979442596436,  L-Loss: 503.33315578103065, C-Loss: 258.0986521244049\n",
      "Epoch: 766, Loss: 10297.42499923706,  L-Loss: 492.12947192043066, C-Loss: 257.3125924170017\n",
      "Epoch: 767, Loss: 10178.567928314209,  L-Loss: 349.60232808440924, C-Loss: 254.376797914505\n",
      "Epoch: 768, Loss: 10064.648048400879,  L-Loss: 449.0345599204302, C-Loss: 251.50394189357758\n",
      "Epoch: 769, Loss: 10063.080045700073,  L-Loss: 447.64771519601345, C-Loss: 251.46508914232254\n",
      "Epoch: 770, Loss: 10182.503845214844,  L-Loss: 512.347839102149, C-Loss: 254.43450945615768\n",
      "Epoch: 771, Loss: 9858.406288146973,  L-Loss: 564.6406219005585, C-Loss: 246.31899800896645\n",
      "Epoch: 772, Loss: 9878.52071762085,  L-Loss: 605.9938978254795, C-Loss: 246.81151869893074\n",
      "Epoch: 773, Loss: 10204.87924003601,  L-Loss: 619.5563551709056, C-Loss: 254.9670928120613\n",
      "Epoch: 774, Loss: 10053.651853561401,  L-Loss: 622.6768415272236, C-Loss: 251.1856272816658\n",
      "Epoch: 775, Loss: 10137.655647277832,  L-Loss: 598.2945298999548, C-Loss: 253.29181724786758\n",
      "Epoch: 776, Loss: 10098.252500534058,  L-Loss: 627.6111620441079, C-Loss: 252.29940956830978\n",
      "Epoch: 777, Loss: 9951.18666267395,  L-Loss: 478.4565342217684, C-Loss: 248.66005286574364\n",
      "Epoch: 778, Loss: 10095.22152709961,  L-Loss: 453.0091175213456, C-Loss: 252.26728636026382\n",
      "Epoch: 779, Loss: 9978.594402313232,  L-Loss: 527.7310344427824, C-Loss: 249.33292815089226\n",
      "Epoch: 780, Loss: 10087.393728256226,  L-Loss: 512.196791395545, C-Loss: 252.0567935705185\n",
      "Epoch: 781, Loss: 9997.194919586182,  L-Loss: 560.2841963022947, C-Loss: 249.78980270028114\n",
      "Epoch: 782, Loss: 9926.880319595337,  L-Loss: 559.7680765688419, C-Loss: 248.03206592798233\n",
      "Epoch: 783, Loss: 10158.513946533203,  L-Loss: 745.9022093638778, C-Loss: 253.77637308835983\n",
      "Epoch: 784, Loss: 10251.81995010376,  L-Loss: 643.620199136436, C-Loss: 256.13459450006485\n",
      "Epoch: 785, Loss: 10135.055828094482,  L-Loss: 595.6055805683136, C-Loss: 253.22749388217926\n",
      "Epoch: 786, Loss: 10240.775648117065,  L-Loss: 658.8878416419029, C-Loss: 255.85466945171356\n",
      "Epoch: 787, Loss: 9893.293617248535,  L-Loss: 741.8787276670337, C-Loss: 247.14687168598175\n",
      "Epoch: 788, Loss: 10039.534679412842,  L-Loss: 730.6226068288088, C-Loss: 250.80571195483208\n",
      "Epoch: 789, Loss: 10115.137287139893,  L-Loss: 730.3849791958928, C-Loss: 252.6958359181881\n",
      "Epoch: 790, Loss: 9988.176414489746,  L-Loss: 740.6435060948133, C-Loss: 249.51924920082092\n",
      "Epoch: 791, Loss: 10110.651334762573,  L-Loss: 920.4438598006964, C-Loss: 252.53617250919342\n",
      "Epoch: 792, Loss: 10083.026739120483,  L-Loss: 962.6331324875355, C-Loss: 251.83501052856445\n",
      "Epoch: 793, Loss: 9770.373085021973,  L-Loss: 984.3961512520909, C-Loss: 244.01322799921036\n",
      "Epoch: 794, Loss: 10279.86455154419,  L-Loss: 794.4532879665494, C-Loss: 256.79800021648407\n",
      "Epoch: 795, Loss: 9957.282028198242,  L-Loss: 772.5798750072718, C-Loss: 248.738904774189\n",
      "Epoch: 796, Loss: 10102.754795074463,  L-Loss: 705.9927505105734, C-Loss: 252.39237248897552\n",
      "Epoch: 797, Loss: 10149.525062561035,  L-Loss: 669.4945715591311, C-Loss: 253.57075309753418\n",
      "Epoch: 798, Loss: 10319.579420089722,  L-Loss: 1193.0120192095637, C-Loss: 257.6912323832512\n",
      "Epoch: 799, Loss: 9985.41658782959,  L-Loss: 838.9558459147811, C-Loss: 249.42567586898804\n",
      "Epoch: 800, Loss: 10038.403455734253,  L-Loss: 771.5743383169174, C-Loss: 250.76719325780869\n",
      "Epoch: 801, Loss: 10176.686416625977,  L-Loss: 664.3946250006557, C-Loss: 254.25106137990952\n",
      "Epoch: 802, Loss: 10293.753952026367,  L-Loss: 668.5121033266187, C-Loss: 257.1767213344574\n",
      "Epoch: 803, Loss: 10447.856182098389,  L-Loss: 617.6007231473923, C-Loss: 261.0420038700104\n",
      "Epoch: 804, Loss: 10272.909523010254,  L-Loss: 837.4942845329642, C-Loss: 256.61336475610733\n",
      "Epoch: 805, Loss: 10289.717317581177,  L-Loss: 656.1354036703706, C-Loss: 257.07889997959137\n",
      "Epoch: 806, Loss: 9887.23171043396,  L-Loss: 618.3460934087634, C-Loss: 247.0262057185173\n",
      "Epoch: 807, Loss: 10264.743448257446,  L-Loss: 674.0919945463538, C-Loss: 256.45006358623505\n",
      "Epoch: 808, Loss: 10348.860179901123,  L-Loss: 794.2189363464713, C-Loss: 258.52294921875\n",
      "Epoch: 809, Loss: 10039.259344100952,  L-Loss: 810.4623386412859, C-Loss: 250.77886781096458\n",
      "Epoch: 810, Loss: 10041.548332214355,  L-Loss: 597.8135729655623, C-Loss: 250.88925498723984\n",
      "Epoch: 811, Loss: 10326.944808959961,  L-Loss: 559.4178129583597, C-Loss: 258.0337654352188\n",
      "Epoch: 812, Loss: 10175.283353805542,  L-Loss: 624.6977556422353, C-Loss: 254.22590962052345\n",
      "Epoch: 813, Loss: 10207.217475891113,  L-Loss: 565.2152448520064, C-Loss: 255.03913354873657\n",
      "Epoch: 814, Loss: 10063.501483917236,  L-Loss: 807.1790504157543, C-Loss: 251.38574242591858\n",
      "Epoch: 815, Loss: 10168.629919052124,  L-Loss: 1102.6286583393812, C-Loss: 253.9400907754898\n",
      "Epoch: 816, Loss: 10303.734308242798,  L-Loss: 1063.308423705399, C-Loss: 257.3275306224823\n",
      "Epoch: 817, Loss: 10486.110181808472,  L-Loss: 954.3430883288383, C-Loss: 261.9141678214073\n",
      "Epoch: 818, Loss: 10403.479461669922,  L-Loss: 784.1828639730811, C-Loss: 259.8909400701523\n",
      "Epoch: 819, Loss: 10225.547327041626,  L-Loss: 822.432703115046, C-Loss: 255.43307507038116\n",
      "Epoch: 820, Loss: 10342.213693618774,  L-Loss: 892.0341100990772, C-Loss: 258.3323341012001\n",
      "Epoch: 821, Loss: 10551.868293762207,  L-Loss: 1006.2727612704039, C-Loss: 263.545139670372\n",
      "Epoch: 822, Loss: 10665.816045761108,  L-Loss: 772.605768956244, C-Loss: 266.4522490501404\n",
      "Epoch: 823, Loss: 10151.528907775879,  L-Loss: 995.3167285248637, C-Loss: 253.53939360380173\n",
      "Epoch: 824, Loss: 10160.588529586792,  L-Loss: 886.6559360399842, C-Loss: 253.7930493056774\n",
      "Epoch: 825, Loss: 10354.350988388062,  L-Loss: 821.5424614176154, C-Loss: 258.6533891558647\n",
      "Epoch: 826, Loss: 10106.057262420654,  L-Loss: 946.7197457104921, C-Loss: 252.41475173830986\n",
      "Epoch: 827, Loss: 10139.65294265747,  L-Loss: 1045.6635332405567, C-Loss: 253.22990745306015\n",
      "Epoch: 828, Loss: 10166.849657058716,  L-Loss: 1216.5005527734756, C-Loss: 253.86711645126343\n",
      "Epoch: 829, Loss: 9893.042999267578,  L-Loss: 1196.4491026550531, C-Loss: 247.02696320414543\n",
      "Epoch: 830, Loss: 10101.006977081299,  L-Loss: 1213.4660968482494, C-Loss: 252.22180730104446\n",
      "Epoch: 831, Loss: 10273.021675109863,  L-Loss: 1444.1421821415424, C-Loss: 256.46450597047806\n",
      "Epoch: 832, Loss: 10329.622512817383,  L-Loss: 1670.0908048823476, C-Loss: 257.82304018735886\n",
      "Epoch: 833, Loss: 10243.867679595947,  L-Loss: 1598.8985290005803, C-Loss: 255.69696789979935\n",
      "Epoch: 834, Loss: 9631.197786331177,  L-Loss: 1471.4517708346248, C-Loss: 240.41208073496819\n",
      "Epoch: 835, Loss: 10168.863859176636,  L-Loss: 1325.2423322424293, C-Loss: 253.8902845978737\n",
      "Epoch: 836, Loss: 10189.372701644897,  L-Loss: 1608.1306278929114, C-Loss: 254.3322845697403\n",
      "Epoch: 837, Loss: 10072.393419265747,  L-Loss: 1680.5362667441368, C-Loss: 251.38970029354095\n",
      "Epoch: 838, Loss: 10243.970027923584,  L-Loss: 1578.9510648027062, C-Loss: 255.7045128941536\n",
      "Epoch: 839, Loss: 10176.147706985474,  L-Loss: 1722.0661779493093, C-Loss: 253.9731758236885\n",
      "Epoch: 840, Loss: 9904.838274002075,  L-Loss: 1506.4646409153938, C-Loss: 247.24434053897858\n",
      "Epoch: 841, Loss: 10011.389129638672,  L-Loss: 1535.9590187445283, C-Loss: 249.9007384479046\n",
      "Epoch: 842, Loss: 10097.59803199768,  L-Loss: 1369.7957778722048, C-Loss: 252.0975027680397\n",
      "Epoch: 843, Loss: 9800.444723129272,  L-Loss: 1666.9865217655897, C-Loss: 244.59437149763107\n",
      "Epoch: 844, Loss: 10132.550832748413,  L-Loss: 1424.0985928326845, C-Loss: 252.9577458500862\n",
      "Epoch: 845, Loss: 10174.124526977539,  L-Loss: 1531.262201063335, C-Loss: 253.97029781341553\n",
      "Epoch: 846, Loss: 10106.739095687866,  L-Loss: 1379.3960265815258, C-Loss: 252.32362842559814\n",
      "Epoch: 847, Loss: 10202.1042137146,  L-Loss: 1108.0153505206108, C-Loss: 254.7756010890007\n",
      "Epoch: 848, Loss: 10388.117395401001,  L-Loss: 1299.6493325009942, C-Loss: 259.3780221939087\n",
      "Epoch: 849, Loss: 10187.725099563599,  L-Loss: 1140.514908619225, C-Loss: 254.40799874067307\n",
      "Epoch: 850, Loss: 9908.765857696533,  L-Loss: 1456.7311385646462, C-Loss: 247.35496467351913\n",
      "Epoch: 851, Loss: 10321.031297683716,  L-Loss: 1325.6670991033316, C-Loss: 257.6943665742874\n",
      "Epoch: 852, Loss: 10123.005056381226,  L-Loss: 1321.4378547668457, C-Loss: 252.7447674870491\n",
      "Epoch: 853, Loss: 9983.936443328857,  L-Loss: 1324.740653194487, C-Loss: 249.26722556352615\n",
      "Epoch: 854, Loss: 10376.430603027344,  L-Loss: 1464.8318905755877, C-Loss: 259.0445569753647\n",
      "Epoch: 855, Loss: 9923.867956161499,  L-Loss: 1336.2346928939223, C-Loss: 247.76264044642448\n",
      "Epoch: 856, Loss: 10166.224128723145,  L-Loss: 1215.4773198068142, C-Loss: 253.85173380374908\n",
      "Epoch: 857, Loss: 9996.01932144165,  L-Loss: 1185.93110409379, C-Loss: 249.60400021076202\n",
      "Epoch: 858, Loss: 9959.09766960144,  L-Loss: 1655.8186628296971, C-Loss: 248.56348687410355\n",
      "Epoch: 859, Loss: 10184.465656280518,  L-Loss: 1306.0233375281096, C-Loss: 254.28513604402542\n",
      "Epoch: 860, Loss: 9976.05898475647,  L-Loss: 1559.910566791892, C-Loss: 249.01149666309357\n",
      "Epoch: 861, Loss: 10275.898937225342,  L-Loss: 1463.9989612326026, C-Loss: 256.5314739346504\n",
      "Epoch: 862, Loss: 10001.182529449463,  L-Loss: 979.7604436501861, C-Loss: 249.78462320566177\n",
      "Epoch: 863, Loss: 9964.808673858643,  L-Loss: 1105.3434952870011, C-Loss: 248.84388089179993\n",
      "Epoch: 864, Loss: 9843.35479927063,  L-Loss: 1028.8884848281741, C-Loss: 245.8266485631466\n",
      "Epoch: 865, Loss: 10044.13868522644,  L-Loss: 1033.6561959385872, C-Loss: 250.8450523018837\n",
      "Epoch: 866, Loss: 10012.121318817139,  L-Loss: 999.3488727658987, C-Loss: 250.05319517850876\n",
      "Epoch: 867, Loss: 10203.417881011963,  L-Loss: 1227.0630088150501, C-Loss: 254.77868074178696\n",
      "Epoch: 868, Loss: 9983.198637008667,  L-Loss: 971.544628828764, C-Loss: 249.33707949519157\n",
      "Epoch: 869, Loss: 10099.376304626465,  L-Loss: 977.7548068165779, C-Loss: 252.23996949195862\n",
      "Epoch: 870, Loss: 10262.420658111572,  L-Loss: 938.2362102046609, C-Loss: 256.3259572982788\n",
      "Epoch: 871, Loss: 9999.320693969727,  L-Loss: 895.2024380713701, C-Loss: 249.75921660661697\n",
      "Epoch: 872, Loss: 10030.79299736023,  L-Loss: 839.7622036859393, C-Loss: 250.55988430976868\n",
      "Epoch: 873, Loss: 10050.830131530762,  L-Loss: 792.0128362178802, C-Loss: 251.07275059819221\n",
      "Epoch: 874, Loss: 10078.66189956665,  L-Loss: 760.9805833026767, C-Loss: 251.77630192041397\n",
      "Epoch: 875, Loss: 10028.652057647705,  L-Loss: 1072.1215218529105, C-Loss: 250.44827061891556\n",
      "Epoch: 876, Loss: 10054.344047546387,  L-Loss: 1404.2512821778655, C-Loss: 251.00753849744797\n",
      "Epoch: 877, Loss: 9858.2779006958,  L-Loss: 1604.533255085349, C-Loss: 246.05581390857697\n",
      "Epoch: 878, Loss: 9780.88939666748,  L-Loss: 1180.1259864792228, C-Loss: 244.22720223665237\n",
      "Epoch: 879, Loss: 9845.633743286133,  L-Loss: 896.2026305347681, C-Loss: 245.91679269075394\n",
      "Epoch: 880, Loss: 10032.86929321289,  L-Loss: 1173.2832002714276, C-Loss: 250.52841067314148\n",
      "Epoch: 881, Loss: 10174.063438415527,  L-Loss: 1098.6370197832584, C-Loss: 254.0769270658493\n",
      "Epoch: 882, Loss: 9881.750980377197,  L-Loss: 1021.9695183038712, C-Loss: 246.7882821559906\n",
      "Epoch: 883, Loss: 10291.316972732544,  L-Loss: 930.4017859399319, C-Loss: 257.0503237247467\n",
      "Epoch: 884, Loss: 10427.30513381958,  L-Loss: 1286.1185105741024, C-Loss: 260.3610983490944\n",
      "Epoch: 885, Loss: 9795.172994613647,  L-Loss: 1119.0368131622672, C-Loss: 244.59956562519073\n",
      "Epoch: 886, Loss: 10022.902978897095,  L-Loss: 1009.3647406324744, C-Loss: 250.3202327489853\n",
      "Epoch: 887, Loss: 10021.047193527222,  L-Loss: 1063.1654163375497, C-Loss: 250.26038825511932\n",
      "Epoch: 888, Loss: 9666.727544784546,  L-Loss: 1571.814693018794, C-Loss: 241.2752347290516\n",
      "Epoch: 889, Loss: 9991.727684020996,  L-Loss: 1856.33896189183, C-Loss: 249.3291067481041\n",
      "Epoch: 890, Loss: 9930.903427124023,  L-Loss: 1764.2187246456742, C-Loss: 247.83153066039085\n",
      "Epoch: 891, Loss: 10007.712882995605,  L-Loss: 1774.138717211783, C-Loss: 249.74928748607635\n",
      "Epoch: 892, Loss: 9840.181079864502,  L-Loss: 1770.1951399743557, C-Loss: 245.56197839975357\n",
      "Epoch: 893, Loss: 9973.924253463745,  L-Loss: 1419.1924826800823, C-Loss: 248.9933089017868\n",
      "Epoch: 894, Loss: 9993.126829147339,  L-Loss: 1408.1004805639386, C-Loss: 249.47614508867264\n",
      "Epoch: 895, Loss: 10235.898761749268,  L-Loss: 1213.3155058175325, C-Loss: 255.59413993358612\n",
      "Epoch: 896, Loss: 9783.40627670288,  L-Loss: 1371.8750154674053, C-Loss: 244.2421889603138\n",
      "Epoch: 897, Loss: 9889.447584152222,  L-Loss: 1683.6414586901665, C-Loss: 246.81527897715569\n",
      "Epoch: 898, Loss: 9840.670732498169,  L-Loss: 1579.3954318910837, C-Loss: 245.62191951274872\n",
      "Epoch: 899, Loss: 10161.49513053894,  L-Loss: 1386.859857454896, C-Loss: 253.69066348671913\n",
      "Epoch: 900, Loss: 10298.48257446289,  L-Loss: 1253.1019313186407, C-Loss: 257.1487894654274\n",
      "Epoch: 901, Loss: 9835.412593841553,  L-Loss: 1140.1328200101852, C-Loss: 245.60028186440468\n",
      "Epoch: 902, Loss: 9645.877738952637,  L-Loss: 1310.5301759019494, C-Loss: 240.8193103671074\n",
      "Epoch: 903, Loss: 9886.082818984985,  L-Loss: 1161.1112360060215, C-Loss: 246.86179339885712\n",
      "Epoch: 904, Loss: 10277.599405288696,  L-Loss: 1063.030766710639, C-Loss: 256.67422765493393\n",
      "Epoch: 905, Loss: 10294.948036193848,  L-Loss: 1166.190087273717, C-Loss: 257.08215314149857\n",
      "Epoch: 906, Loss: 9939.18981552124,  L-Loss: 1103.731375105679, C-Loss: 248.20381289720535\n",
      "Epoch: 907, Loss: 9778.669401168823,  L-Loss: 1585.43875131011, C-Loss: 244.07037490606308\n",
      "Epoch: 908, Loss: 9738.247465133667,  L-Loss: 1443.5942852124572, C-Loss: 243.0952875316143\n",
      "Epoch: 909, Loss: 10182.158569335938,  L-Loss: 1309.9451250359416, C-Loss: 254.22647893428802\n",
      "Epoch: 910, Loss: 10376.857080459595,  L-Loss: 1119.3580678328872, C-Loss: 259.14158684015274\n",
      "Epoch: 911, Loss: 10267.655456542969,  L-Loss: 1068.703374631703, C-Loss: 256.4242109656334\n",
      "Epoch: 912, Loss: 9807.489337921143,  L-Loss: 1144.5760186389089, C-Loss: 244.9010889530182\n",
      "Epoch: 913, Loss: 9949.616847991943,  L-Loss: 1260.6394432634115, C-Loss: 248.4252606332302\n",
      "Epoch: 914, Loss: 9910.533075332642,  L-Loss: 1096.673540867865, C-Loss: 247.4891586303711\n",
      "Epoch: 915, Loss: 10141.804761886597,  L-Loss: 1147.4145559072495, C-Loss: 253.25826621055603\n",
      "Epoch: 916, Loss: 10031.551574707031,  L-Loss: 1074.6858854591846, C-Loss: 250.52011728286743\n",
      "Epoch: 917, Loss: 10071.100498199463,  L-Loss: 937.8364726305008, C-Loss: 251.54305332899094\n",
      "Epoch: 918, Loss: 9946.704040527344,  L-Loss: 1169.5206680446863, C-Loss: 248.37522119283676\n",
      "Epoch: 919, Loss: 9750.398777008057,  L-Loss: 1629.133832424879, C-Loss: 243.35268598794937\n",
      "Epoch: 920, Loss: 9955.781791687012,  L-Loss: 1349.1614178419113, C-Loss: 248.55725473165512\n",
      "Epoch: 921, Loss: 10053.19835472107,  L-Loss: 1382.4975668340921, C-Loss: 250.98433429002762\n",
      "Epoch: 922, Loss: 10048.60597038269,  L-Loss: 1681.809508934617, C-Loss: 250.7946968972683\n",
      "Epoch: 923, Loss: 10267.082675933838,  L-Loss: 1611.0334417670965, C-Loss: 256.27430868148804\n",
      "Epoch: 924, Loss: 9986.142412185669,  L-Loss: 1866.1565661877394, C-Loss: 249.1870213150978\n",
      "Epoch: 925, Loss: 9911.834224700928,  L-Loss: 1822.5232499316335, C-Loss: 247.3402247428894\n",
      "Epoch: 926, Loss: 9897.48204421997,  L-Loss: 1898.4452335238457, C-Loss: 246.96244037151337\n",
      "Epoch: 927, Loss: 10098.43702507019,  L-Loss: 1892.6145010739565, C-Loss: 251.98777228593826\n",
      "Epoch: 928, Loss: 9733.308736801147,  L-Loss: 2401.25010111928, C-Loss: 242.7324056327343\n",
      "Epoch: 929, Loss: 10148.27124595642,  L-Loss: 2269.739134386182, C-Loss: 253.139346241951\n",
      "Epoch: 930, Loss: 10149.374465942383,  L-Loss: 1478.454905718565, C-Loss: 253.3647479712963\n",
      "Epoch: 931, Loss: 9715.900735855103,  L-Loss: 1455.0668472871184, C-Loss: 242.5337510406971\n",
      "Epoch: 932, Loss: 10165.939004898071,  L-Loss: 1183.5927129983902, C-Loss: 253.8525768518448\n",
      "Epoch: 933, Loss: 9925.090259552002,  L-Loss: 1272.9017117321491, C-Loss: 247.80903106927872\n",
      "Epoch: 934, Loss: 9909.678392410278,  L-Loss: 1620.5400091037154, C-Loss: 247.33682507276535\n",
      "Epoch: 935, Loss: 10085.419746398926,  L-Loss: 1351.9433362036943, C-Loss: 251.79750734567642\n",
      "Epoch: 936, Loss: 10063.733001708984,  L-Loss: 1269.426141358912, C-Loss: 251.27596899867058\n",
      "Epoch: 937, Loss: 10178.463603973389,  L-Loss: 1075.480378843844, C-Loss: 254.19272005558014\n",
      "Epoch: 938, Loss: 9769.632822036743,  L-Loss: 1053.965144611895, C-Loss: 243.9773292541504\n",
      "Epoch: 939, Loss: 10117.506790161133,  L-Loss: 1167.557500332594, C-Loss: 252.64578068256378\n",
      "Epoch: 940, Loss: 9837.621084213257,  L-Loss: 1038.240113966167, C-Loss: 245.68096661567688\n",
      "Epoch: 941, Loss: 10072.294034957886,  L-Loss: 1089.769897222519, C-Loss: 251.5349086523056\n",
      "Epoch: 942, Loss: 10516.785234451294,  L-Loss: 983.706446647644, C-Loss: 262.67370438575745\n",
      "Epoch: 943, Loss: 10170.819396972656,  L-Loss: 1713.6432162374258, C-Loss: 253.84207457304\n",
      "Epoch: 944, Loss: 9977.560152053833,  L-Loss: 1536.6638441383839, C-Loss: 249.0548379123211\n",
      "Epoch: 945, Loss: 9887.437213897705,  L-Loss: 1714.1969272494316, C-Loss: 246.75738048553467\n",
      "Epoch: 946, Loss: 9885.366525650024,  L-Loss: 2110.3665991798043, C-Loss: 246.60657227039337\n",
      "Epoch: 947, Loss: 10356.051586151123,  L-Loss: 2109.2447054609656, C-Loss: 258.3739787340164\n",
      "Epoch: 948, Loss: 9992.502052307129,  L-Loss: 1827.2907442227006, C-Loss: 249.35572960972786\n",
      "Epoch: 949, Loss: 10027.129661560059,  L-Loss: 1850.8078156039119, C-Loss: 250.21553951501846\n",
      "Epoch: 950, Loss: 9890.799556732178,  L-Loss: 1294.5419172346592, C-Loss: 246.94635313749313\n",
      "Epoch: 951, Loss: 9793.632846832275,  L-Loss: 1248.2944022119045, C-Loss: 244.52874746918678\n",
      "Epoch: 952, Loss: 10010.059617996216,  L-Loss: 1278.1437573954463, C-Loss: 249.93195429444313\n",
      "Epoch: 953, Loss: 9716.536273956299,  L-Loss: 1234.3836983144283, C-Loss: 242.60481068491936\n",
      "Epoch: 954, Loss: 10161.304698944092,  L-Loss: 2101.966434419155, C-Loss: 253.5071257352829\n",
      "Epoch: 955, Loss: 9829.153909683228,  L-Loss: 3035.5909770280123, C-Loss: 244.96994996070862\n",
      "Epoch: 956, Loss: 9997.678470611572,  L-Loss: 2109.1123292520642, C-Loss: 249.41468387842178\n",
      "Epoch: 957, Loss: 10062.425401687622,  L-Loss: 2379.922371610999, C-Loss: 250.965654194355\n",
      "Epoch: 958, Loss: 10029.086938858032,  L-Loss: 2060.0909142121673, C-Loss: 250.21215039491653\n",
      "Epoch: 959, Loss: 10017.267654418945,  L-Loss: 1994.535112902522, C-Loss: 249.9330574274063\n",
      "Epoch: 960, Loss: 9913.686624526978,  L-Loss: 2452.8849267214537, C-Loss: 247.22894477844238\n",
      "Epoch: 961, Loss: 10223.337562561035,  L-Loss: 2569.1633761897683, C-Loss: 254.9411482810974\n",
      "Epoch: 962, Loss: 10198.324991226196,  L-Loss: 3075.7049993872643, C-Loss: 254.18919810652733\n",
      "Epoch: 963, Loss: 9729.64694595337,  L-Loss: 2924.9181370288134, C-Loss: 242.50994420051575\n",
      "Epoch: 964, Loss: 10082.269289016724,  L-Loss: 2367.560845144093, C-Loss: 251.4648420214653\n",
      "Epoch: 965, Loss: 9709.039512634277,  L-Loss: 2229.6503400951624, C-Loss: 242.1685747206211\n",
      "Epoch: 966, Loss: 9935.264488220215,  L-Loss: 1660.774231813848, C-Loss: 247.96641850471497\n",
      "Epoch: 967, Loss: 9701.794816970825,  L-Loss: 2176.8900350928307, C-Loss: 242.00064808130264\n",
      "Epoch: 968, Loss: 9911.376230239868,  L-Loss: 2169.3818655088544, C-Loss: 247.2420598268509\n",
      "Epoch: 969, Loss: 9749.327253341675,  L-Loss: 1795.1645407155156, C-Loss: 243.28438955545425\n",
      "Epoch: 970, Loss: 9816.864833831787,  L-Loss: 1848.9464712515473, C-Loss: 244.9593841433525\n",
      "Epoch: 971, Loss: 10138.384447097778,  L-Loss: 2316.33831589669, C-Loss: 252.88052713871002\n",
      "Epoch: 972, Loss: 10010.135906219482,  L-Loss: 2475.402849085629, C-Loss: 249.63454711437225\n",
      "Epoch: 973, Loss: 10322.295888900757,  L-Loss: 2277.920413926244, C-Loss: 257.487918227911\n",
      "Epoch: 974, Loss: 9988.899263381958,  L-Loss: 2140.6641592383385, C-Loss: 249.18731525540352\n",
      "Epoch: 975, Loss: 9882.239505767822,  L-Loss: 1777.0086323991418, C-Loss: 246.61173537373543\n",
      "Epoch: 976, Loss: 9824.820499420166,  L-Loss: 1624.3471449166536, C-Loss: 245.21442571282387\n",
      "Epoch: 977, Loss: 9925.498056411743,  L-Loss: 1549.3425460457802, C-Loss: 247.7501162290573\n",
      "Epoch: 978, Loss: 10075.484930038452,  L-Loss: 1500.5110449939966, C-Loss: 251.5119953751564\n",
      "Epoch: 979, Loss: 10230.777770996094,  L-Loss: 1684.716893836856, C-Loss: 255.34826496243477\n",
      "Epoch: 980, Loss: 9983.780990600586,  L-Loss: 1828.259648039937, C-Loss: 249.13745975494385\n",
      "Epoch: 981, Loss: 9872.451997756958,  L-Loss: 1348.43149253726, C-Loss: 246.4741925895214\n",
      "Epoch: 982, Loss: 10402.501892089844,  L-Loss: 1072.370012871921, C-Loss: 259.7944552898407\n",
      "Epoch: 983, Loss: 10098.48804473877,  L-Loss: 1466.000137731433, C-Loss: 252.09570109844208\n",
      "Epoch: 984, Loss: 9979.985921859741,  L-Loss: 1784.2463543713093, C-Loss: 249.05358666181564\n",
      "Epoch: 985, Loss: 10001.870546340942,  L-Loss: 1525.3849662095308, C-Loss: 249.66541665792465\n",
      "Epoch: 986, Loss: 10106.70824432373,  L-Loss: 1445.9945385828614, C-Loss: 252.3062065243721\n",
      "Epoch: 987, Loss: 10133.01986694336,  L-Loss: 1322.4788933694363, C-Loss: 252.99487680196762\n",
      "Epoch: 988, Loss: 10036.316297531128,  L-Loss: 1325.8018821403384, C-Loss: 250.57645750045776\n",
      "Epoch: 989, Loss: 9837.409942626953,  L-Loss: 1813.1110931187868, C-Loss: 245.4819706082344\n",
      "Epoch: 990, Loss: 9710.288919448853,  L-Loss: 1935.2501013502479, C-Loss: 242.27341067790985\n",
      "Epoch: 991, Loss: 10040.642377853394,  L-Loss: 1617.5012021139264, C-Loss: 250.61168390512466\n",
      "Epoch: 992, Loss: 10018.002027511597,  L-Loss: 1834.3373945578933, C-Loss: 249.99146643280983\n",
      "Epoch: 993, Loss: 10031.719026565552,  L-Loss: 1836.3939577192068, C-Loss: 250.33387780189514\n",
      "Epoch: 994, Loss: 10093.262340545654,  L-Loss: 2198.5908246934414, C-Loss: 251.7819104194641\n",
      "Epoch: 995, Loss: 10291.09133720398,  L-Loss: 2898.070152491331, C-Loss: 256.5527660250664\n",
      "Epoch: 996, Loss: 9892.912637710571,  L-Loss: 1939.9278528243303, C-Loss: 246.83783403038979\n",
      "Epoch: 997, Loss: 9870.107454299927,  L-Loss: 2250.418075442314, C-Loss: 246.19008177518845\n",
      "Epoch: 998, Loss: 10132.90075302124,  L-Loss: 2017.5163817033172, C-Loss: 252.81814020872116\n",
      "Epoch: 999, Loss: 10184.754022598267,  L-Loss: 1899.9243698269129, C-Loss: 254.14386969804764\n",
      "Epoch: 1000, Loss: 9842.580404281616,  L-Loss: 2403.12810626626, C-Loss: 245.46372812986374\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training!\")\n",
    "best_loss = np.infty\n",
    "for epoch in range(num_epochs+1): \n",
    "    # Training.\n",
    "    net.train()\n",
    "    loss_tracker = 0.0\n",
    "    latent_loss_tracker = 0.0\n",
    "    cor_loss_tracker = 0.0\n",
    "    for x, y in train_dataloader:\n",
    "        optimizer.zero_grad()      \n",
    "\n",
    "        # Pass x, y to network. Retrieve both encodings, and decoding of ys encoding.\n",
    "        fx_x, fe_y, fd_z = net(x, y)\n",
    "        # Calc loss.\n",
    "        l_loss, c_loss = net.losses(fx_x, fe_y, fd_z, y)\n",
    "        # Normalize losses by batch.\n",
    "        l_loss /= x.shape[0]\n",
    "        c_loss /= x.shape[0]\n",
    "        loss = net.beta*l_loss + net.alpha*c_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_tracker+=loss.item()\n",
    "        latent_loss_tracker+=l_loss.item()\n",
    "        cor_loss_tracker+=c_loss.item()\n",
    "    writer.add_scalar('train/loss', loss_tracker, epoch)\n",
    "    writer.add_scalar('train/latent_loss', latent_loss_tracker, epoch)\n",
    "    writer.add_scalar('train/corr_loss', cor_loss_tracker, epoch)\n",
    "    \n",
    "    # Evaluation\n",
    "    net.eval()\n",
    "    loss_tracker = 0.0\n",
    "    latent_loss_tracker = 0.0\n",
    "    cor_loss_tracker = 0.0\n",
    "    acc_track = 0.0\n",
    "    for x, y in test_dataloader:\n",
    "        # evaluation only requires x. As its just Fd(Fx(x))\n",
    "        fx_x, fe_y = net.Fx(x), net.Fe(y)\n",
    "        fd_z = net.Fd(fx_x)\n",
    "\n",
    "        l_loss, c_loss = net.losses(fx_x, fe_y, fd_z, y)\n",
    "        # Normalize losses by batch.\n",
    "        l_loss /= x.shape[0]\n",
    "        c_loss /= x.shape[0]\n",
    "        loss = net.beta*l_loss + net.alpha*c_loss\n",
    "        \n",
    "        latent_loss_tracker += l_loss.item()\n",
    "        cor_loss_tracker += c_loss.item()\n",
    "        loss_tracker += loss.item()\n",
    "        lab_preds = torch.round(net.Fd(net.Fx(x))).cpu().detach().numpy()\n",
    "        \n",
    "    print(f\"Epoch: {epoch}, Loss: {loss_tracker},  L-Loss: {latent_loss_tracker}, C-Loss: {cor_loss_tracker}\")\n",
    "    torch.save(net.state_dict(), f'./models/mediamill/c2ae/v4_2{epoch}.pt')\n",
    "    writer.add_scalar('val/loss', loss_tracker, epoch)\n",
    "    writer.add_scalar('val/latent_loss', latent_loss_tracker, epoch)\n",
    "    writer.add_scalar('val/corr_loss', cor_loss_tracker, epoch)\n",
    "    \n",
    "    # Log metrics on whole dataset.\n",
    "    mets = eval_metrics(net, [ham_los, accuracy_score, micro_f1, micro_p, micro_r, macro_f1, macro_p, macro_r], \n",
    "                        [test_dataset, train_dataset], torch.device('cuda'))\n",
    "    for k, v in mets['dataset_1'].items():\n",
    "        writer.add_scalar(f'train/{k}', v, epoch)\n",
    "    for k, v in mets['dataset_0'].items():\n",
    "        writer.add_scalar(f'val/{k}', v, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picking best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_net = load_model(C2AE, './models/mediamill/c2ae/v4_2950.pt', Fx=Fx_tmc, Fe=Fe_tmc, Fd=Fd_tmc, device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_0': {'ham_los': 0.03430385628000619,\n",
       "  'accuracy_score': 0.07573176397707913,\n",
       "  'micro_f1': 0.5826874469533748,\n",
       "  'micro_p': 0.620816440098577,\n",
       "  'micro_r': 0.5489710198414791,\n",
       "  'macro_f1': 0.1278815755808191,\n",
       "  'macro_p': 0.21369858766535993,\n",
       "  'macro_r': 0.11195772712532844},\n",
       " 'dataset_1': {'ham_los': 0.030500020285640993,\n",
       "  'accuracy_score': 0.09515051785887135,\n",
       "  'micro_f1': 0.6269701729298044,\n",
       "  'micro_p': 0.6646013667425968,\n",
       "  'micro_r': 0.5933721351605198,\n",
       "  'macro_f1': 0.1810227401352932,\n",
       "  'macro_p': 0.3406434281722783,\n",
       "  'macro_r': 0.15087116899792413}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mets = eval_metrics(eval_net, [ham_los, accuracy_score, micro_f1, micro_p, micro_r, macro_f1, macro_p, macro_r], [test_dataset, train_dataset], device)\n",
    "mets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_net = load_model(C2AE, './models/mediamill/c2ae/v4_2430.pt', Fx=Fx_tmc, Fe=Fe_tmc, Fd=Fd_tmc, device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_0': {'ham_los': 0.031299978379439305,\n",
       "  'accuracy_score': 0.08432708688245315,\n",
       "  'micro_f1': 0.5695608624598029,\n",
       "  'micro_p': 0.7118384988403964,\n",
       "  'micro_r': 0.47468410045517656,\n",
       "  'macro_f1': 0.10003849766216992,\n",
       "  'macro_p': 0.19545522979837945,\n",
       "  'macro_r': 0.07995643575974129},\n",
       " 'dataset_1': {'ham_los': 0.029350926574605,\n",
       "  'accuracy_score': 0.08508372858387378,\n",
       "  'micro_f1': 0.5964554738113539,\n",
       "  'micro_p': 0.7343766899565208,\n",
       "  'micro_r': 0.5021483985001886,\n",
       "  'macro_f1': 0.14216146757861564,\n",
       "  'macro_p': 0.3395320937990518,\n",
       "  'macro_r': 0.10828125431332984}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mets = eval_metrics(eval_net, [ham_los, accuracy_score, micro_f1, micro_p, micro_r, macro_f1, macro_p, macro_r], [test_dataset, train_dataset], device)\n",
    "mets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
