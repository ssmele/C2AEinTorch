{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C2AE Architecture\n",
    "* X:\n",
    "    * (N, d)\n",
    "* Y:\n",
    "    * (N, m)\n",
    "* Z:\n",
    "    * (N, l)\n",
    "\n",
    "## Three main components:\n",
    "* Fx:\n",
    "    * Encodes x into latent space z.\n",
    "* Fe:\n",
    "    * Encodes y into latent space z.\n",
    "* Fd:\n",
    "    * Decodes z into label space. \n",
    "\n",
    "## Loss functions:\n",
    "\n",
    "$$L_1 = ||F_x(X) - F_e(Y)||^2 s.t. F_x(X)Fx(X)^T = F_e(Y)F_e(Y)^T = I$$\n",
    "$$L_2 = \\Gamma(F_e, F_d) = \\Sigma_i^N E_i$$\n",
    "$$E_i = \\frac{1}{|y_i^1||y_i^0|} \\Sigma_{p,q \\in y_i^1\\times y_i^0} e^{F_d(F_e(y_i))^q - F_d(F_e(y_I))^p}$$\n",
    "\n",
    "## Combined Loss:\n",
    "$$L_1 + \\alpha L_2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from C2AE import C2AE, save_model, load_model, Fe, Fx, Fd, eval_metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import hamming_loss, accuracy_score, f1_score, precision_score, recall_score\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from skmultilearn.dataset import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene:train - exists, not redownloading\n",
      "scene:test - exists, not redownloading\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "train_x, train_y, feat_names, label_names = load_dataset('scene', 'train')\n",
    "test_x, test_y, _, _ = load_dataset('scene', 'test')\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(train_x.todense(), device=device, dtype=torch.float),torch.tensor(train_y.todense(), device=device,dtype=torch.float))\n",
    "test_dataset = TensorDataset(torch.tensor(test_x.todense(), device=device, dtype=torch.float), torch.tensor(test_y.todense(), device=device, dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1211, 294]),\n",
       " torch.Size([1211, 6]),\n",
       " torch.Size([1196, 294]),\n",
       " torch.Size([1196, 6]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[:][0].shape, train_dataset[:][1].shape, test_dataset[:][0].shape, test_dataset[:][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def micro_r(y_t, y_p):\n",
    "    return recall_score(y_t, y_p, average='micro')\n",
    "def macro_r(y_t, y_p):\n",
    "    return recall_score(y_t, y_p, average='macro')\n",
    "def micro_p(y_t, y_p):\n",
    "    return precision_score(y_t, y_p, average='micro')\n",
    "def macro_p(y_t, y_p):\n",
    "    return precision_score(y_t, y_p, average='macro')\n",
    "def micro_f1(y_t, y_p):\n",
    "    return f1_score(y_t, y_p, average='micro')\n",
    "def macro_f1(y_t, y_p):\n",
    "    return f1_score(y_t, y_p, average='macro')\n",
    "def ham_los(*args, **kwargs):\n",
    "    return hamming_loss(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configs.\n",
    "num_epochs = 1000\n",
    "batch_size = 32\n",
    "lr = 0.001\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# # Scene config\n",
    "feat_dim = 294\n",
    "latent_dim = 5\n",
    "num_labels = 6\n",
    "fx_h_dim=20\n",
    "fe_h_dim=20\n",
    "fd_h_dim=50\n",
    "\n",
    "# Scene models.\n",
    "Fx_scene = Fx(feat_dim, fx_h_dim, fx_h_dim, latent_dim)\n",
    "Fe_scene = Fe(num_labels, fe_h_dim, latent_dim)\n",
    "Fd_scene = Fd(latent_dim, fd_h_dim, num_labels, fin_act=torch.sigmoid)\n",
    "               \n",
    "# Initializing net.\n",
    "net = C2AE(Fx_scene, Fe_scene, Fd_scene, beta=0.5, alpha=10, emb_lambda=0.01, latent_dim=latent_dim, device=device)\n",
    "net = net.to(device)\n",
    "\n",
    "\n",
    "# Doing weight_decay here is eqiv to adding the L2 norm.\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "writer = SummaryWriter(comment='scene-c2ae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training!\n",
      "Epoch: 0, Loss: 383.4921340942383,  L-Loss: 3.1638980265706778, C-Loss: 38.19101822376251\n",
      "Epoch: 1, Loss: 382.1139135360718,  L-Loss: 1.6566793415695429, C-Loss: 38.128557562828064\n",
      "Epoch: 2, Loss: 382.2040843963623,  L-Loss: 3.001723300665617, C-Loss: 38.07032233476639\n",
      "Epoch: 3, Loss: 382.06808853149414,  L-Loss: 4.195376731455326, C-Loss: 37.997039914131165\n",
      "Epoch: 4, Loss: 382.2564105987549,  L-Loss: 5.8342824429273605, C-Loss: 37.933926820755005\n",
      "Epoch: 5, Loss: 384.197003364563,  L-Loss: 10.322519063949585, C-Loss: 37.90357440710068\n",
      "Epoch: 6, Loss: 386.89673137664795,  L-Loss: 16.923314929008484, C-Loss: 37.84350764751434\n",
      "Epoch: 7, Loss: 388.9680995941162,  L-Loss: 23.168397426605225, C-Loss: 37.738390266895294\n",
      "Epoch: 8, Loss: 392.5284299850464,  L-Loss: 28.516899675130844, C-Loss: 37.82699805498123\n",
      "Epoch: 9, Loss: 392.86380100250244,  L-Loss: 33.38949924707413, C-Loss: 37.616905093193054\n",
      "Epoch: 10, Loss: 394.351601600647,  L-Loss: 37.51728665828705, C-Loss: 37.5592964887619\n",
      "Epoch: 11, Loss: 388.8541965484619,  L-Loss: 37.4777769446373, C-Loss: 37.01153016090393\n",
      "Epoch: 12, Loss: 383.1205358505249,  L-Loss: 37.19368386268616, C-Loss: 36.45236939191818\n",
      "Epoch: 13, Loss: 377.864821434021,  L-Loss: 36.442707896232605, C-Loss: 35.96434676647186\n",
      "Epoch: 14, Loss: 370.08444118499756,  L-Loss: 33.92530560493469, C-Loss: 35.3121782541275\n",
      "Epoch: 15, Loss: 368.1753797531128,  L-Loss: 33.019415110349655, C-Loss: 35.16656756401062\n",
      "Epoch: 16, Loss: 367.8781261444092,  L-Loss: 32.61343976855278, C-Loss: 35.15714055299759\n",
      "Epoch: 17, Loss: 366.2989730834961,  L-Loss: 30.686733901500702, C-Loss: 35.09556061029434\n",
      "Epoch: 18, Loss: 359.95451307296753,  L-Loss: 30.077077955007553, C-Loss: 34.49159723520279\n",
      "Epoch: 19, Loss: 353.11154651641846,  L-Loss: 27.9255194067955, C-Loss: 33.91487890481949\n",
      "Epoch: 20, Loss: 348.4367084503174,  L-Loss: 26.52810761332512, C-Loss: 33.517265141010284\n",
      "Epoch: 21, Loss: 345.1799545288086,  L-Loss: 28.05052760243416, C-Loss: 33.11546856164932\n",
      "Epoch: 22, Loss: 341.94552659988403,  L-Loss: 25.69555976986885, C-Loss: 32.90977442264557\n",
      "Epoch: 23, Loss: 335.1986994743347,  L-Loss: 24.823529601097107, C-Loss: 32.27869349718094\n",
      "Epoch: 24, Loss: 332.1429982185364,  L-Loss: 25.35574722290039, C-Loss: 31.946512460708618\n",
      "Epoch: 25, Loss: 329.18042755126953,  L-Loss: 21.74172729253769, C-Loss: 31.8309565782547\n",
      "Epoch: 26, Loss: 326.668906211853,  L-Loss: 25.668348655104637, C-Loss: 31.38347339630127\n",
      "Epoch: 27, Loss: 321.6052417755127,  L-Loss: 21.148076444864273, C-Loss: 31.10312008857727\n",
      "Epoch: 28, Loss: 319.64476108551025,  L-Loss: 20.29887965321541, C-Loss: 30.949532210826874\n",
      "Epoch: 29, Loss: 368.89289379119873,  L-Loss: 30.267560124397278, C-Loss: 35.37591099739075\n",
      "Epoch: 30, Loss: 319.3260450363159,  L-Loss: 18.426038563251495, C-Loss: 31.011302411556244\n",
      "Epoch: 31, Loss: 312.7500367164612,  L-Loss: 19.080798506736755, C-Loss: 30.32096356153488\n",
      "Epoch: 32, Loss: 307.7324285507202,  L-Loss: 23.489048525691032, C-Loss: 29.598790049552917\n",
      "Epoch: 33, Loss: 303.3268847465515,  L-Loss: 15.896430969238281, C-Loss: 29.537866711616516\n",
      "Epoch: 34, Loss: 306.1992497444153,  L-Loss: 18.076673686504364, C-Loss: 29.71609091758728\n",
      "Epoch: 35, Loss: 300.5023341178894,  L-Loss: 20.518444627523422, C-Loss: 29.024311304092407\n",
      "Epoch: 36, Loss: 299.1028423309326,  L-Loss: 14.604642540216446, C-Loss: 29.180052042007446\n",
      "Epoch: 37, Loss: 298.09978008270264,  L-Loss: 17.09927035868168, C-Loss: 28.95501446723938\n",
      "Epoch: 38, Loss: 293.0573959350586,  L-Loss: 17.07874046266079, C-Loss: 28.451802611351013\n",
      "Epoch: 39, Loss: 291.7835941314697,  L-Loss: 13.525223419070244, C-Loss: 28.502098381519318\n",
      "Epoch: 40, Loss: 290.9044671058655,  L-Loss: 15.025663211941719, C-Loss: 28.339163839817047\n",
      "Epoch: 41, Loss: 288.7973041534424,  L-Loss: 14.952667519450188, C-Loss: 28.132097125053406\n",
      "Epoch: 42, Loss: 287.25215768814087,  L-Loss: 12.83402007818222, C-Loss: 28.08351480960846\n",
      "Epoch: 43, Loss: 285.7318067550659,  L-Loss: 13.566439852118492, C-Loss: 27.89485853910446\n",
      "Epoch: 44, Loss: 284.39359188079834,  L-Loss: 14.056984558701515, C-Loss: 27.73650997877121\n",
      "Epoch: 45, Loss: 282.6637125015259,  L-Loss: 11.772303126752377, C-Loss: 27.67775583267212\n",
      "Epoch: 46, Loss: 290.38252544403076,  L-Loss: 13.854954943060875, C-Loss: 28.345504820346832\n",
      "Epoch: 47, Loss: 286.59923124313354,  L-Loss: 13.417033076286316, C-Loss: 27.989071488380432\n",
      "Epoch: 48, Loss: 281.5834550857544,  L-Loss: 11.317358568310738, C-Loss: 27.59247750043869\n",
      "Epoch: 49, Loss: 279.2495665550232,  L-Loss: 12.137356251478195, C-Loss: 27.31808865070343\n",
      "Epoch: 50, Loss: 277.6142683029175,  L-Loss: 13.375585064291954, C-Loss: 27.09264773130417\n",
      "Epoch: 51, Loss: 278.56086111068726,  L-Loss: 10.51441016048193, C-Loss: 27.330365419387817\n",
      "Epoch: 52, Loss: 275.8140106201172,  L-Loss: 11.9703488945961, C-Loss: 26.98288404941559\n",
      "Epoch: 53, Loss: 276.27550983428955,  L-Loss: 13.241780430078506, C-Loss: 26.965462177991867\n",
      "Epoch: 54, Loss: 276.2041263580322,  L-Loss: 9.98783103376627, C-Loss: 27.121021151542664\n",
      "Epoch: 55, Loss: 272.46047592163086,  L-Loss: 11.751492753624916, C-Loss: 26.65847271680832\n",
      "Epoch: 56, Loss: 276.71927404403687,  L-Loss: 11.747917987406254, C-Loss: 27.084531664848328\n",
      "Epoch: 57, Loss: 270.26691341400146,  L-Loss: 9.788281537592411, C-Loss: 26.537277460098267\n",
      "Epoch: 58, Loss: 271.85612630844116,  L-Loss: 10.239759914577007, C-Loss: 26.67362505197525\n",
      "Epoch: 59, Loss: 272.95818567276,  L-Loss: 11.382568314671516, C-Loss: 26.72669005393982\n",
      "Epoch: 60, Loss: 268.8269553184509,  L-Loss: 9.617725268006325, C-Loss: 26.401809573173523\n",
      "Epoch: 61, Loss: 272.2259826660156,  L-Loss: 9.809479504823685, C-Loss: 26.73212417960167\n",
      "Epoch: 62, Loss: 268.44765281677246,  L-Loss: 10.918373882770538, C-Loss: 26.298846691846848\n",
      "Epoch: 63, Loss: 268.57953691482544,  L-Loss: 9.085418432950974, C-Loss: 26.403682559728622\n",
      "Epoch: 64, Loss: 270.1830430030823,  L-Loss: 9.365261942148209, C-Loss: 26.550041258335114\n",
      "Epoch: 65, Loss: 267.4292268753052,  L-Loss: 10.492692954838276, C-Loss: 26.218288213014603\n",
      "Epoch: 66, Loss: 266.92533445358276,  L-Loss: 8.308456040918827, C-Loss: 26.27711057662964\n",
      "Epoch: 67, Loss: 267.66100692749023,  L-Loss: 9.032145395874977, C-Loss: 26.314493656158447\n",
      "Epoch: 68, Loss: 266.1166658401489,  L-Loss: 9.50509449839592, C-Loss: 26.136412262916565\n",
      "Epoch: 69, Loss: 264.7652745246887,  L-Loss: 7.807176329195499, C-Loss: 26.08616864681244\n",
      "Epoch: 70, Loss: 267.7982449531555,  L-Loss: 8.709247529506683, C-Loss: 26.344362437725067\n",
      "Epoch: 71, Loss: 264.3933644294739,  L-Loss: 8.61997588723898, C-Loss: 26.008337646722794\n",
      "Epoch: 72, Loss: 265.86071157455444,  L-Loss: 7.86016171425581, C-Loss: 26.193062901496887\n",
      "Epoch: 73, Loss: 263.07794189453125,  L-Loss: 7.8784486055374146, C-Loss: 25.91387188434601\n",
      "Epoch: 74, Loss: 265.2487316131592,  L-Loss: 8.583430379629135, C-Loss: 26.09570160508156\n",
      "Epoch: 75, Loss: 265.20707178115845,  L-Loss: 7.535412676632404, C-Loss: 26.14393663406372\n",
      "Epoch: 76, Loss: 263.9454584121704,  L-Loss: 8.011533744633198, C-Loss: 25.99396911263466\n",
      "Epoch: 77, Loss: 263.3445405960083,  L-Loss: 7.651657000184059, C-Loss: 25.951871126890182\n",
      "Epoch: 78, Loss: 262.11575269699097,  L-Loss: 7.220707893371582, C-Loss: 25.850540071725845\n",
      "Epoch: 79, Loss: 261.86588191986084,  L-Loss: 7.600329577922821, C-Loss: 25.80657172203064\n",
      "Epoch: 80, Loss: 262.80241441726685,  L-Loss: 7.232080541551113, C-Loss: 25.918637543916702\n",
      "Epoch: 81, Loss: 260.4951329231262,  L-Loss: 7.2688107788562775, C-Loss: 25.686073005199432\n",
      "Epoch: 82, Loss: 262.7554864883423,  L-Loss: 7.2984433099627495, C-Loss: 25.910626471042633\n",
      "Epoch: 83, Loss: 260.12993144989014,  L-Loss: 6.925251759588718, C-Loss: 25.666730642318726\n",
      "Epoch: 84, Loss: 261.3323130607605,  L-Loss: 7.247589714825153, C-Loss: 25.77085191011429\n",
      "Epoch: 85, Loss: 268.27235555648804,  L-Loss: 7.2009923085570335, C-Loss: 26.46718594431877\n",
      "Epoch: 86, Loss: 260.1194100379944,  L-Loss: 7.005208943039179, C-Loss: 25.661680310964584\n",
      "Epoch: 87, Loss: 260.46835136413574,  L-Loss: 6.606400094926357, C-Loss: 25.716515213251114\n",
      "Epoch: 88, Loss: 261.74600887298584,  L-Loss: 6.362197712063789, C-Loss: 25.85649085044861\n",
      "Epoch: 89, Loss: 258.75560188293457,  L-Loss: 7.17579747736454, C-Loss: 25.51677018404007\n",
      "Epoch: 90, Loss: 262.70416593551636,  L-Loss: 6.75609527528286, C-Loss: 25.932612001895905\n",
      "Epoch: 91, Loss: 257.33878803253174,  L-Loss: 5.849282801151276, C-Loss: 25.441414922475815\n",
      "Epoch: 92, Loss: 261.49092149734497,  L-Loss: 7.282274533063173, C-Loss: 25.784977793693542\n",
      "Epoch: 93, Loss: 263.29114961624146,  L-Loss: 6.463626764714718, C-Loss: 26.0059335231781\n",
      "Epoch: 94, Loss: 258.7939977645874,  L-Loss: 5.9112959280610085, C-Loss: 25.583835035562515\n",
      "Epoch: 95, Loss: 258.11781120300293,  L-Loss: 5.8819794580340385, C-Loss: 25.517682164907455\n",
      "Epoch: 96, Loss: 258.69360542297363,  L-Loss: 5.804030515253544, C-Loss: 25.57915899157524\n",
      "Epoch: 97, Loss: 256.9634289741516,  L-Loss: 5.790840707719326, C-Loss: 25.406800717115402\n",
      "Epoch: 98, Loss: 258.01597023010254,  L-Loss: 5.735918566584587, C-Loss: 25.51480096578598\n",
      "Epoch: 99, Loss: 256.52943992614746,  L-Loss: 5.401668556034565, C-Loss: 25.382860243320465\n",
      "Epoch: 100, Loss: 257.171838760376,  L-Loss: 5.796856090426445, C-Loss: 25.427340865135193\n",
      "Epoch: 101, Loss: 258.57420587539673,  L-Loss: 5.687748193740845, C-Loss: 25.573033154010773\n",
      "Epoch: 102, Loss: 256.47152280807495,  L-Loss: 5.269692394882441, C-Loss: 25.383667439222336\n",
      "Epoch: 103, Loss: 259.2393841743469,  L-Loss: 5.475665286183357, C-Loss: 25.65015521645546\n",
      "Epoch: 104, Loss: 255.28603982925415,  L-Loss: 5.6566615626215935, C-Loss: 25.245770514011383\n",
      "Epoch: 105, Loss: 257.99694538116455,  L-Loss: 5.529132455587387, C-Loss: 25.52323803305626\n",
      "Epoch: 106, Loss: 259.9406929016113,  L-Loss: 5.280081197619438, C-Loss: 25.73006495833397\n",
      "Epoch: 107, Loss: 257.67613554000854,  L-Loss: 6.400552984327078, C-Loss: 25.4475859105587\n",
      "Epoch: 108, Loss: 259.2168354988098,  L-Loss: 5.370997503399849, C-Loss: 25.653133809566498\n",
      "Epoch: 109, Loss: 255.12606620788574,  L-Loss: 4.489139001816511, C-Loss: 25.288149297237396\n",
      "Epoch: 110, Loss: 257.87383365631104,  L-Loss: 5.893246427178383, C-Loss: 25.492721140384674\n",
      "Epoch: 111, Loss: 260.23548555374146,  L-Loss: 5.21371927857399, C-Loss: 25.762862592935562\n",
      "Epoch: 112, Loss: 255.1338448524475,  L-Loss: 4.430143721401691, C-Loss: 25.29187712073326\n",
      "Epoch: 113, Loss: 255.7460470199585,  L-Loss: 4.827156152576208, C-Loss: 25.333246797323227\n",
      "Epoch: 114, Loss: 253.81048440933228,  L-Loss: 4.710043702274561, C-Loss: 25.145546078681946\n",
      "Epoch: 115, Loss: 254.7144055366516,  L-Loss: 4.397518720477819, C-Loss: 25.251564532518387\n",
      "Epoch: 116, Loss: 255.41520357131958,  L-Loss: 4.38436060026288, C-Loss: 25.322302281856537\n",
      "Epoch: 117, Loss: 254.4535117149353,  L-Loss: 5.063181467354298, C-Loss: 25.192191898822784\n",
      "Epoch: 118, Loss: 255.23426246643066,  L-Loss: 4.244250059127808, C-Loss: 25.311213940382004\n",
      "Epoch: 119, Loss: 253.47012519836426,  L-Loss: 4.169693350791931, C-Loss: 25.138527870178223\n",
      "Epoch: 120, Loss: 255.22209119796753,  L-Loss: 5.187643140554428, C-Loss: 25.2628270983696\n",
      "Epoch: 121, Loss: 255.04724836349487,  L-Loss: 4.0876986011862755, C-Loss: 25.300339609384537\n",
      "Epoch: 122, Loss: 255.27799797058105,  L-Loss: 4.2630751095712185, C-Loss: 25.31464594602585\n",
      "Epoch: 123, Loss: 252.82587003707886,  L-Loss: 4.635714735835791, C-Loss: 25.050801128149033\n",
      "Epoch: 124, Loss: 252.7193546295166,  L-Loss: 3.8470841757953167, C-Loss: 25.079581320285797\n",
      "Epoch: 125, Loss: 253.2604422569275,  L-Loss: 3.8322464004158974, C-Loss: 25.134431630373\n",
      "Epoch: 126, Loss: 253.21686697006226,  L-Loss: 4.680923890322447, C-Loss: 25.087640523910522\n",
      "Epoch: 127, Loss: 252.9362874031067,  L-Loss: 3.8611440397799015, C-Loss: 25.100571393966675\n",
      "Epoch: 128, Loss: 253.77811813354492,  L-Loss: 3.898180305957794, C-Loss: 25.18290278315544\n",
      "Epoch: 129, Loss: 255.28765773773193,  L-Loss: 4.994965687394142, C-Loss: 25.279017597436905\n",
      "Epoch: 130, Loss: 257.2795777320862,  L-Loss: 3.90928615629673, C-Loss: 25.532493203878403\n",
      "Epoch: 131, Loss: 253.800883769989,  L-Loss: 3.73800210095942, C-Loss: 25.193188458681107\n",
      "Epoch: 132, Loss: 252.82257795333862,  L-Loss: 4.439895683899522, C-Loss: 25.06026315689087\n",
      "Epoch: 133, Loss: 252.95901823043823,  L-Loss: 3.568737495690584, C-Loss: 25.11746472120285\n",
      "Epoch: 134, Loss: 252.10199546813965,  L-Loss: 3.4923938252031803, C-Loss: 25.035579830408096\n",
      "Epoch: 135, Loss: 252.2350344657898,  L-Loss: 4.133482199162245, C-Loss: 25.016829431056976\n",
      "Epoch: 136, Loss: 251.0485920906067,  L-Loss: 3.397912923246622, C-Loss: 24.934963434934616\n",
      "Epoch: 137, Loss: 252.56096506118774,  L-Loss: 3.5404228009283543, C-Loss: 25.07907536625862\n",
      "Epoch: 138, Loss: 250.56775617599487,  L-Loss: 3.672064457088709, C-Loss: 24.87317204475403\n",
      "Epoch: 139, Loss: 251.58758163452148,  L-Loss: 3.361381061375141, C-Loss: 24.990688979625702\n",
      "Epoch: 140, Loss: 250.41535663604736,  L-Loss: 3.2128795236349106, C-Loss: 24.880891621112823\n",
      "Epoch: 141, Loss: 253.2819356918335,  L-Loss: 3.9992601089179516, C-Loss: 25.12823048233986\n",
      "Epoch: 142, Loss: 250.65435075759888,  L-Loss: 3.1931027956306934, C-Loss: 24.90577983856201\n",
      "Epoch: 143, Loss: 252.22322368621826,  L-Loss: 3.5774583108723164, C-Loss: 25.043449580669403\n",
      "Epoch: 144, Loss: 249.9386887550354,  L-Loss: 3.460898395627737, C-Loss: 24.820823818445206\n",
      "Epoch: 145, Loss: 251.0875301361084,  L-Loss: 3.167998433113098, C-Loss: 24.950353115797043\n",
      "Epoch: 146, Loss: 251.50424194335938,  L-Loss: 3.0294151790440083, C-Loss: 24.99895343184471\n",
      "Epoch: 147, Loss: 250.46863412857056,  L-Loss: 3.6164361350238323, C-Loss: 24.866041779518127\n",
      "Epoch: 148, Loss: 251.62697887420654,  L-Loss: 3.2181165628135204, C-Loss: 25.001791954040527\n",
      "Epoch: 149, Loss: 250.2504367828369,  L-Loss: 3.1025852784514427, C-Loss: 24.869914203882217\n",
      "Epoch: 150, Loss: 252.21419763565063,  L-Loss: 3.6906266920268536, C-Loss: 25.036888360977173\n",
      "Epoch: 151, Loss: 257.71960163116455,  L-Loss: 3.1862160488963127, C-Loss: 25.612649351358414\n",
      "Epoch: 152, Loss: 250.78160905838013,  L-Loss: 3.12396839261055, C-Loss: 24.921962469816208\n",
      "Epoch: 153, Loss: 248.04959058761597,  L-Loss: 2.9651660583913326, C-Loss: 24.656700640916824\n",
      "Epoch: 154, Loss: 247.94904279708862,  L-Loss: 2.814588848501444, C-Loss: 24.654174715280533\n",
      "Epoch: 155, Loss: 248.31571245193481,  L-Loss: 2.7394964452832937, C-Loss: 24.694596141576767\n",
      "Epoch: 156, Loss: 248.5262908935547,  L-Loss: 2.909681348130107, C-Loss: 24.707145184278488\n",
      "Epoch: 157, Loss: 247.55325317382812,  L-Loss: 2.742929197847843, C-Loss: 24.618178516626358\n",
      "Epoch: 158, Loss: 247.81549453735352,  L-Loss: 2.71967139467597, C-Loss: 24.64556583762169\n",
      "Epoch: 159, Loss: 250.08200883865356,  L-Loss: 3.2857155352830887, C-Loss: 24.843915075063705\n",
      "Epoch: 160, Loss: 246.6251769065857,  L-Loss: 2.7636746428906918, C-Loss: 24.524333626031876\n",
      "Epoch: 161, Loss: 252.20044374465942,  L-Loss: 3.198810890316963, C-Loss: 25.06010392308235\n",
      "Epoch: 162, Loss: 249.38366222381592,  L-Loss: 2.9662689231336117, C-Loss: 24.79005256295204\n",
      "Epoch: 163, Loss: 252.34316062927246,  L-Loss: 2.7565062269568443, C-Loss: 25.096490681171417\n",
      "Epoch: 164, Loss: 249.8459496498108,  L-Loss: 2.4698328860104084, C-Loss: 24.86110308766365\n",
      "Epoch: 165, Loss: 251.4303789138794,  L-Loss: 3.3151730559766293, C-Loss: 24.97727945446968\n",
      "Epoch: 166, Loss: 249.84577083587646,  L-Loss: 2.7102310489863157, C-Loss: 24.849065333604813\n",
      "Epoch: 167, Loss: 248.00487089157104,  L-Loss: 2.5502464156597853, C-Loss: 24.672974556684494\n",
      "Epoch: 168, Loss: 248.40166997909546,  L-Loss: 3.0335995852947235, C-Loss: 24.688486963510513\n",
      "Epoch: 169, Loss: 249.26224899291992,  L-Loss: 2.623918831348419, C-Loss: 24.79502895474434\n",
      "Epoch: 170, Loss: 248.1946587562561,  L-Loss: 2.6488717794418335, C-Loss: 24.687022030353546\n",
      "Epoch: 171, Loss: 245.10206127166748,  L-Loss: 2.563352471217513, C-Loss: 24.382038444280624\n",
      "Epoch: 172, Loss: 248.40813636779785,  L-Loss: 2.708897575736046, C-Loss: 24.70536881685257\n",
      "Epoch: 173, Loss: 247.65572929382324,  L-Loss: 2.3916546516120434, C-Loss: 24.645990163087845\n",
      "Epoch: 174, Loss: 252.12749814987183,  L-Loss: 2.779718704521656, C-Loss: 25.073763757944107\n",
      "Epoch: 175, Loss: 247.86530590057373,  L-Loss: 2.5532829016447067, C-Loss: 24.65886679291725\n",
      "Epoch: 176, Loss: 245.2223243713379,  L-Loss: 2.3382798582315445, C-Loss: 24.405318439006805\n",
      "Epoch: 177, Loss: 250.6374855041504,  L-Loss: 2.737210437655449, C-Loss: 24.926887959241867\n",
      "Epoch: 178, Loss: 246.49652433395386,  L-Loss: 2.423054963350296, C-Loss: 24.52849990129471\n",
      "Epoch: 179, Loss: 248.78873205184937,  L-Loss: 2.651196289807558, C-Loss: 24.746313512325287\n",
      "Epoch: 180, Loss: 246.353364944458,  L-Loss: 2.3096902184188366, C-Loss: 24.519851982593536\n",
      "Epoch: 181, Loss: 248.53346014022827,  L-Loss: 2.390278782695532, C-Loss: 24.733832210302353\n",
      "Epoch: 182, Loss: 245.3191089630127,  L-Loss: 2.138095695525408, C-Loss: 24.42500600218773\n",
      "Epoch: 183, Loss: 246.02038049697876,  L-Loss: 2.3232502210885286, C-Loss: 24.485875487327576\n",
      "Epoch: 184, Loss: 246.02078866958618,  L-Loss: 2.1836226452142, C-Loss: 24.492897987365723\n",
      "Epoch: 185, Loss: 244.79937267303467,  L-Loss: 2.102152118459344, C-Loss: 24.374829560518265\n",
      "Epoch: 186, Loss: 248.27164030075073,  L-Loss: 2.340300928801298, C-Loss: 24.71014866232872\n",
      "Epoch: 187, Loss: 244.3925633430481,  L-Loss: 2.1855356954038143, C-Loss: 24.329979479312897\n",
      "Epoch: 188, Loss: 246.79000425338745,  L-Loss: 2.19156501442194, C-Loss: 24.569422215223312\n",
      "Epoch: 189, Loss: 244.2394518852234,  L-Loss: 2.078088128939271, C-Loss: 24.32004064321518\n",
      "Epoch: 190, Loss: 246.5362687110901,  L-Loss: 2.2527430839836597, C-Loss: 24.540989726781845\n",
      "Epoch: 191, Loss: 243.54315757751465,  L-Loss: 1.916249841451645, C-Loss: 24.25850310921669\n",
      "Epoch: 192, Loss: 246.29620456695557,  L-Loss: 2.1331245759502053, C-Loss: 24.522964537143707\n",
      "Epoch: 193, Loss: 243.14375066757202,  L-Loss: 2.165642922744155, C-Loss: 24.206093043088913\n",
      "Epoch: 194, Loss: 243.83033800125122,  L-Loss: 1.9034568425267935, C-Loss: 24.28786090016365\n",
      "Epoch: 195, Loss: 247.4005422592163,  L-Loss: 2.0303301326930523, C-Loss: 24.638537645339966\n",
      "Epoch: 196, Loss: 244.21702909469604,  L-Loss: 2.198749866336584, C-Loss: 24.3117655813694\n",
      "Epoch: 197, Loss: 245.53500413894653,  L-Loss: 2.062600079923868, C-Loss: 24.450370609760284\n",
      "Epoch: 198, Loss: 244.32378911972046,  L-Loss: 1.8887767735868692, C-Loss: 24.337939977645874\n",
      "Epoch: 199, Loss: 248.75001454353333,  L-Loss: 2.530140621587634, C-Loss: 24.74849435687065\n",
      "Epoch: 200, Loss: 245.3916473388672,  L-Loss: 2.009554024785757, C-Loss: 24.438687175512314\n",
      "Epoch: 201, Loss: 247.47279453277588,  L-Loss: 1.851620675995946, C-Loss: 24.654698133468628\n",
      "Epoch: 202, Loss: 246.14998292922974,  L-Loss: 2.12981041893363, C-Loss: 24.508507817983627\n",
      "Epoch: 203, Loss: 244.2512092590332,  L-Loss: 1.8880953527987003, C-Loss: 24.330716013908386\n",
      "Epoch: 204, Loss: 245.04548358917236,  L-Loss: 2.003308892250061, C-Loss: 24.404382824897766\n",
      "Epoch: 205, Loss: 245.409282207489,  L-Loss: 1.9020420163869858, C-Loss: 24.445826083421707\n",
      "Epoch: 206, Loss: 246.34838771820068,  L-Loss: 1.9071340002119541, C-Loss: 24.539481937885284\n",
      "Epoch: 207, Loss: 244.82795906066895,  L-Loss: 1.740503546781838, C-Loss: 24.395770490169525\n",
      "Epoch: 208, Loss: 247.9380669593811,  L-Loss: 2.0179873453453183, C-Loss: 24.6929073035717\n",
      "Epoch: 209, Loss: 246.70873928070068,  L-Loss: 1.8878310061991215, C-Loss: 24.576482504606247\n",
      "Epoch: 210, Loss: 243.71236419677734,  L-Loss: 1.8189375810325146, C-Loss: 24.280289739370346\n",
      "Epoch: 211, Loss: 250.5963053703308,  L-Loss: 2.1525003723800182, C-Loss: 24.952005475759506\n",
      "Epoch: 212, Loss: 246.0764536857605,  L-Loss: 1.7640555370599031, C-Loss: 24.519442945718765\n",
      "Epoch: 213, Loss: 247.1105604171753,  L-Loss: 1.9698338452726603, C-Loss: 24.61256432533264\n",
      "Epoch: 214, Loss: 245.1216902732849,  L-Loss: 1.8182805143296719, C-Loss: 24.42125490307808\n",
      "Epoch: 215, Loss: 248.37683653831482,  L-Loss: 1.7726229634135962, C-Loss: 24.74905264377594\n",
      "Epoch: 216, Loss: 248.42767667770386,  L-Loss: 1.7031108401715755, C-Loss: 24.757612109184265\n",
      "Epoch: 217, Loss: 246.77062392234802,  L-Loss: 2.0653376542031765, C-Loss: 24.573795467615128\n",
      "Epoch: 218, Loss: 254.08116579055786,  L-Loss: 2.093067303299904, C-Loss: 25.303463011980057\n",
      "Epoch: 219, Loss: 245.32056999206543,  L-Loss: 1.7243856191635132, C-Loss: 24.44583773612976\n",
      "Epoch: 220, Loss: 249.35027074813843,  L-Loss: 2.10946386680007, C-Loss: 24.829553872346878\n",
      "Epoch: 221, Loss: 247.20342874526978,  L-Loss: 1.7925636153668165, C-Loss: 24.63071471452713\n",
      "Epoch: 222, Loss: 246.2924838066101,  L-Loss: 1.6161984140053391, C-Loss: 24.548438519239426\n",
      "Epoch: 223, Loss: 244.98203992843628,  L-Loss: 1.5556295067071915, C-Loss: 24.420422345399857\n",
      "Epoch: 224, Loss: 245.3588161468506,  L-Loss: 1.7726655835285783, C-Loss: 24.44724801182747\n",
      "Epoch: 225, Loss: 244.2668433189392,  L-Loss: 1.5225971825420856, C-Loss: 24.35055434703827\n",
      "Epoch: 226, Loss: 247.79815530776978,  L-Loss: 1.5538469487801194, C-Loss: 24.702123165130615\n",
      "Epoch: 227, Loss: 247.20248174667358,  L-Loss: 1.7904092781245708, C-Loss: 24.63072779774666\n",
      "Epoch: 228, Loss: 243.04802465438843,  L-Loss: 1.5662156604230404, C-Loss: 24.226491302251816\n",
      "Epoch: 229, Loss: 247.74293327331543,  L-Loss: 1.5338772870600224, C-Loss: 24.697599560022354\n",
      "Epoch: 230, Loss: 245.65680265426636,  L-Loss: 1.5650849156081676, C-Loss: 24.487426161766052\n",
      "Epoch: 231, Loss: 244.57152557373047,  L-Loss: 1.5586888585239649, C-Loss: 24.379218101501465\n",
      "Epoch: 232, Loss: 241.8192105293274,  L-Loss: 1.4452005047351122, C-Loss: 24.109661012887955\n",
      "Epoch: 233, Loss: 247.55368041992188,  L-Loss: 1.6045693848282099, C-Loss: 24.675139665603638\n",
      "Epoch: 234, Loss: 242.96358394622803,  L-Loss: 1.441385523416102, C-Loss: 24.224289059638977\n",
      "Epoch: 235, Loss: 244.35624647140503,  L-Loss: 1.4959267945960164, C-Loss: 24.360828459262848\n",
      "Epoch: 236, Loss: 245.41780805587769,  L-Loss: 1.4465460488572717, C-Loss: 24.469453662633896\n",
      "Epoch: 237, Loss: 247.43658351898193,  L-Loss: 1.4808840425685048, C-Loss: 24.669614225625992\n",
      "Epoch: 238, Loss: 246.5808973312378,  L-Loss: 1.438183331862092, C-Loss: 24.58618050813675\n",
      "Epoch: 239, Loss: 246.9660768508911,  L-Loss: 1.5560144428163767, C-Loss: 24.618806809186935\n",
      "Epoch: 240, Loss: 246.5930962562561,  L-Loss: 1.4592951089143753, C-Loss: 24.586344838142395\n",
      "Epoch: 241, Loss: 243.17912006378174,  L-Loss: 1.4378785621374846, C-Loss: 24.246018260717392\n",
      "Epoch: 242, Loss: 249.99617433547974,  L-Loss: 1.687811290845275, C-Loss: 24.915226936340332\n",
      "Epoch: 243, Loss: 245.6333565711975,  L-Loss: 1.4460924491286278, C-Loss: 24.4910309612751\n",
      "Epoch: 244, Loss: 245.76309537887573,  L-Loss: 1.3834976768121123, C-Loss: 24.507134705781937\n",
      "Epoch: 245, Loss: 243.5535101890564,  L-Loss: 1.3535200506448746, C-Loss: 24.28767502307892\n",
      "Epoch: 246, Loss: 246.8306736946106,  L-Loss: 1.3970854189246893, C-Loss: 24.61321285367012\n",
      "Epoch: 247, Loss: 243.6403102874756,  L-Loss: 1.2777151772752404, C-Loss: 24.300145119428635\n",
      "Epoch: 248, Loss: 246.5799970626831,  L-Loss: 1.4321063794195652, C-Loss: 24.586394429206848\n",
      "Epoch: 249, Loss: 246.49619722366333,  L-Loss: 1.4926978200674057, C-Loss: 24.57498475909233\n",
      "Epoch: 250, Loss: 244.7269582748413,  L-Loss: 1.3923663720488548, C-Loss: 24.403077483177185\n",
      "Epoch: 251, Loss: 246.7698473930359,  L-Loss: 1.513478897511959, C-Loss: 24.601310700178146\n",
      "Epoch: 252, Loss: 244.66770792007446,  L-Loss: 1.3419596273452044, C-Loss: 24.399672627449036\n",
      "Epoch: 253, Loss: 245.55067825317383,  L-Loss: 1.3038782253861427, C-Loss: 24.489874005317688\n",
      "Epoch: 254, Loss: 246.8406901359558,  L-Loss: 1.2900062464177608, C-Loss: 24.619568586349487\n",
      "Epoch: 255, Loss: 246.77625703811646,  L-Loss: 1.4095735382288694, C-Loss: 24.607146948575974\n",
      "Epoch: 256, Loss: 248.11040496826172,  L-Loss: 1.43987450376153, C-Loss: 24.739046722650528\n",
      "Epoch: 257, Loss: 246.0528540611267,  L-Loss: 1.3456637244671583, C-Loss: 24.538002252578735\n",
      "Epoch: 258, Loss: 248.46632623672485,  L-Loss: 1.4890405517071486, C-Loss: 24.77218070626259\n",
      "Epoch: 259, Loss: 248.14041137695312,  L-Loss: 1.2919940892606974, C-Loss: 24.74944180250168\n",
      "Epoch: 260, Loss: 246.87403440475464,  L-Loss: 1.248165488243103, C-Loss: 24.624995321035385\n",
      "Epoch: 261, Loss: 246.9930968284607,  L-Loss: 1.1962993927299976, C-Loss: 24.639494746923447\n",
      "Epoch: 262, Loss: 245.0877013206482,  L-Loss: 1.2551877386868, C-Loss: 24.44601058959961\n",
      "Epoch: 263, Loss: 246.45504665374756,  L-Loss: 1.2533686235547066, C-Loss: 24.582836240530014\n",
      "Epoch: 264, Loss: 244.85206985473633,  L-Loss: 1.2621390204876661, C-Loss: 24.422099977731705\n",
      "Epoch: 265, Loss: 249.13389110565186,  L-Loss: 1.387805188074708, C-Loss: 24.843998610973358\n",
      "Epoch: 266, Loss: 245.59323501586914,  L-Loss: 1.1931218281388283, C-Loss: 24.499667465686798\n",
      "Epoch: 267, Loss: 249.49042463302612,  L-Loss: 1.328870601952076, C-Loss: 24.882598876953125\n",
      "Epoch: 268, Loss: 247.11834955215454,  L-Loss: 1.2013068348169327, C-Loss: 24.651769757270813\n",
      "Epoch: 269, Loss: 247.7568211555481,  L-Loss: 1.1487758047878742, C-Loss: 24.71824359893799\n",
      "Epoch: 270, Loss: 246.4767541885376,  L-Loss: 1.1151926349848509, C-Loss: 24.591915488243103\n",
      "Epoch: 271, Loss: 245.00599718093872,  L-Loss: 1.17730791028589, C-Loss: 24.441734224557877\n",
      "Epoch: 272, Loss: 247.5638198852539,  L-Loss: 1.1187558434903622, C-Loss: 24.700444102287292\n",
      "Epoch: 273, Loss: 243.92202377319336,  L-Loss: 1.1199697162956, C-Loss: 24.3362038731575\n",
      "Epoch: 274, Loss: 248.1067533493042,  L-Loss: 1.309777980670333, C-Loss: 24.745186656713486\n",
      "Epoch: 275, Loss: 245.5075707435608,  L-Loss: 1.1550725549459457, C-Loss: 24.493003487586975\n",
      "Epoch: 276, Loss: 250.06504154205322,  L-Loss: 1.190876891836524, C-Loss: 24.94696033000946\n",
      "Epoch: 277, Loss: 245.6617088317871,  L-Loss: 1.134392506442964, C-Loss: 24.509451150894165\n",
      "Epoch: 278, Loss: 249.8751187324524,  L-Loss: 1.2193305268883705, C-Loss: 24.926545470952988\n",
      "Epoch: 279, Loss: 247.31181144714355,  L-Loss: 1.0593471443280578, C-Loss: 24.67821356654167\n",
      "Epoch: 280, Loss: 250.77936935424805,  L-Loss: 1.1678882203996181, C-Loss: 25.01954275369644\n",
      "Epoch: 281, Loss: 246.12809705734253,  L-Loss: 1.1965013490989804, C-Loss: 24.552984535694122\n",
      "Epoch: 282, Loss: 248.13161611557007,  L-Loss: 1.0795150948688388, C-Loss: 24.75918585062027\n",
      "Epoch: 283, Loss: 250.05215549468994,  L-Loss: 1.2817312348634005, C-Loss: 24.941128939390182\n",
      "Epoch: 284, Loss: 250.56222200393677,  L-Loss: 1.3021399341523647, C-Loss: 24.99111521244049\n",
      "Epoch: 285, Loss: 251.30960941314697,  L-Loss: 1.3935841154307127, C-Loss: 25.061281830072403\n",
      "Epoch: 286, Loss: 255.74362421035767,  L-Loss: 1.1836146097630262, C-Loss: 25.515181988477707\n",
      "Epoch: 287, Loss: 248.59291172027588,  L-Loss: 1.5101943537592888, C-Loss: 24.783781439065933\n",
      "Epoch: 288, Loss: 260.5294666290283,  L-Loss: 2.016350354999304, C-Loss: 25.952129185199738\n",
      "Epoch: 289, Loss: 259.3073124885559,  L-Loss: 1.402732607908547, C-Loss: 25.860594391822815\n",
      "Epoch: 290, Loss: 272.1347270011902,  L-Loss: 2.027685245499015, C-Loss: 27.112088590860367\n",
      "Epoch: 291, Loss: 293.47928047180176,  L-Loss: 2.666971828788519, C-Loss: 29.214579224586487\n",
      "Epoch: 292, Loss: 266.14848232269287,  L-Loss: 1.6537964269518852, C-Loss: 26.53215855360031\n",
      "Epoch: 293, Loss: 259.3197693824768,  L-Loss: 1.7101328670978546, C-Loss: 25.84647023677826\n",
      "Epoch: 294, Loss: 257.3751606941223,  L-Loss: 1.3927785567939281, C-Loss: 25.667877316474915\n",
      "Epoch: 295, Loss: 258.5112519264221,  L-Loss: 1.4130896050482988, C-Loss: 25.78047090768814\n",
      "Epoch: 296, Loss: 254.08672714233398,  L-Loss: 1.2402017191052437, C-Loss: 25.346662640571594\n",
      "Epoch: 297, Loss: 251.9747314453125,  L-Loss: 1.2563076186925173, C-Loss: 25.134657829999924\n",
      "Epoch: 298, Loss: 245.4886794090271,  L-Loss: 1.1731908936053514, C-Loss: 24.4902084171772\n",
      "Epoch: 299, Loss: 245.98388719558716,  L-Loss: 1.2109360992908478, C-Loss: 24.53784191608429\n",
      "Epoch: 300, Loss: 244.96937608718872,  L-Loss: 1.1800921000540257, C-Loss: 24.43793296813965\n",
      "Epoch: 301, Loss: 248.08356285095215,  L-Loss: 1.209203939884901, C-Loss: 24.747896045446396\n",
      "Epoch: 302, Loss: 245.65414190292358,  L-Loss: 1.1534608118236065, C-Loss: 24.50774109363556\n",
      "Epoch: 303, Loss: 250.0473861694336,  L-Loss: 1.1691329525783658, C-Loss: 24.94628217816353\n",
      "Epoch: 304, Loss: 246.66473627090454,  L-Loss: 1.1131131378933787, C-Loss: 24.610817581415176\n",
      "Epoch: 305, Loss: 250.57965326309204,  L-Loss: 1.1480537299066782, C-Loss: 25.000562727451324\n",
      "Epoch: 306, Loss: 246.0961503982544,  L-Loss: 1.0998758263885975, C-Loss: 24.554621279239655\n",
      "Epoch: 307, Loss: 252.76378297805786,  L-Loss: 1.1560959490016103, C-Loss: 25.21857351064682\n",
      "Epoch: 308, Loss: 246.85349321365356,  L-Loss: 1.0845945160835981, C-Loss: 24.631119698286057\n",
      "Epoch: 309, Loss: 251.2569031715393,  L-Loss: 1.1166590647771955, C-Loss: 25.069857388734818\n",
      "Epoch: 310, Loss: 247.9635157585144,  L-Loss: 1.0590760558843613, C-Loss: 24.743397802114487\n",
      "Epoch: 311, Loss: 249.81221675872803,  L-Loss: 1.0742805497720838, C-Loss: 24.927507668733597\n",
      "Epoch: 312, Loss: 247.99020910263062,  L-Loss: 1.0309076653793454, C-Loss: 24.747475534677505\n",
      "Epoch: 313, Loss: 249.38833141326904,  L-Loss: 1.0468990486115217, C-Loss: 24.886488288640976\n",
      "Epoch: 314, Loss: 248.90815448760986,  L-Loss: 1.021347802132368, C-Loss: 24.83974802494049\n",
      "Epoch: 315, Loss: 250.01306343078613,  L-Loss: 1.0411885464563966, C-Loss: 24.949246883392334\n",
      "Epoch: 316, Loss: 249.27660846710205,  L-Loss: 1.0001481985673308, C-Loss: 24.877653628587723\n",
      "Epoch: 317, Loss: 249.21483850479126,  L-Loss: 1.0155227426439524, C-Loss: 24.870708018541336\n",
      "Epoch: 318, Loss: 250.8953423500061,  L-Loss: 0.9926583748310804, C-Loss: 25.0399012863636\n",
      "Epoch: 319, Loss: 248.83293771743774,  L-Loss: 1.0014219898730516, C-Loss: 24.83322286605835\n",
      "Epoch: 320, Loss: 249.38739585876465,  L-Loss: 0.9795285724103451, C-Loss: 24.889763116836548\n",
      "Epoch: 321, Loss: 248.5061502456665,  L-Loss: 1.0282358545809984, C-Loss: 24.79920318722725\n",
      "Epoch: 322, Loss: 248.62897729873657,  L-Loss: 0.9962167162448168, C-Loss: 24.81308686733246\n",
      "Epoch: 323, Loss: 250.35178804397583,  L-Loss: 1.0597736686468124, C-Loss: 24.98219034075737\n",
      "Epoch: 324, Loss: 249.55462789535522,  L-Loss: 0.9947574194520712, C-Loss: 24.905724734067917\n",
      "Epoch: 325, Loss: 250.47878074645996,  L-Loss: 1.0403293874114752, C-Loss: 24.99586147069931\n",
      "Epoch: 326, Loss: 248.63573217391968,  L-Loss: 0.9673880990594625, C-Loss: 24.815203934907913\n",
      "Epoch: 327, Loss: 249.37194156646729,  L-Loss: 1.0054211840033531, C-Loss: 24.886923015117645\n",
      "Epoch: 328, Loss: 248.77598237991333,  L-Loss: 0.9485436780378222, C-Loss: 24.830171048641205\n",
      "Epoch: 329, Loss: 248.14337015151978,  L-Loss: 0.9725213414058089, C-Loss: 24.7657111287117\n",
      "Epoch: 330, Loss: 248.01012563705444,  L-Loss: 0.9201370710507035, C-Loss: 24.75500574707985\n",
      "Epoch: 331, Loss: 249.8581576347351,  L-Loss: 0.9636722644791007, C-Loss: 24.937632262706757\n",
      "Epoch: 332, Loss: 250.5335750579834,  L-Loss: 0.929115385748446, C-Loss: 25.006901800632477\n",
      "Epoch: 333, Loss: 249.79332160949707,  L-Loss: 0.936821979470551, C-Loss: 24.932491153478622\n",
      "Epoch: 334, Loss: 250.38087558746338,  L-Loss: 0.9108972568064928, C-Loss: 24.992542922496796\n",
      "Epoch: 335, Loss: 248.7434220314026,  L-Loss: 0.9109164010733366, C-Loss: 24.828796297311783\n",
      "Epoch: 336, Loss: 249.20370435714722,  L-Loss: 0.8953239163383842, C-Loss: 24.875604271888733\n",
      "Epoch: 337, Loss: 248.90092039108276,  L-Loss: 0.8814442772418261, C-Loss: 24.846019834280014\n",
      "Epoch: 338, Loss: 248.78958177566528,  L-Loss: 0.8896962283179164, C-Loss: 24.834473341703415\n",
      "Epoch: 339, Loss: 249.60547399520874,  L-Loss: 0.8786669597029686, C-Loss: 24.916614085435867\n",
      "Epoch: 340, Loss: 247.93822145462036,  L-Loss: 0.8791282307356596, C-Loss: 24.749865859746933\n",
      "Epoch: 341, Loss: 248.570538520813,  L-Loss: 0.877719889394939, C-Loss: 24.813167691230774\n",
      "Epoch: 342, Loss: 247.49186754226685,  L-Loss: 0.8636097749695182, C-Loss: 24.706006348133087\n",
      "Epoch: 343, Loss: 247.58890581130981,  L-Loss: 0.8753277957439423, C-Loss: 24.71512421965599\n",
      "Epoch: 344, Loss: 248.21616220474243,  L-Loss: 0.8543463833630085, C-Loss: 24.778898924589157\n",
      "Epoch: 345, Loss: 248.65212535858154,  L-Loss: 0.8765824679285288, C-Loss: 24.82138329744339\n",
      "Epoch: 346, Loss: 247.94936990737915,  L-Loss: 0.8586010942235589, C-Loss: 24.752007216215134\n",
      "Epoch: 347, Loss: 249.32043170928955,  L-Loss: 0.8766983980312943, C-Loss: 24.888208210468292\n",
      "Epoch: 348, Loss: 248.25639581680298,  L-Loss: 0.8627705695107579, C-Loss: 24.782500982284546\n",
      "Epoch: 349, Loss: 248.9740490913391,  L-Loss: 0.8750035986304283, C-Loss: 24.85365456342697\n",
      "Epoch: 350, Loss: 249.32576942443848,  L-Loss: 0.8473693262785673, C-Loss: 24.890208572149277\n",
      "Epoch: 351, Loss: 249.28262186050415,  L-Loss: 0.8700312431901693, C-Loss: 24.884760707616806\n",
      "Epoch: 352, Loss: 248.88598775863647,  L-Loss: 0.842271963134408, C-Loss: 24.846484929323196\n",
      "Epoch: 353, Loss: 248.67299461364746,  L-Loss: 0.8674854310229421, C-Loss: 24.823924958705902\n",
      "Epoch: 354, Loss: 248.3845009803772,  L-Loss: 0.8484424743801355, C-Loss: 24.79602810740471\n",
      "Epoch: 355, Loss: 249.02822542190552,  L-Loss: 0.8530517648905516, C-Loss: 24.860170036554337\n",
      "Epoch: 356, Loss: 248.19688320159912,  L-Loss: 0.8367880955338478, C-Loss: 24.77784886956215\n",
      "Epoch: 357, Loss: 248.47901058197021,  L-Loss: 0.8534513125196099, C-Loss: 24.805228769779205\n",
      "Epoch: 358, Loss: 248.57944536209106,  L-Loss: 0.8204146949574351, C-Loss: 24.816923767328262\n",
      "Epoch: 359, Loss: 247.91702270507812,  L-Loss: 0.8341577751561999, C-Loss: 24.74999448657036\n",
      "Epoch: 360, Loss: 246.34113216400146,  L-Loss: 0.8131187278777361, C-Loss: 24.59345716238022\n",
      "Epoch: 361, Loss: 246.61391305923462,  L-Loss: 0.8236368438228965, C-Loss: 24.620209336280823\n",
      "Epoch: 362, Loss: 246.21871423721313,  L-Loss: 0.807105946354568, C-Loss: 24.581516325473785\n",
      "Epoch: 363, Loss: 246.28080701828003,  L-Loss: 0.8130893604829907, C-Loss: 24.587426036596298\n",
      "Epoch: 364, Loss: 248.9789047241211,  L-Loss: 0.8388158921152353, C-Loss: 24.85594990849495\n",
      "Epoch: 365, Loss: 247.932053565979,  L-Loss: 0.9166813353076577, C-Loss: 24.74737122654915\n",
      "Epoch: 366, Loss: 248.07551765441895,  L-Loss: 1.0324385203421116, C-Loss: 24.755929946899414\n",
      "Epoch: 367, Loss: 250.51516675949097,  L-Loss: 1.0527819991111755, C-Loss: 24.99887752532959\n",
      "Epoch: 368, Loss: 249.2819857597351,  L-Loss: 0.847097447142005, C-Loss: 24.88584342598915\n",
      "Epoch: 369, Loss: 254.68952322006226,  L-Loss: 0.959879114292562, C-Loss: 25.420958280563354\n",
      "Epoch: 370, Loss: 250.12059020996094,  L-Loss: 0.8902950696647167, C-Loss: 24.96754440665245\n",
      "Epoch: 371, Loss: 251.96428632736206,  L-Loss: 0.948748248629272, C-Loss: 25.14899092912674\n",
      "Epoch: 372, Loss: 255.36742067337036,  L-Loss: 1.1442013122141361, C-Loss: 25.479531794786453\n",
      "Epoch: 373, Loss: 264.53033685684204,  L-Loss: 0.923091764561832, C-Loss: 26.40687921643257\n",
      "Epoch: 374, Loss: 272.09387254714966,  L-Loss: 1.444894678890705, C-Loss: 27.137142717838287\n",
      "Epoch: 375, Loss: 268.2866778373718,  L-Loss: 0.9093114463612437, C-Loss: 26.783202171325684\n",
      "Epoch: 376, Loss: 257.7832112312317,  L-Loss: 0.9459398286417127, C-Loss: 25.731024086475372\n",
      "Epoch: 377, Loss: 257.78304958343506,  L-Loss: 0.8410955714061856, C-Loss: 25.736250281333923\n",
      "Epoch: 378, Loss: 253.9111156463623,  L-Loss: 0.8278356418013573, C-Loss: 25.349719643592834\n",
      "Epoch: 379, Loss: 250.95028734207153,  L-Loss: 0.7453666785731912, C-Loss: 25.057760536670685\n",
      "Epoch: 380, Loss: 251.83165884017944,  L-Loss: 0.7586161596700549, C-Loss: 25.14523497223854\n",
      "Epoch: 381, Loss: 251.21163606643677,  L-Loss: 0.7422829838469625, C-Loss: 25.08404940366745\n",
      "Epoch: 382, Loss: 249.90094900131226,  L-Loss: 0.7428502449765801, C-Loss: 24.95295226573944\n",
      "Epoch: 383, Loss: 249.54464960098267,  L-Loss: 0.776218787766993, C-Loss: 24.91565391421318\n",
      "Epoch: 384, Loss: 247.45176124572754,  L-Loss: 0.7725269198417664, C-Loss: 24.706549614667892\n",
      "Epoch: 385, Loss: 249.179594039917,  L-Loss: 0.8696695985272527, C-Loss: 24.874475747346878\n",
      "Epoch: 386, Loss: 247.10080480575562,  L-Loss: 0.7913569947704673, C-Loss: 24.67051264643669\n",
      "Epoch: 387, Loss: 248.7549958229065,  L-Loss: 0.8945394288748503, C-Loss: 24.830772638320923\n",
      "Epoch: 388, Loss: 249.76666975021362,  L-Loss: 0.7582952110096812, C-Loss: 24.93875241279602\n",
      "Epoch: 389, Loss: 250.0979127883911,  L-Loss: 0.8070174185559154, C-Loss: 24.96944034099579\n",
      "Epoch: 390, Loss: 249.66068315505981,  L-Loss: 0.7648358941078186, C-Loss: 24.92782661318779\n",
      "Epoch: 391, Loss: 250.17071294784546,  L-Loss: 0.7319366000592709, C-Loss: 24.9804747402668\n",
      "Epoch: 392, Loss: 249.69145250320435,  L-Loss: 0.8084870791062713, C-Loss: 24.928720593452454\n",
      "Epoch: 393, Loss: 249.66617918014526,  L-Loss: 0.7411109069362283, C-Loss: 24.929562389850616\n",
      "Epoch: 394, Loss: 249.02693557739258,  L-Loss: 0.8196156695485115, C-Loss: 24.861712753772736\n",
      "Epoch: 395, Loss: 249.47205543518066,  L-Loss: 0.727709336206317, C-Loss: 24.91082012653351\n",
      "Epoch: 396, Loss: 250.36470794677734,  L-Loss: 0.7655814494937658, C-Loss: 24.998191714286804\n",
      "Epoch: 397, Loss: 249.39690399169922,  L-Loss: 0.701235618442297, C-Loss: 24.90462875366211\n",
      "Epoch: 398, Loss: 247.384991645813,  L-Loss: 0.7016057725995779, C-Loss: 24.7034193277359\n",
      "Epoch: 399, Loss: 251.12363481521606,  L-Loss: 0.6950837699696422, C-Loss: 25.07760915160179\n",
      "Epoch: 400, Loss: 249.38772439956665,  L-Loss: 0.6982860779389739, C-Loss: 24.903858333826065\n",
      "Epoch: 401, Loss: 255.5625557899475,  L-Loss: 0.7357715955004096, C-Loss: 25.51946720480919\n",
      "Epoch: 402, Loss: 251.37041425704956,  L-Loss: 0.7010947428643703, C-Loss: 25.101986974477768\n",
      "Epoch: 403, Loss: 249.46703338623047,  L-Loss: 0.7423582198098302, C-Loss: 24.90958532691002\n",
      "Epoch: 404, Loss: 246.98763513565063,  L-Loss: 0.6826425772160292, C-Loss: 24.66463130712509\n",
      "Epoch: 405, Loss: 249.54185390472412,  L-Loss: 0.7050123251974583, C-Loss: 24.918934881687164\n",
      "Epoch: 406, Loss: 249.29843187332153,  L-Loss: 0.6846118504181504, C-Loss: 24.895612597465515\n",
      "Epoch: 407, Loss: 249.24796772003174,  L-Loss: 0.695122464094311, C-Loss: 24.89004024863243\n",
      "Epoch: 408, Loss: 249.7454719543457,  L-Loss: 0.6740043070167303, C-Loss: 24.94084683060646\n",
      "Epoch: 409, Loss: 248.61790370941162,  L-Loss: 0.6901058265939355, C-Loss: 24.827284902334213\n",
      "Epoch: 410, Loss: 248.8310203552246,  L-Loss: 0.6899562953040004, C-Loss: 24.848604291677475\n",
      "Epoch: 411, Loss: 250.26423120498657,  L-Loss: 0.6952857039868832, C-Loss: 24.991658985614777\n",
      "Epoch: 412, Loss: 254.25808906555176,  L-Loss: 0.7851002924144268, C-Loss: 25.386553645133972\n",
      "Epoch: 413, Loss: 249.05526638031006,  L-Loss: 0.7192418351769447, C-Loss: 24.869564652442932\n",
      "Epoch: 414, Loss: 254.59104299545288,  L-Loss: 0.7973421895876527, C-Loss: 25.4192373752594\n",
      "Epoch: 415, Loss: 247.8406162261963,  L-Loss: 0.6859115632250905, C-Loss: 24.74976620078087\n",
      "Epoch: 416, Loss: 255.49457120895386,  L-Loss: 0.7451104568317533, C-Loss: 25.512201756238937\n",
      "Epoch: 417, Loss: 249.71108150482178,  L-Loss: 0.6783917006105185, C-Loss: 24.93718847632408\n",
      "Epoch: 418, Loss: 252.46070432662964,  L-Loss: 0.7262264229357243, C-Loss: 25.209759294986725\n",
      "Epoch: 419, Loss: 255.36753940582275,  L-Loss: 0.7796778492629528, C-Loss: 25.497769981622696\n",
      "Epoch: 420, Loss: 251.9203019142151,  L-Loss: 0.746174868196249, C-Loss: 25.154721438884735\n",
      "Epoch: 421, Loss: 257.41945123672485,  L-Loss: 0.8809667322784662, C-Loss: 25.697896718978882\n",
      "Epoch: 422, Loss: 254.61602306365967,  L-Loss: 0.7257516449317336, C-Loss: 25.425314724445343\n",
      "Epoch: 423, Loss: 257.33012437820435,  L-Loss: 0.8004856994375587, C-Loss: 25.69298818707466\n",
      "Epoch: 424, Loss: 252.2386598587036,  L-Loss: 0.7131823822855949, C-Loss: 25.18820682168007\n",
      "Epoch: 425, Loss: 254.3067708015442,  L-Loss: 0.7633584514260292, C-Loss: 25.392509162425995\n",
      "Epoch: 426, Loss: 259.21109437942505,  L-Loss: 0.8455166323110461, C-Loss: 25.878833770751953\n",
      "Epoch: 427, Loss: 253.8482847213745,  L-Loss: 0.7227609232068062, C-Loss: 25.348690539598465\n",
      "Epoch: 428, Loss: 254.36991262435913,  L-Loss: 0.8139787381514907, C-Loss: 25.396292328834534\n",
      "Epoch: 429, Loss: 251.71746587753296,  L-Loss: 0.6826266152784228, C-Loss: 25.137615114450455\n",
      "Epoch: 430, Loss: 253.45148134231567,  L-Loss: 0.7145223580300808, C-Loss: 25.30942216515541\n",
      "Epoch: 431, Loss: 251.824387550354,  L-Loss: 0.6932228347286582, C-Loss: 25.14777797460556\n",
      "Epoch: 432, Loss: 252.36364364624023,  L-Loss: 0.6804058440029621, C-Loss: 25.20234426856041\n",
      "Epoch: 433, Loss: 250.0364727973938,  L-Loss: 0.6752584865316749, C-Loss: 24.969884425401688\n",
      "Epoch: 434, Loss: 248.71381855010986,  L-Loss: 0.60682556591928, C-Loss: 24.841040641069412\n",
      "Epoch: 435, Loss: 251.13553380966187,  L-Loss: 0.6464928230270743, C-Loss: 25.08122870326042\n",
      "Epoch: 436, Loss: 250.64271545410156,  L-Loss: 0.6102402340620756, C-Loss: 25.033759474754333\n",
      "Epoch: 437, Loss: 250.46457195281982,  L-Loss: 0.6264375792816281, C-Loss: 25.015135407447815\n",
      "Epoch: 438, Loss: 249.06968450546265,  L-Loss: 0.634123700670898, C-Loss: 24.875262141227722\n",
      "Epoch: 439, Loss: 249.76032638549805,  L-Loss: 0.6118392962962389, C-Loss: 24.945440590381622\n",
      "Epoch: 440, Loss: 251.36409425735474,  L-Loss: 0.6012612199410796, C-Loss: 25.106346487998962\n",
      "Epoch: 441, Loss: 250.218852519989,  L-Loss: 0.6249610297381878, C-Loss: 24.99063730239868\n",
      "Epoch: 442, Loss: 249.14556694030762,  L-Loss: 0.5998731898143888, C-Loss: 24.88456302881241\n",
      "Epoch: 443, Loss: 252.83283138275146,  L-Loss: 0.6011508889496326, C-Loss: 25.253225684165955\n",
      "Epoch: 444, Loss: 249.06477117538452,  L-Loss: 0.5927753048017621, C-Loss: 24.876838117837906\n",
      "Epoch: 445, Loss: 250.01431560516357,  L-Loss: 0.5953855477273464, C-Loss: 24.971662402153015\n",
      "Epoch: 446, Loss: 252.46383380889893,  L-Loss: 0.5882741156965494, C-Loss: 25.21696937084198\n",
      "Epoch: 447, Loss: 251.04179525375366,  L-Loss: 0.588408668525517, C-Loss: 25.0747592151165\n",
      "Epoch: 448, Loss: 250.46459817886353,  L-Loss: 0.5863300133496523, C-Loss: 25.017143309116364\n",
      "Epoch: 449, Loss: 253.12330722808838,  L-Loss: 0.5925027476623654, C-Loss: 25.282705307006836\n",
      "Epoch: 450, Loss: 251.96871757507324,  L-Loss: 0.5727041140198708, C-Loss: 25.168236583471298\n",
      "Epoch: 451, Loss: 252.53352975845337,  L-Loss: 0.5961121143773198, C-Loss: 25.223547220230103\n",
      "Epoch: 452, Loss: 251.04711771011353,  L-Loss: 0.5699993306770921, C-Loss: 25.07621195912361\n",
      "Epoch: 453, Loss: 254.06369018554688,  L-Loss: 0.6032313136383891, C-Loss: 25.376207292079926\n",
      "Epoch: 454, Loss: 251.99130630493164,  L-Loss: 0.585294634103775, C-Loss: 25.169866055250168\n",
      "Epoch: 455, Loss: 252.48101472854614,  L-Loss: 0.601479479111731, C-Loss: 25.218027621507645\n",
      "Epoch: 456, Loss: 250.10318231582642,  L-Loss: 0.5728790573775768, C-Loss: 24.981674283742905\n",
      "Epoch: 457, Loss: 252.4200315475464,  L-Loss: 0.598512914031744, C-Loss: 25.212077766656876\n",
      "Epoch: 458, Loss: 250.90786504745483,  L-Loss: 0.5893750656396151, C-Loss: 25.06131786108017\n",
      "Epoch: 459, Loss: 251.88691663742065,  L-Loss: 0.5923388339579105, C-Loss: 25.159074634313583\n",
      "Epoch: 460, Loss: 248.86129760742188,  L-Loss: 0.5692218663170934, C-Loss: 24.85766875743866\n",
      "Epoch: 461, Loss: 251.00374507904053,  L-Loss: 0.5584494331851602, C-Loss: 25.072452157735825\n",
      "Epoch: 462, Loss: 251.97809982299805,  L-Loss: 0.5911582447588444, C-Loss: 25.16825222969055\n",
      "Epoch: 463, Loss: 251.3917031288147,  L-Loss: 0.5713703976944089, C-Loss: 25.110601872205734\n",
      "Epoch: 464, Loss: 254.2377109527588,  L-Loss: 0.6299805883318186, C-Loss: 25.392272144556046\n",
      "Epoch: 465, Loss: 253.28695249557495,  L-Loss: 0.6041421722620726, C-Loss: 25.2984881401062\n",
      "Epoch: 466, Loss: 259.17705726623535,  L-Loss: 0.6812316169962287, C-Loss: 25.88364440202713\n",
      "Epoch: 467, Loss: 256.3839612007141,  L-Loss: 0.5912068979814649, C-Loss: 25.60883605480194\n",
      "Epoch: 468, Loss: 266.22149419784546,  L-Loss: 0.7233863864094019, C-Loss: 26.585980147123337\n",
      "Epoch: 469, Loss: 277.46205711364746,  L-Loss: 1.00531146209687, C-Loss: 27.69594031572342\n",
      "Epoch: 470, Loss: 284.4309196472168,  L-Loss: 1.6029166094958782, C-Loss: 28.362946033477783\n",
      "Epoch: 471, Loss: 295.92859840393066,  L-Loss: 1.3389731757342815, C-Loss: 29.52591109275818\n",
      "Epoch: 472, Loss: 324.00236654281616,  L-Loss: 1.1184117821976542, C-Loss: 32.34431594610214\n",
      "Epoch: 473, Loss: 271.5494804382324,  L-Loss: 0.9850445967167616, C-Loss: 27.105695575475693\n",
      "Epoch: 474, Loss: 266.4940538406372,  L-Loss: 1.1623117933049798, C-Loss: 26.591289937496185\n",
      "Epoch: 475, Loss: 259.7009015083313,  L-Loss: 1.0527742761187255, C-Loss: 25.91745173931122\n",
      "Epoch: 476, Loss: 262.12869691848755,  L-Loss: 1.1293893177062273, C-Loss: 26.15640038251877\n",
      "Epoch: 477, Loss: 266.84088945388794,  L-Loss: 1.1047164695337415, C-Loss: 26.628852874040604\n",
      "Epoch: 478, Loss: 263.0967106819153,  L-Loss: 1.1265199650079012, C-Loss: 26.25334495306015\n",
      "Epoch: 479, Loss: 260.5212993621826,  L-Loss: 0.9247028715908527, C-Loss: 26.00589492917061\n",
      "Epoch: 480, Loss: 259.5384588241577,  L-Loss: 0.8899354124441743, C-Loss: 25.909348785877228\n",
      "Epoch: 481, Loss: 250.81834030151367,  L-Loss: 0.8442312581464648, C-Loss: 25.039622604846954\n",
      "Epoch: 482, Loss: 251.88027477264404,  L-Loss: 0.8756925947964191, C-Loss: 25.144242882728577\n",
      "Epoch: 483, Loss: 249.93227624893188,  L-Loss: 0.8297711070626974, C-Loss: 24.95173904299736\n",
      "Epoch: 484, Loss: 250.60881233215332,  L-Loss: 0.826494506560266, C-Loss: 25.01955622434616\n",
      "Epoch: 485, Loss: 249.12511348724365,  L-Loss: 0.871767464093864, C-Loss: 24.86892294883728\n",
      "Epoch: 486, Loss: 251.1709303855896,  L-Loss: 0.8681512512266636, C-Loss: 25.07368555665016\n",
      "Epoch: 487, Loss: 252.63436365127563,  L-Loss: 0.8561690365895629, C-Loss: 25.220627903938293\n",
      "Epoch: 488, Loss: 251.07930421829224,  L-Loss: 0.7865336071699858, C-Loss: 25.06860375404358\n",
      "Epoch: 489, Loss: 254.84534645080566,  L-Loss: 0.8279740419238806, C-Loss: 25.443135887384415\n",
      "Epoch: 490, Loss: 250.82558345794678,  L-Loss: 0.803344520740211, C-Loss: 25.042391180992126\n",
      "Epoch: 491, Loss: 253.27926874160767,  L-Loss: 0.8369247410446405, C-Loss: 25.28608086705208\n",
      "Epoch: 492, Loss: 249.5110330581665,  L-Loss: 0.8364380914717913, C-Loss: 24.909281611442566\n",
      "Epoch: 493, Loss: 255.51513671875,  L-Loss: 0.8541973624378443, C-Loss: 25.50880390405655\n",
      "Epoch: 494, Loss: 248.6899824142456,  L-Loss: 0.814352635294199, C-Loss: 24.82828062772751\n",
      "Epoch: 495, Loss: 253.21527576446533,  L-Loss: 0.7967151729390025, C-Loss: 25.281691700220108\n",
      "Epoch: 496, Loss: 248.59501600265503,  L-Loss: 0.79022616147995, C-Loss: 24.81999036669731\n",
      "Epoch: 497, Loss: 254.7623519897461,  L-Loss: 0.7979737157002091, C-Loss: 25.436336874961853\n",
      "Epoch: 498, Loss: 249.40261507034302,  L-Loss: 0.7975661335512996, C-Loss: 24.900383055210114\n",
      "Epoch: 499, Loss: 255.8952078819275,  L-Loss: 0.7975105131044984, C-Loss: 25.549645572900772\n",
      "Epoch: 500, Loss: 250.4473729133606,  L-Loss: 0.7930673211812973, C-Loss: 25.005083918571472\n",
      "Epoch: 501, Loss: 256.86726093292236,  L-Loss: 0.8003860609605908, C-Loss: 25.646706998348236\n",
      "Epoch: 502, Loss: 252.452401638031,  L-Loss: 0.7862647706642747, C-Loss: 25.20592710375786\n",
      "Epoch: 503, Loss: 255.39337396621704,  L-Loss: 0.7739924369379878, C-Loss: 25.500637650489807\n",
      "Epoch: 504, Loss: 250.69836711883545,  L-Loss: 0.7717742370441556, C-Loss: 25.031247973442078\n",
      "Epoch: 505, Loss: 252.09644651412964,  L-Loss: 0.7581315580755472, C-Loss: 25.17173832654953\n",
      "Epoch: 506, Loss: 250.1058669090271,  L-Loss: 0.7427668627351522, C-Loss: 24.973448127508163\n",
      "Epoch: 507, Loss: 250.77145051956177,  L-Loss: 0.7361429445445538, C-Loss: 25.04033789038658\n",
      "Epoch: 508, Loss: 250.86667728424072,  L-Loss: 0.7366252318024635, C-Loss: 25.049836307764053\n",
      "Epoch: 509, Loss: 250.58491468429565,  L-Loss: 0.7237547086551785, C-Loss: 25.022303968667984\n",
      "Epoch: 510, Loss: 251.36935424804688,  L-Loss: 0.7270971285179257, C-Loss: 25.10058042407036\n",
      "Epoch: 511, Loss: 249.6110601425171,  L-Loss: 0.7150164819322526, C-Loss: 24.925355225801468\n",
      "Epoch: 512, Loss: 251.02278900146484,  L-Loss: 0.7260587522760034, C-Loss: 25.065975815057755\n",
      "Epoch: 513, Loss: 251.25197649002075,  L-Loss: 0.7196216378360987, C-Loss: 25.089216321706772\n",
      "Epoch: 514, Loss: 250.99830675125122,  L-Loss: 0.7326613906770945, C-Loss: 25.06319761276245\n",
      "Epoch: 515, Loss: 252.7859296798706,  L-Loss: 0.7176205245777965, C-Loss: 25.242711931467056\n",
      "Epoch: 516, Loss: 250.95714950561523,  L-Loss: 0.726714301854372, C-Loss: 25.059379160404205\n",
      "Epoch: 517, Loss: 252.5963339805603,  L-Loss: 0.7205384280532598, C-Loss: 25.223606646060944\n",
      "Epoch: 518, Loss: 251.50508451461792,  L-Loss: 0.7278003254905343, C-Loss: 25.114118218421936\n",
      "Epoch: 519, Loss: 252.8996376991272,  L-Loss: 0.7272869665175676, C-Loss: 25.25359958410263\n",
      "Epoch: 520, Loss: 251.2922921180725,  L-Loss: 0.7300922172144055, C-Loss: 25.092724829912186\n",
      "Epoch: 521, Loss: 253.44406414031982,  L-Loss: 0.737068104557693, C-Loss: 25.307553082704544\n",
      "Epoch: 522, Loss: 250.11589431762695,  L-Loss: 0.745100081898272, C-Loss: 24.974334478378296\n",
      "Epoch: 523, Loss: 251.49868965148926,  L-Loss: 0.7271715188398957, C-Loss: 25.113510489463806\n",
      "Epoch: 524, Loss: 251.697772026062,  L-Loss: 0.7367561850696802, C-Loss: 25.132939487695694\n",
      "Epoch: 525, Loss: 252.16833639144897,  L-Loss: 0.7078310120850801, C-Loss: 25.181442499160767\n",
      "Epoch: 526, Loss: 250.5094451904297,  L-Loss: 0.7185959480702877, C-Loss: 25.015014559030533\n",
      "Epoch: 527, Loss: 250.1851463317871,  L-Loss: 0.6908308947458863, C-Loss: 24.983973056077957\n",
      "Epoch: 528, Loss: 249.9059863090515,  L-Loss: 0.7121098013594747, C-Loss: 24.954993039369583\n",
      "Epoch: 529, Loss: 252.15850591659546,  L-Loss: 0.6926798839122057, C-Loss: 25.181216657161713\n",
      "Epoch: 530, Loss: 250.30147552490234,  L-Loss: 0.7064908016473055, C-Loss: 24.994823068380356\n",
      "Epoch: 531, Loss: 250.28754472732544,  L-Loss: 0.6846936559304595, C-Loss: 24.99451994895935\n",
      "Epoch: 532, Loss: 250.516215801239,  L-Loss: 0.6907505355775356, C-Loss: 25.017083942890167\n",
      "Epoch: 533, Loss: 250.72864961624146,  L-Loss: 0.6766071561723948, C-Loss: 25.039034515619278\n",
      "Epoch: 534, Loss: 250.85097646713257,  L-Loss: 0.675250330939889, C-Loss: 25.051335155963898\n",
      "Epoch: 535, Loss: 249.52637720108032,  L-Loss: 0.6706008575856686, C-Loss: 24.919107645750046\n",
      "Epoch: 536, Loss: 250.65975141525269,  L-Loss: 0.6756382919847965, C-Loss: 25.032193213701248\n",
      "Epoch: 537, Loss: 251.92482900619507,  L-Loss: 0.6632514502853155, C-Loss: 25.159320414066315\n",
      "Epoch: 538, Loss: 251.99362897872925,  L-Loss: 0.6900181341916323, C-Loss: 25.164862096309662\n",
      "Epoch: 539, Loss: 252.7505645751953,  L-Loss: 0.6660182671621442, C-Loss: 25.24175563454628\n",
      "Epoch: 540, Loss: 253.9596757888794,  L-Loss: 0.6582015082240105, C-Loss: 25.363057553768158\n",
      "Epoch: 541, Loss: 253.56460666656494,  L-Loss: 0.6904142620041966, C-Loss: 25.32194009423256\n",
      "Epoch: 542, Loss: 255.5309386253357,  L-Loss: 0.6812231577932835, C-Loss: 25.519032895565033\n",
      "Epoch: 543, Loss: 252.06886434555054,  L-Loss: 0.7043282771483064, C-Loss: 25.17167004942894\n",
      "Epoch: 544, Loss: 254.55041217803955,  L-Loss: 0.6898674312978983, C-Loss: 25.420547753572464\n",
      "Epoch: 545, Loss: 254.79854011535645,  L-Loss: 0.6539024701341987, C-Loss: 25.447158873081207\n",
      "Epoch: 546, Loss: 253.8077597618103,  L-Loss: 0.6646783575415611, C-Loss: 25.347542136907578\n",
      "Epoch: 547, Loss: 255.26183319091797,  L-Loss: 0.6486960435286164, C-Loss: 25.49374833703041\n",
      "Epoch: 548, Loss: 253.77851581573486,  L-Loss: 0.6453478122130036, C-Loss: 25.345584005117416\n",
      "Epoch: 549, Loss: 255.74844360351562,  L-Loss: 0.6441226378083229, C-Loss: 25.542638272047043\n",
      "Epoch: 550, Loss: 254.28110694885254,  L-Loss: 0.6313439374789596, C-Loss: 25.396543592214584\n",
      "Epoch: 551, Loss: 254.53143215179443,  L-Loss: 0.6335174879059196, C-Loss: 25.42146745324135\n",
      "Epoch: 552, Loss: 253.26955366134644,  L-Loss: 0.6288892030715942, C-Loss: 25.295510590076447\n",
      "Epoch: 553, Loss: 254.08587741851807,  L-Loss: 0.6224715812131763, C-Loss: 25.377464085817337\n",
      "Epoch: 554, Loss: 255.73869228363037,  L-Loss: 0.6278814123943448, C-Loss: 25.542475402355194\n",
      "Epoch: 555, Loss: 253.50843334197998,  L-Loss: 0.6275408240035176, C-Loss: 25.319466441869736\n",
      "Epoch: 556, Loss: 258.3329133987427,  L-Loss: 0.6547219883650541, C-Loss: 25.800555378198624\n",
      "Epoch: 557, Loss: 255.09900188446045,  L-Loss: 0.632972564548254, C-Loss: 25.47825139760971\n",
      "Epoch: 558, Loss: 257.74709606170654,  L-Loss: 0.6783475922420621, C-Loss: 25.74079203605652\n",
      "Epoch: 559, Loss: 258.1504430770874,  L-Loss: 0.6420219885185361, C-Loss: 25.782943218946457\n",
      "Epoch: 560, Loss: 254.82969903945923,  L-Loss: 0.6500355331227183, C-Loss: 25.45046827197075\n",
      "Epoch: 561, Loss: 253.0659146308899,  L-Loss: 0.638717551715672, C-Loss: 25.274655610322952\n",
      "Epoch: 562, Loss: 256.45481157302856,  L-Loss: 0.6113023264333606, C-Loss: 25.614916145801544\n",
      "Epoch: 563, Loss: 249.077250957489,  L-Loss: 0.6282114898785949, C-Loss: 24.87631446123123\n",
      "Epoch: 564, Loss: 256.6045961380005,  L-Loss: 0.6569365067407489, C-Loss: 25.62761279940605\n",
      "Epoch: 565, Loss: 252.39503622055054,  L-Loss: 0.5853095650672913, C-Loss: 25.21023815870285\n",
      "Epoch: 566, Loss: 257.399649143219,  L-Loss: 0.6225007465109229, C-Loss: 25.70883995294571\n",
      "Epoch: 567, Loss: 256.828950881958,  L-Loss: 0.5803967737592757, C-Loss: 25.65387535095215\n",
      "Epoch: 568, Loss: 252.80038833618164,  L-Loss: 0.5912693040445447, C-Loss: 25.25047540664673\n",
      "Epoch: 569, Loss: 254.2351531982422,  L-Loss: 0.5786384781822562, C-Loss: 25.394583225250244\n",
      "Epoch: 570, Loss: 250.95559549331665,  L-Loss: 0.5871918797492981, C-Loss: 25.066200017929077\n",
      "Epoch: 571, Loss: 252.07815313339233,  L-Loss: 0.5871458286419511, C-Loss: 25.17845806479454\n",
      "Epoch: 572, Loss: 252.46296882629395,  L-Loss: 0.5869328356347978, C-Loss: 25.216950178146362\n",
      "Epoch: 573, Loss: 252.66066932678223,  L-Loss: 0.6150852032005787, C-Loss: 25.235312670469284\n",
      "Epoch: 574, Loss: 249.12918710708618,  L-Loss: 0.5804049982689321, C-Loss: 24.883898347616196\n",
      "Epoch: 575, Loss: 255.46418523788452,  L-Loss: 0.5945127112790942, C-Loss: 25.516692966222763\n",
      "Epoch: 576, Loss: 257.7488718032837,  L-Loss: 0.6622984493151307, C-Loss: 25.741772383451462\n",
      "Epoch: 577, Loss: 261.89643573760986,  L-Loss: 0.6551706651225686, C-Loss: 26.156885117292404\n",
      "Epoch: 578, Loss: 264.1682677268982,  L-Loss: 0.6860106401145458, C-Loss: 26.38252618908882\n",
      "Epoch: 579, Loss: 274.1926031112671,  L-Loss: 0.7733076456934214, C-Loss: 27.380594730377197\n",
      "Epoch: 580, Loss: 256.2982873916626,  L-Loss: 0.6263090493157506, C-Loss: 25.59851336479187\n",
      "Epoch: 581, Loss: 252.65342950820923,  L-Loss: 0.5519452588632703, C-Loss: 25.237745821475983\n",
      "Epoch: 582, Loss: 252.35044765472412,  L-Loss: 0.5613815300166607, C-Loss: 25.206975668668747\n",
      "Epoch: 583, Loss: 255.90292119979858,  L-Loss: 0.5435410337522626, C-Loss: 25.563115298748016\n",
      "Epoch: 584, Loss: 250.74955081939697,  L-Loss: 0.5333763547241688, C-Loss: 25.048286259174347\n",
      "Epoch: 585, Loss: 254.3879280090332,  L-Loss: 0.5545851439237595, C-Loss: 25.411063641309738\n",
      "Epoch: 586, Loss: 253.20700931549072,  L-Loss: 0.5719949454069138, C-Loss: 25.292101353406906\n",
      "Epoch: 587, Loss: 251.76559257507324,  L-Loss: 0.5849079769104719, C-Loss: 25.147313863039017\n",
      "Epoch: 588, Loss: 261.9616951942444,  L-Loss: 0.6673377510160208, C-Loss: 26.16280233860016\n",
      "Epoch: 589, Loss: 252.27211046218872,  L-Loss: 0.5598076898604631, C-Loss: 25.19922035932541\n",
      "Epoch: 590, Loss: 257.57514905929565,  L-Loss: 0.5926053929142654, C-Loss: 25.72788468003273\n",
      "Epoch: 591, Loss: 260.34315824508667,  L-Loss: 0.5859513394534588, C-Loss: 26.005018532276154\n",
      "Epoch: 592, Loss: 255.20804929733276,  L-Loss: 0.5651694675907493, C-Loss: 25.492546170949936\n",
      "Epoch: 593, Loss: 256.1065273284912,  L-Loss: 0.6336540170013905, C-Loss: 25.57897001504898\n",
      "Epoch: 594, Loss: 258.07791090011597,  L-Loss: 0.5761171318590641, C-Loss: 25.77898508310318\n",
      "Epoch: 595, Loss: 250.57786560058594,  L-Loss: 0.5774598373100162, C-Loss: 25.02891343832016\n",
      "Epoch: 596, Loss: 258.02849769592285,  L-Loss: 0.5539999166503549, C-Loss: 25.77515009045601\n",
      "Epoch: 597, Loss: 250.99668073654175,  L-Loss: 0.5489428383298218, C-Loss: 25.07222095131874\n",
      "Epoch: 598, Loss: 259.79105043411255,  L-Loss: 0.5653372723609209, C-Loss: 25.950838208198547\n",
      "Epoch: 599, Loss: 255.64740180969238,  L-Loss: 0.5596353067085147, C-Loss: 25.53675839304924\n",
      "Epoch: 600, Loss: 251.36306428909302,  L-Loss: 0.5707323467358947, C-Loss: 25.10776972770691\n",
      "Epoch: 601, Loss: 256.4800682067871,  L-Loss: 0.5511749992147088, C-Loss: 25.620447993278503\n",
      "Epoch: 602, Loss: 249.93187952041626,  L-Loss: 0.5535602234303951, C-Loss: 24.96550977230072\n",
      "Epoch: 603, Loss: 258.8754963874817,  L-Loss: 0.5500671714544296, C-Loss: 25.86004638671875\n",
      "Epoch: 604, Loss: 252.5942039489746,  L-Loss: 0.5577565524727106, C-Loss: 25.231532394886017\n",
      "Epoch: 605, Loss: 252.53556728363037,  L-Loss: 0.544793825596571, C-Loss: 25.226316928863525\n",
      "Epoch: 606, Loss: 254.49081945419312,  L-Loss: 0.5443405751138926, C-Loss: 25.421864837408066\n",
      "Epoch: 607, Loss: 252.34782361984253,  L-Loss: 0.5441640904173255, C-Loss: 25.20757418870926\n",
      "Epoch: 608, Loss: 252.65072059631348,  L-Loss: 0.5382977109402418, C-Loss: 25.238157153129578\n",
      "Epoch: 609, Loss: 252.56367111206055,  L-Loss: 0.5225928202271461, C-Loss: 25.230237424373627\n",
      "Epoch: 610, Loss: 251.50386476516724,  L-Loss: 0.5166727812029421, C-Loss: 25.12455263733864\n",
      "Epoch: 611, Loss: 253.3720908164978,  L-Loss: 0.5307162664830685, C-Loss: 25.310673117637634\n",
      "Epoch: 612, Loss: 254.92972040176392,  L-Loss: 0.5178482886403799, C-Loss: 25.46707969903946\n",
      "Epoch: 613, Loss: 252.87871837615967,  L-Loss: 0.5149035062640905, C-Loss: 25.26212650537491\n",
      "Epoch: 614, Loss: 253.09056758880615,  L-Loss: 0.5142795015126467, C-Loss: 25.283343195915222\n",
      "Epoch: 615, Loss: 253.6644172668457,  L-Loss: 0.5258667599409819, C-Loss: 25.340148270130157\n",
      "Epoch: 616, Loss: 255.6614179611206,  L-Loss: 0.5276981377974153, C-Loss: 25.539757072925568\n",
      "Epoch: 617, Loss: 255.42682552337646,  L-Loss: 0.5534212021157146, C-Loss: 25.51501163840294\n",
      "Epoch: 618, Loss: 256.5412940979004,  L-Loss: 0.5254256408661604, C-Loss: 25.627858191728592\n",
      "Epoch: 619, Loss: 254.68852710723877,  L-Loss: 0.5354188252240419, C-Loss: 25.44208186864853\n",
      "Epoch: 620, Loss: 255.66051816940308,  L-Loss: 0.5289672818034887, C-Loss: 25.53960347175598\n",
      "Epoch: 621, Loss: 255.95211172103882,  L-Loss: 0.5202465811744332, C-Loss: 25.569198697805405\n",
      "Epoch: 622, Loss: 255.22121477127075,  L-Loss: 0.5227061761543155, C-Loss: 25.49598616361618\n",
      "Epoch: 623, Loss: 253.42796516418457,  L-Loss: 0.5171055220998824, C-Loss: 25.316941291093826\n",
      "Epoch: 624, Loss: 257.7667384147644,  L-Loss: 0.5214741434901953, C-Loss: 25.75059986114502\n",
      "Epoch: 625, Loss: 252.99458122253418,  L-Loss: 0.5208532009273767, C-Loss: 25.27341565489769\n",
      "Epoch: 626, Loss: 253.2551760673523,  L-Loss: 0.5104173757135868, C-Loss: 25.299996703863144\n",
      "Epoch: 627, Loss: 255.6150279045105,  L-Loss: 0.5007794452831149, C-Loss: 25.53646394610405\n",
      "Epoch: 628, Loss: 250.40311908721924,  L-Loss: 0.5084441099315882, C-Loss: 25.014889806509018\n",
      "Epoch: 629, Loss: 254.12383317947388,  L-Loss: 0.5032589491456747, C-Loss: 25.387220233678818\n",
      "Epoch: 630, Loss: 251.1746063232422,  L-Loss: 0.5078369379043579, C-Loss: 25.092068910598755\n",
      "Epoch: 631, Loss: 253.08079051971436,  L-Loss: 0.5229914132505655, C-Loss: 25.281929403543472\n",
      "Epoch: 632, Loss: 252.9842176437378,  L-Loss: 0.5146893407218158, C-Loss: 25.27268746495247\n",
      "Epoch: 633, Loss: 255.3551425933838,  L-Loss: 0.5356059074401855, C-Loss: 25.50873365998268\n",
      "Epoch: 634, Loss: 252.36243438720703,  L-Loss: 0.5328618865460157, C-Loss: 25.20960035920143\n",
      "Epoch: 635, Loss: 255.31234169006348,  L-Loss: 0.5655664689838886, C-Loss: 25.5029559135437\n",
      "Epoch: 636, Loss: 257.18813943862915,  L-Loss: 0.5647255978547037, C-Loss: 25.690577685832977\n",
      "Epoch: 637, Loss: 248.8774857521057,  L-Loss: 0.5384952607564628, C-Loss: 24.8608241379261\n",
      "Epoch: 638, Loss: 257.1386399269104,  L-Loss: 0.5554488720372319, C-Loss: 25.68609181046486\n",
      "Epoch: 639, Loss: 262.2411780357361,  L-Loss: 0.5467775436118245, C-Loss: 26.19677895307541\n",
      "Epoch: 640, Loss: 278.9900641441345,  L-Loss: 0.5912487087771297, C-Loss: 27.869444012641907\n",
      "Epoch: 641, Loss: 270.6191053390503,  L-Loss: 0.5819819401949644, C-Loss: 27.03281134366989\n",
      "Epoch: 642, Loss: 262.34554147720337,  L-Loss: 0.5244863256812096, C-Loss: 26.208329737186432\n",
      "Epoch: 643, Loss: 263.5426344871521,  L-Loss: 0.5481750005856156, C-Loss: 26.326854646205902\n",
      "Epoch: 644, Loss: 253.35119533538818,  L-Loss: 0.5251171616837382, C-Loss: 25.308863639831543\n",
      "Epoch: 645, Loss: 251.96510457992554,  L-Loss: 0.6264630807563663, C-Loss: 25.16518744826317\n",
      "Epoch: 646, Loss: 252.16020107269287,  L-Loss: 0.6581992590799928, C-Loss: 25.183109939098358\n",
      "Epoch: 647, Loss: 265.6575765609741,  L-Loss: 0.667013636790216, C-Loss: 26.532406747341156\n",
      "Epoch: 648, Loss: 266.0791015625,  L-Loss: 0.5622246135026217, C-Loss: 26.579798847436905\n",
      "Epoch: 649, Loss: 251.69598388671875,  L-Loss: 0.48595653753727674, C-Loss: 25.145300567150116\n",
      "Epoch: 650, Loss: 255.1370553970337,  L-Loss: 0.5149762155488133, C-Loss: 25.48795673251152\n",
      "Epoch: 651, Loss: 251.47926998138428,  L-Loss: 0.4660341562703252, C-Loss: 25.124625205993652\n",
      "Epoch: 652, Loss: 253.32854080200195,  L-Loss: 0.4891004445962608, C-Loss: 25.308399558067322\n",
      "Epoch: 653, Loss: 251.15718793869019,  L-Loss: 0.46669597551226616, C-Loss: 25.09238377213478\n",
      "Epoch: 654, Loss: 253.04406118392944,  L-Loss: 0.49260361632332206, C-Loss: 25.27977627515793\n",
      "Epoch: 655, Loss: 254.0365858078003,  L-Loss: 0.4698041770607233, C-Loss: 25.380168437957764\n",
      "Epoch: 656, Loss: 250.94657135009766,  L-Loss: 0.48622902436181903, C-Loss: 25.070345669984818\n",
      "Epoch: 657, Loss: 253.15915155410767,  L-Loss: 0.5050047021359205, C-Loss: 25.290664941072464\n",
      "Epoch: 658, Loss: 252.20267343521118,  L-Loss: 0.49453721288591623, C-Loss: 25.195540457963943\n",
      "Epoch: 659, Loss: 253.5411548614502,  L-Loss: 0.4867840022780001, C-Loss: 25.329776108264923\n",
      "Epoch: 660, Loss: 254.76127815246582,  L-Loss: 0.47467623464763165, C-Loss: 25.452394008636475\n",
      "Epoch: 661, Loss: 253.875554561615,  L-Loss: 0.47669811313971877, C-Loss: 25.36372059583664\n",
      "Epoch: 662, Loss: 251.71154117584229,  L-Loss: 0.4873836785554886, C-Loss: 25.14678505063057\n",
      "Epoch: 663, Loss: 254.31904125213623,  L-Loss: 0.49802677892148495, C-Loss: 25.407002687454224\n",
      "Epoch: 664, Loss: 250.76977396011353,  L-Loss: 0.498346459120512, C-Loss: 25.0520601272583\n",
      "Epoch: 665, Loss: 252.22790622711182,  L-Loss: 0.49569153133779764, C-Loss: 25.198006182909012\n",
      "Epoch: 666, Loss: 253.06257581710815,  L-Loss: 0.49447547644376755, C-Loss: 25.281533658504486\n",
      "Epoch: 667, Loss: 254.15729808807373,  L-Loss: 0.5137538644485176, C-Loss: 25.39004224538803\n",
      "Epoch: 668, Loss: 255.1496901512146,  L-Loss: 0.47793927462771535, C-Loss: 25.491072177886963\n",
      "Epoch: 669, Loss: 251.4105978012085,  L-Loss: 0.4923854162916541, C-Loss: 25.11644047498703\n",
      "Epoch: 670, Loss: 262.1354875564575,  L-Loss: 0.4823299618437886, C-Loss: 26.189432114362717\n",
      "Epoch: 671, Loss: 250.63579273223877,  L-Loss: 0.4783591339364648, C-Loss: 25.039661020040512\n",
      "Epoch: 672, Loss: 253.99513149261475,  L-Loss: 0.46903721056878567, C-Loss: 25.376061379909515\n",
      "Epoch: 673, Loss: 253.54147291183472,  L-Loss: 0.462069284170866, C-Loss: 25.331043601036072\n",
      "Epoch: 674, Loss: 254.81468534469604,  L-Loss: 0.47288196440786123, C-Loss: 25.457824617624283\n",
      "Epoch: 675, Loss: 251.5810775756836,  L-Loss: 0.46986662689596415, C-Loss: 25.13461446762085\n",
      "Epoch: 676, Loss: 253.746253490448,  L-Loss: 0.49249776639044285, C-Loss: 25.35000041127205\n",
      "Epoch: 677, Loss: 251.63382577896118,  L-Loss: 0.5118918176740408, C-Loss: 25.137788116931915\n",
      "Epoch: 678, Loss: 255.06793594360352,  L-Loss: 0.5141114583238959, C-Loss: 25.481088131666183\n",
      "Epoch: 679, Loss: 255.64936923980713,  L-Loss: 0.5046870121732354, C-Loss: 25.539702594280243\n",
      "Epoch: 680, Loss: 252.62617921829224,  L-Loss: 0.48659452982246876, C-Loss: 25.238288015127182\n",
      "Epoch: 681, Loss: 263.11322689056396,  L-Loss: 0.4913116479292512, C-Loss: 26.2867571413517\n",
      "Epoch: 682, Loss: 254.6838994026184,  L-Loss: 0.48301494400948286, C-Loss: 25.444239109754562\n",
      "Epoch: 683, Loss: 256.76890087127686,  L-Loss: 0.46557044703513384, C-Loss: 25.653611660003662\n",
      "Epoch: 684, Loss: 252.1911792755127,  L-Loss: 0.45925300335511565, C-Loss: 25.196155190467834\n",
      "Epoch: 685, Loss: 253.7190647125244,  L-Loss: 0.46114183217287064, C-Loss: 25.348849445581436\n",
      "Epoch: 686, Loss: 251.66452646255493,  L-Loss: 0.4616824476979673, C-Loss: 25.14336848258972\n",
      "Epoch: 687, Loss: 254.41055250167847,  L-Loss: 0.47129502007737756, C-Loss: 25.417490482330322\n",
      "Epoch: 688, Loss: 253.81628942489624,  L-Loss: 0.48278241511434317, C-Loss: 25.3574897646904\n",
      "Epoch: 689, Loss: 255.4371976852417,  L-Loss: 0.4768138495273888, C-Loss: 25.51987898349762\n",
      "Epoch: 690, Loss: 254.09131908416748,  L-Loss: 0.4794127345085144, C-Loss: 25.38516131043434\n",
      "Epoch: 691, Loss: 252.8124122619629,  L-Loss: 0.47653358336538076, C-Loss: 25.257414937019348\n",
      "Epoch: 692, Loss: 257.4839253425598,  L-Loss: 0.47162489499896765, C-Loss: 25.724811255931854\n",
      "Epoch: 693, Loss: 254.86078262329102,  L-Loss: 0.47887691017240286, C-Loss: 25.46213436126709\n",
      "Epoch: 694, Loss: 257.8382182121277,  L-Loss: 0.45478899125009775, C-Loss: 25.761082261800766\n",
      "Epoch: 695, Loss: 251.31424951553345,  L-Loss: 0.46211104840040207, C-Loss: 25.10831931233406\n",
      "Epoch: 696, Loss: 254.45791292190552,  L-Loss: 0.47216070210561156, C-Loss: 25.422183454036713\n",
      "Epoch: 697, Loss: 249.33954095840454,  L-Loss: 0.456748123280704, C-Loss: 24.911116868257523\n",
      "Epoch: 698, Loss: 254.8168225288391,  L-Loss: 0.5242320983670652, C-Loss: 25.455470860004425\n",
      "Epoch: 699, Loss: 247.47328090667725,  L-Loss: 0.5187072870321572, C-Loss: 24.721392899751663\n",
      "Epoch: 700, Loss: 255.83663845062256,  L-Loss: 0.5822896994650364, C-Loss: 25.55454909801483\n",
      "Epoch: 701, Loss: 259.4997353553772,  L-Loss: 0.5310880057513714, C-Loss: 25.923419445753098\n",
      "Epoch: 702, Loss: 252.53692531585693,  L-Loss: 0.49527331348508596, C-Loss: 25.22892862558365\n",
      "Epoch: 703, Loss: 255.48826551437378,  L-Loss: 0.48551640938967466, C-Loss: 25.524550765752792\n",
      "Epoch: 704, Loss: 254.32856941223145,  L-Loss: 0.4402893912047148, C-Loss: 25.410842329263687\n",
      "Epoch: 705, Loss: 254.5388264656067,  L-Loss: 0.5115612773224711, C-Loss: 25.42830467224121\n",
      "Epoch: 706, Loss: 251.59825897216797,  L-Loss: 0.4729600204154849, C-Loss: 25.136178016662598\n",
      "Epoch: 707, Loss: 254.80394983291626,  L-Loss: 0.47800357919186354, C-Loss: 25.4564947783947\n",
      "Epoch: 708, Loss: 252.29727172851562,  L-Loss: 0.4743605484254658, C-Loss: 25.20600914955139\n",
      "Epoch: 709, Loss: 253.2861042022705,  L-Loss: 0.44386540446430445, C-Loss: 25.30641695857048\n",
      "Epoch: 710, Loss: 264.51553201675415,  L-Loss: 0.4909477895125747, C-Loss: 26.427005529403687\n",
      "Epoch: 711, Loss: 253.28407382965088,  L-Loss: 0.4613552773371339, C-Loss: 25.305339515209198\n",
      "Epoch: 712, Loss: 254.59383630752563,  L-Loss: 0.49674184527248144, C-Loss: 25.4345463514328\n",
      "Epoch: 713, Loss: 253.93505334854126,  L-Loss: 0.4658266557380557, C-Loss: 25.370213955640793\n",
      "Epoch: 714, Loss: 256.46237087249756,  L-Loss: 0.5500928652472794, C-Loss: 25.618732541799545\n",
      "Epoch: 715, Loss: 259.9001202583313,  L-Loss: 0.5081263342872262, C-Loss: 25.964605510234833\n",
      "Epoch: 716, Loss: 251.16400909423828,  L-Loss: 0.5075445165857673, C-Loss: 25.091023832559586\n",
      "Epoch: 717, Loss: 254.79760360717773,  L-Loss: 0.5349810104817152, C-Loss: 25.453011453151703\n",
      "Epoch: 718, Loss: 250.01907110214233,  L-Loss: 0.4615436075255275, C-Loss: 24.97882989048958\n",
      "Epoch: 719, Loss: 254.1261191368103,  L-Loss: 0.5185543606057763, C-Loss: 25.386684089899063\n",
      "Epoch: 720, Loss: 247.32144260406494,  L-Loss: 0.490870576351881, C-Loss: 24.70760065317154\n",
      "Epoch: 721, Loss: 257.58047819137573,  L-Loss: 0.5153258140198886, C-Loss: 25.73228120803833\n",
      "Epoch: 722, Loss: 258.2470588684082,  L-Loss: 0.4756544753909111, C-Loss: 25.800922960042953\n",
      "Epoch: 723, Loss: 253.69445371627808,  L-Loss: 0.4502669721841812, C-Loss: 25.346932113170624\n",
      "Epoch: 724, Loss: 254.8616394996643,  L-Loss: 0.44586183689534664, C-Loss: 25.46387070417404\n",
      "Epoch: 725, Loss: 249.42681884765625,  L-Loss: 0.41958457697182894, C-Loss: 24.9217027425766\n",
      "Epoch: 726, Loss: 253.75766372680664,  L-Loss: 0.43464129604399204, C-Loss: 25.35403424501419\n",
      "Epoch: 727, Loss: 254.94351959228516,  L-Loss: 0.4418071829713881, C-Loss: 25.472261667251587\n",
      "Epoch: 728, Loss: 254.0812258720398,  L-Loss: 0.444195294752717, C-Loss: 25.38591280579567\n",
      "Epoch: 729, Loss: 253.32094430923462,  L-Loss: 0.43108815932646394, C-Loss: 25.310539841651917\n",
      "Epoch: 730, Loss: 253.08423233032227,  L-Loss: 0.43094961158931255, C-Loss: 25.286875754594803\n",
      "Epoch: 731, Loss: 251.83730363845825,  L-Loss: 0.43216433050110936, C-Loss: 25.16212236881256\n",
      "Epoch: 732, Loss: 252.68903589248657,  L-Loss: 0.41952458769083023, C-Loss: 25.247927367687225\n",
      "Epoch: 733, Loss: 253.79329776763916,  L-Loss: 0.4266533018089831, C-Loss: 25.357997089624405\n",
      "Epoch: 734, Loss: 252.74810028076172,  L-Loss: 0.4172954591922462, C-Loss: 25.253945291042328\n",
      "Epoch: 735, Loss: 252.49732160568237,  L-Loss: 0.42683815117925406, C-Loss: 25.22839030623436\n",
      "Epoch: 736, Loss: 251.1194405555725,  L-Loss: 0.41777623631060123, C-Loss: 25.091054916381836\n",
      "Epoch: 737, Loss: 255.08086347579956,  L-Loss: 0.44139865320175886, C-Loss: 25.48601645231247\n",
      "Epoch: 738, Loss: 255.37748336791992,  L-Loss: 0.43797782715409994, C-Loss: 25.515849471092224\n",
      "Epoch: 739, Loss: 250.80282306671143,  L-Loss: 0.41960559971630573, C-Loss: 25.059302121400833\n",
      "Epoch: 740, Loss: 252.2118434906006,  L-Loss: 0.42569651873782277, C-Loss: 25.199899703264236\n",
      "Epoch: 741, Loss: 253.34137725830078,  L-Loss: 0.4210672853514552, C-Loss: 25.313084363937378\n",
      "Epoch: 742, Loss: 254.45740842819214,  L-Loss: 0.4452315205708146, C-Loss: 25.42347925901413\n",
      "Epoch: 743, Loss: 255.84178924560547,  L-Loss: 0.4328537015244365, C-Loss: 25.562536537647247\n",
      "Epoch: 744, Loss: 253.68762159347534,  L-Loss: 0.4498279942199588, C-Loss: 25.34627091884613\n",
      "Epoch: 745, Loss: 253.96046018600464,  L-Loss: 0.45368399983271956, C-Loss: 25.373361587524414\n",
      "Epoch: 746, Loss: 252.13886785507202,  L-Loss: 0.4299082150682807, C-Loss: 25.192391395568848\n",
      "Epoch: 747, Loss: 255.06880712509155,  L-Loss: 0.4375566514208913, C-Loss: 25.485002875328064\n",
      "Epoch: 748, Loss: 255.2773814201355,  L-Loss: 0.43998775351792574, C-Loss: 25.50573879480362\n",
      "Epoch: 749, Loss: 252.330246925354,  L-Loss: 0.48243564646691084, C-Loss: 25.208902716636658\n",
      "Epoch: 750, Loss: 252.0120973587036,  L-Loss: 0.437168694101274, C-Loss: 25.179351270198822\n",
      "Epoch: 751, Loss: 255.86624670028687,  L-Loss: 0.4961282014846802, C-Loss: 25.56181824207306\n",
      "Epoch: 752, Loss: 260.3213610649109,  L-Loss: 0.4507275205105543, C-Loss: 26.009599775075912\n",
      "Epoch: 753, Loss: 256.83356380462646,  L-Loss: 0.46348584070801735, C-Loss: 25.660182058811188\n",
      "Epoch: 754, Loss: 261.9491066932678,  L-Loss: 0.4635933260433376, C-Loss: 26.171730995178223\n",
      "Epoch: 755, Loss: 257.75650215148926,  L-Loss: 0.4558460731059313, C-Loss: 25.752858221530914\n",
      "Epoch: 756, Loss: 254.60228633880615,  L-Loss: 0.48260685335844755, C-Loss: 25.436098396778107\n",
      "Epoch: 757, Loss: 263.67045497894287,  L-Loss: 0.45975131541490555, C-Loss: 26.3440580368042\n",
      "Epoch: 758, Loss: 258.4228096008301,  L-Loss: 0.46277492120862007, C-Loss: 25.81914210319519\n",
      "Epoch: 759, Loss: 256.7219295501709,  L-Loss: 0.43527506617829204, C-Loss: 25.650429040193558\n",
      "Epoch: 760, Loss: 249.55744743347168,  L-Loss: 0.4015187439508736, C-Loss: 24.935668647289276\n",
      "Epoch: 761, Loss: 248.5119662284851,  L-Loss: 0.41812360286712646, C-Loss: 24.830290287733078\n",
      "Epoch: 762, Loss: 251.57926082611084,  L-Loss: 0.41268783528357744, C-Loss: 25.137291818857193\n",
      "Epoch: 763, Loss: 253.82326745986938,  L-Loss: 0.486131789162755, C-Loss: 25.358020275831223\n",
      "Epoch: 764, Loss: 254.83379459381104,  L-Loss: 0.4253379013389349, C-Loss: 25.462112367153168\n",
      "Epoch: 765, Loss: 255.67125368118286,  L-Loss: 0.4653421062976122, C-Loss: 25.54385843873024\n",
      "Epoch: 766, Loss: 259.8731646537781,  L-Loss: 0.4256832655519247, C-Loss: 25.966032058000565\n",
      "Epoch: 767, Loss: 258.30365800857544,  L-Loss: 0.4326289063319564, C-Loss: 25.80873429775238\n",
      "Epoch: 768, Loss: 258.01985788345337,  L-Loss: 0.4366423632018268, C-Loss: 25.780153512954712\n",
      "Epoch: 769, Loss: 252.10206413269043,  L-Loss: 0.4221565183252096, C-Loss: 25.18909865617752\n",
      "Epoch: 770, Loss: 260.9632577896118,  L-Loss: 0.5096145286224782, C-Loss: 26.070845156908035\n",
      "Epoch: 771, Loss: 258.3180732727051,  L-Loss: 0.4225483611226082, C-Loss: 25.81067994236946\n",
      "Epoch: 772, Loss: 252.56043767929077,  L-Loss: 0.4503227365203202, C-Loss: 25.233527421951294\n",
      "Epoch: 773, Loss: 252.98539686203003,  L-Loss: 0.4320911490358412, C-Loss: 25.276935130357742\n",
      "Epoch: 774, Loss: 254.90077829360962,  L-Loss: 0.41394643671810627, C-Loss: 25.469380378723145\n",
      "Epoch: 775, Loss: 258.2547264099121,  L-Loss: 0.4282108061015606, C-Loss: 25.80406215786934\n",
      "Epoch: 776, Loss: 255.97299814224243,  L-Loss: 0.40308818966150284, C-Loss: 25.577145516872406\n",
      "Epoch: 777, Loss: 259.01756286621094,  L-Loss: 0.4448645329102874, C-Loss: 25.879512667655945\n",
      "Epoch: 778, Loss: 259.1098403930664,  L-Loss: 0.398272184189409, C-Loss: 25.89107048511505\n",
      "Epoch: 779, Loss: 263.148624420166,  L-Loss: 0.4197988137602806, C-Loss: 26.293872237205505\n",
      "Epoch: 780, Loss: 259.02325773239136,  L-Loss: 0.4029458239674568, C-Loss: 25.882178455591202\n",
      "Epoch: 781, Loss: 257.24409008026123,  L-Loss: 0.40203697979450226, C-Loss: 25.704307079315186\n",
      "Epoch: 782, Loss: 267.45815801620483,  L-Loss: 0.44361246982589364, C-Loss: 26.72363543510437\n",
      "Epoch: 783, Loss: 254.11938381195068,  L-Loss: 0.38394301384687424, C-Loss: 25.392741203308105\n",
      "Epoch: 784, Loss: 252.31997680664062,  L-Loss: 0.39764951122924685, C-Loss: 25.212114989757538\n",
      "Epoch: 785, Loss: 259.8651189804077,  L-Loss: 0.3890604358166456, C-Loss: 25.967058956623077\n",
      "Epoch: 786, Loss: 251.74931049346924,  L-Loss: 0.398666282184422, C-Loss: 25.15499758720398\n",
      "Epoch: 787, Loss: 254.96610975265503,  L-Loss: 0.3881917344406247, C-Loss: 25.477201461791992\n",
      "Epoch: 788, Loss: 255.13203287124634,  L-Loss: 0.39711369667202234, C-Loss: 25.493347465991974\n",
      "Epoch: 789, Loss: 255.00557041168213,  L-Loss: 0.39884919626638293, C-Loss: 25.480614483356476\n",
      "Epoch: 790, Loss: 254.04109477996826,  L-Loss: 0.380285554099828, C-Loss: 25.38509526848793\n",
      "Epoch: 791, Loss: 251.98338985443115,  L-Loss: 0.3859528205357492, C-Loss: 25.179041534662247\n",
      "Epoch: 792, Loss: 258.5129985809326,  L-Loss: 0.3856528834439814, C-Loss: 25.832017064094543\n",
      "Epoch: 793, Loss: 252.26132583618164,  L-Loss: 0.38317596446722746, C-Loss: 25.206973910331726\n",
      "Epoch: 794, Loss: 252.28414297103882,  L-Loss: 0.38447495037689805, C-Loss: 25.209190160036087\n",
      "Epoch: 795, Loss: 252.34891986846924,  L-Loss: 0.3859955295920372, C-Loss: 25.215592056512833\n",
      "Epoch: 796, Loss: 257.2748908996582,  L-Loss: 0.3836531648412347, C-Loss: 25.7083061337471\n",
      "Epoch: 797, Loss: 250.04572677612305,  L-Loss: 0.37321690330281854, C-Loss: 24.985911816358566\n",
      "Epoch: 798, Loss: 251.7354383468628,  L-Loss: 0.3735413239337504, C-Loss: 25.15486678481102\n",
      "Epoch: 799, Loss: 260.3825526237488,  L-Loss: 0.3878905260935426, C-Loss: 26.018860638141632\n",
      "Epoch: 800, Loss: 252.40468311309814,  L-Loss: 0.3759050387889147, C-Loss: 25.221673250198364\n",
      "Epoch: 801, Loss: 253.37288522720337,  L-Loss: 0.3769434690475464, C-Loss: 25.318441301584244\n",
      "Epoch: 802, Loss: 251.0756435394287,  L-Loss: 0.37473792396485806, C-Loss: 25.088827520608902\n",
      "Epoch: 803, Loss: 255.71143913269043,  L-Loss: 0.38578848959878087, C-Loss: 25.55185431241989\n",
      "Epoch: 804, Loss: 255.02981090545654,  L-Loss: 0.38421590346843004, C-Loss: 25.483770430088043\n",
      "Epoch: 805, Loss: 252.71443939208984,  L-Loss: 0.3861490678973496, C-Loss: 25.252136677503586\n",
      "Epoch: 806, Loss: 255.4464464187622,  L-Loss: 0.38957166485488415, C-Loss: 25.525166273117065\n",
      "Epoch: 807, Loss: 250.40874910354614,  L-Loss: 0.37717631831765175, C-Loss: 25.022016018629074\n",
      "Epoch: 808, Loss: 252.11703729629517,  L-Loss: 0.3974290322512388, C-Loss: 25.191832095384598\n",
      "Epoch: 809, Loss: 252.24146604537964,  L-Loss: 0.37868937430903316, C-Loss: 25.2052121758461\n",
      "Epoch: 810, Loss: 254.60977792739868,  L-Loss: 0.39046611450612545, C-Loss: 25.4414544403553\n",
      "Epoch: 811, Loss: 261.65945053100586,  L-Loss: 0.3937207511626184, C-Loss: 26.14625895023346\n",
      "Epoch: 812, Loss: 273.1657724380493,  L-Loss: 0.43205638928338885, C-Loss: 27.294974505901337\n",
      "Epoch: 813, Loss: 264.0440173149109,  L-Loss: 0.41654919227585196, C-Loss: 26.383574336767197\n",
      "Epoch: 814, Loss: 294.5519337654114,  L-Loss: 0.49678735062479973, C-Loss: 29.430354058742523\n",
      "Epoch: 815, Loss: 302.00578260421753,  L-Loss: 0.6029032240621746, C-Loss: 30.170433163642883\n",
      "Epoch: 816, Loss: 332.25077533721924,  L-Loss: 0.7977647092193365, C-Loss: 33.18518942594528\n",
      "Epoch: 817, Loss: 291.04710483551025,  L-Loss: 0.6155200153589249, C-Loss: 29.073934108018875\n",
      "Epoch: 818, Loss: 282.02401208877563,  L-Loss: 0.5956630408763885, C-Loss: 28.172618061304092\n",
      "Epoch: 819, Loss: 275.72347497940063,  L-Loss: 0.5100768292322755, C-Loss: 27.54684340953827\n",
      "Epoch: 820, Loss: 271.9054536819458,  L-Loss: 0.498703857883811, C-Loss: 27.165610194206238\n",
      "Epoch: 821, Loss: 267.6188735961914,  L-Loss: 0.4276263969950378, C-Loss: 26.740506172180176\n",
      "Epoch: 822, Loss: 272.05842113494873,  L-Loss: 0.4401771076954901, C-Loss: 27.183833122253418\n",
      "Epoch: 823, Loss: 267.7700734138489,  L-Loss: 0.3911668751388788, C-Loss: 26.757448762655258\n",
      "Epoch: 824, Loss: 264.08503818511963,  L-Loss: 0.3974106381647289, C-Loss: 26.38863319158554\n",
      "Epoch: 825, Loss: 262.29361152648926,  L-Loss: 0.37993051996454597, C-Loss: 26.210364907979965\n",
      "Epoch: 826, Loss: 260.3583507537842,  L-Loss: 0.3752012560144067, C-Loss: 26.017075031995773\n",
      "Epoch: 827, Loss: 254.85884284973145,  L-Loss: 0.3669629921205342, C-Loss: 25.46753618121147\n",
      "Epoch: 828, Loss: 255.16159772872925,  L-Loss: 0.3722845772281289, C-Loss: 25.497545421123505\n",
      "Epoch: 829, Loss: 256.05410051345825,  L-Loss: 0.3682290059514344, C-Loss: 25.586998730897903\n",
      "Epoch: 830, Loss: 257.9543867111206,  L-Loss: 0.3750095055438578, C-Loss: 25.776688367128372\n",
      "Epoch: 831, Loss: 259.5996298789978,  L-Loss: 0.3783195191062987, C-Loss: 25.94104701280594\n",
      "Epoch: 832, Loss: 258.7129096984863,  L-Loss: 0.39001815021038055, C-Loss: 25.851790189743042\n",
      "Epoch: 833, Loss: 256.1269702911377,  L-Loss: 0.37884599436074495, C-Loss: 25.59375461935997\n",
      "Epoch: 834, Loss: 261.4696521759033,  L-Loss: 0.38510685972869396, C-Loss: 26.1277095079422\n",
      "Epoch: 835, Loss: 258.32259941101074,  L-Loss: 0.3689220785163343, C-Loss: 25.813813984394073\n",
      "Epoch: 836, Loss: 258.07840061187744,  L-Loss: 0.3754415628500283, C-Loss: 25.78906786441803\n",
      "Epoch: 837, Loss: 257.8131151199341,  L-Loss: 0.3660999983549118, C-Loss: 25.763006448745728\n",
      "Epoch: 838, Loss: 257.2094006538391,  L-Loss: 0.3780160644091666, C-Loss: 25.702039271593094\n",
      "Epoch: 839, Loss: 261.73969745635986,  L-Loss: 0.3688900386914611, C-Loss: 26.155525267124176\n",
      "Epoch: 840, Loss: 257.6909909248352,  L-Loss: 0.37111314572393894, C-Loss: 25.75054332613945\n",
      "Epoch: 841, Loss: 257.7537798881531,  L-Loss: 0.36382782831788063, C-Loss: 25.757186591625214\n",
      "Epoch: 842, Loss: 258.18483114242554,  L-Loss: 0.3650177796371281, C-Loss: 25.800232350826263\n",
      "Epoch: 843, Loss: 258.2985610961914,  L-Loss: 0.366947403177619, C-Loss: 25.81150871515274\n",
      "Epoch: 844, Loss: 258.2014513015747,  L-Loss: 0.35975687485188246, C-Loss: 25.802157133817673\n",
      "Epoch: 845, Loss: 257.99167251586914,  L-Loss: 0.3648967333137989, C-Loss: 25.78092250227928\n",
      "Epoch: 846, Loss: 258.2225251197815,  L-Loss: 0.3589694993570447, C-Loss: 25.80430406332016\n",
      "Epoch: 847, Loss: 258.8399519920349,  L-Loss: 0.3656657193787396, C-Loss: 25.865711867809296\n",
      "Epoch: 848, Loss: 259.519202709198,  L-Loss: 0.359231723472476, C-Loss: 25.933958768844604\n",
      "Epoch: 849, Loss: 258.97523069381714,  L-Loss: 0.36566451424732804, C-Loss: 25.879239559173584\n",
      "Epoch: 850, Loss: 258.223256111145,  L-Loss: 0.35820342181250453, C-Loss: 25.8044154047966\n",
      "Epoch: 851, Loss: 257.3812732696533,  L-Loss: 0.3657539812847972, C-Loss: 25.71983978152275\n",
      "Epoch: 852, Loss: 257.7039361000061,  L-Loss: 0.36104414938017726, C-Loss: 25.752341210842133\n",
      "Epoch: 853, Loss: 256.8005256652832,  L-Loss: 0.37026680959388614, C-Loss: 25.661539018154144\n",
      "Epoch: 854, Loss: 258.1170325279236,  L-Loss: 0.3638121332041919, C-Loss: 25.793512642383575\n",
      "Epoch: 855, Loss: 256.90729236602783,  L-Loss: 0.37366100307554007, C-Loss: 25.67204639315605\n",
      "Epoch: 856, Loss: 258.013605594635,  L-Loss: 0.36172695038840175, C-Loss: 25.78327441215515\n",
      "Epoch: 857, Loss: 256.9808211326599,  L-Loss: 0.37230200273916125, C-Loss: 25.67946696281433\n",
      "Epoch: 858, Loss: 258.49600172042847,  L-Loss: 0.3593738148920238, C-Loss: 25.83163145184517\n",
      "Epoch: 859, Loss: 258.77006673812866,  L-Loss: 0.3727874532341957, C-Loss: 25.858367443084717\n",
      "Epoch: 860, Loss: 258.79718923568726,  L-Loss: 0.3566673160530627, C-Loss: 25.861885517835617\n",
      "Epoch: 861, Loss: 259.1356768608093,  L-Loss: 0.3698090836405754, C-Loss: 25.895077288150787\n",
      "Epoch: 862, Loss: 259.54339933395386,  L-Loss: 0.3576693986542523, C-Loss: 25.936456263065338\n",
      "Epoch: 863, Loss: 258.22620487213135,  L-Loss: 0.36449249321594834, C-Loss: 25.804395586252213\n",
      "Epoch: 864, Loss: 259.092529296875,  L-Loss: 0.35740583576261997, C-Loss: 25.89138239622116\n",
      "Epoch: 865, Loss: 259.4862766265869,  L-Loss: 0.36075037624686956, C-Loss: 25.93059015274048\n",
      "Epoch: 866, Loss: 259.997013092041,  L-Loss: 0.3596589514054358, C-Loss: 25.98171791434288\n",
      "Epoch: 867, Loss: 256.2447600364685,  L-Loss: 0.35484360391274095, C-Loss: 25.606733739376068\n",
      "Epoch: 868, Loss: 258.40852308273315,  L-Loss: 0.35772514436393976, C-Loss: 25.822965919971466\n",
      "Epoch: 869, Loss: 263.57616901397705,  L-Loss: 0.3636377123184502, C-Loss: 26.339435160160065\n",
      "Epoch: 870, Loss: 260.16746377944946,  L-Loss: 0.3627944691106677, C-Loss: 25.99860644340515\n",
      "Epoch: 871, Loss: 260.8554825782776,  L-Loss: 0.36633511632680893, C-Loss: 26.067231476306915\n",
      "Epoch: 872, Loss: 258.06296014785767,  L-Loss: 0.36455770768225193, C-Loss: 25.788068413734436\n",
      "Epoch: 873, Loss: 261.2911901473999,  L-Loss: 0.35791170317679644, C-Loss: 26.111223608255386\n",
      "Epoch: 874, Loss: 259.42034816741943,  L-Loss: 0.3549732700921595, C-Loss: 25.924285978078842\n",
      "Epoch: 875, Loss: 258.1549644470215,  L-Loss: 0.36195884132757783, C-Loss: 25.797398567199707\n",
      "Epoch: 876, Loss: 262.16476488113403,  L-Loss: 0.35447560949251056, C-Loss: 26.198752641677856\n",
      "Epoch: 877, Loss: 258.23643684387207,  L-Loss: 0.3633172237314284, C-Loss: 25.805477678775787\n",
      "Epoch: 878, Loss: 260.45686197280884,  L-Loss: 0.35118725849315524, C-Loss: 26.028126806020737\n",
      "Epoch: 879, Loss: 258.57377099990845,  L-Loss: 0.3557053171098232, C-Loss: 25.839591920375824\n",
      "Epoch: 880, Loss: 257.34113788604736,  L-Loss: 0.35835333447903395, C-Loss: 25.71619626879692\n",
      "Epoch: 881, Loss: 258.6761956214905,  L-Loss: 0.3545855241827667, C-Loss: 25.849890112876892\n",
      "Epoch: 882, Loss: 257.9728932380676,  L-Loss: 0.364721457939595, C-Loss: 25.779053330421448\n",
      "Epoch: 883, Loss: 256.27270889282227,  L-Loss: 0.35971896164119244, C-Loss: 25.609284818172455\n",
      "Epoch: 884, Loss: 260.7966456413269,  L-Loss: 0.3584892665967345, C-Loss: 26.061739951372147\n",
      "Epoch: 885, Loss: 256.1156759262085,  L-Loss: 0.3724376978352666, C-Loss: 25.592945724725723\n",
      "Epoch: 886, Loss: 260.86664390563965,  L-Loss: 0.3580713509581983, C-Loss: 26.068760812282562\n",
      "Epoch: 887, Loss: 255.76744556427002,  L-Loss: 0.3574187788181007, C-Loss: 25.558873891830444\n",
      "Epoch: 888, Loss: 256.7615761756897,  L-Loss: 0.3620536392554641, C-Loss: 25.658054888248444\n",
      "Epoch: 889, Loss: 261.31234407424927,  L-Loss: 0.36193519085645676, C-Loss: 26.113137513399124\n",
      "Epoch: 890, Loss: 257.4115343093872,  L-Loss: 0.3751086029224098, C-Loss: 25.722398042678833\n",
      "Epoch: 891, Loss: 262.157874584198,  L-Loss: 0.36227327678352594, C-Loss: 26.19767391681671\n",
      "Epoch: 892, Loss: 262.50881910324097,  L-Loss: 0.3632140448316932, C-Loss: 26.23272117972374\n",
      "Epoch: 893, Loss: 258.07175731658936,  L-Loss: 0.37395233754068613, C-Loss: 25.78847774863243\n",
      "Epoch: 894, Loss: 261.3050284385681,  L-Loss: 0.3584092725068331, C-Loss: 26.11258238554001\n",
      "Epoch: 895, Loss: 256.5307230949402,  L-Loss: 0.3662273455411196, C-Loss: 25.634760975837708\n",
      "Epoch: 896, Loss: 259.12969303131104,  L-Loss: 0.36478866124525666, C-Loss: 25.894729614257812\n",
      "Epoch: 897, Loss: 261.0355668067932,  L-Loss: 0.39288442535325885, C-Loss: 26.08391273021698\n",
      "Epoch: 898, Loss: 259.79780530929565,  L-Loss: 0.3929041037335992, C-Loss: 25.96013504266739\n",
      "Epoch: 899, Loss: 260.7912817001343,  L-Loss: 0.37410872895270586, C-Loss: 26.060422956943512\n",
      "Epoch: 900, Loss: 263.7652816772461,  L-Loss: 0.4110195222310722, C-Loss: 26.355977296829224\n",
      "Epoch: 901, Loss: 267.1645231246948,  L-Loss: 0.41812099423259497, C-Loss: 26.695546478033066\n",
      "Epoch: 902, Loss: 270.70558881759644,  L-Loss: 0.4015324981883168, C-Loss: 27.050482094287872\n",
      "Epoch: 903, Loss: 278.5495834350586,  L-Loss: 0.3992681601084769, C-Loss: 27.83499476313591\n",
      "Epoch: 904, Loss: 286.15561532974243,  L-Loss: 0.4252471807412803, C-Loss: 28.59429892897606\n",
      "Epoch: 905, Loss: 272.1759738922119,  L-Loss: 0.35530067374929786, C-Loss: 27.199832290410995\n",
      "Epoch: 906, Loss: 277.59830808639526,  L-Loss: 0.36320593720301986, C-Loss: 27.74167025089264\n",
      "Epoch: 907, Loss: 255.7830934524536,  L-Loss: 0.3181463237851858, C-Loss: 25.56240212917328\n",
      "Epoch: 908, Loss: 265.0122261047363,  L-Loss: 0.3638067585416138, C-Loss: 26.483032017946243\n",
      "Epoch: 909, Loss: 256.6264433860779,  L-Loss: 0.3403468825854361, C-Loss: 25.645627111196518\n",
      "Epoch: 910, Loss: 261.6726121902466,  L-Loss: 0.3477046429179609, C-Loss: 26.14987587928772\n",
      "Epoch: 911, Loss: 260.9594564437866,  L-Loss: 0.3230940871872008, C-Loss: 26.079791128635406\n",
      "Epoch: 912, Loss: 259.61491298675537,  L-Loss: 0.32267109444364905, C-Loss: 25.945357590913773\n",
      "Epoch: 913, Loss: 259.2049560546875,  L-Loss: 0.32987804245203733, C-Loss: 25.904001653194427\n",
      "Epoch: 914, Loss: 256.51318073272705,  L-Loss: 0.31973696779459715, C-Loss: 25.63533118367195\n",
      "Epoch: 915, Loss: 257.8634066581726,  L-Loss: 0.32613864075392485, C-Loss: 25.770033687353134\n",
      "Epoch: 916, Loss: 254.38764810562134,  L-Loss: 0.3161436766386032, C-Loss: 25.422957569360733\n",
      "Epoch: 917, Loss: 254.73390579223633,  L-Loss: 0.3195374463684857, C-Loss: 25.457413613796234\n",
      "Epoch: 918, Loss: 256.67080783843994,  L-Loss: 0.3172426577657461, C-Loss: 25.651218503713608\n",
      "Epoch: 919, Loss: 256.3720107078552,  L-Loss: 0.3234715275466442, C-Loss: 25.621027499437332\n",
      "Epoch: 920, Loss: 254.14784908294678,  L-Loss: 0.3154968749731779, C-Loss: 25.39901003241539\n",
      "Epoch: 921, Loss: 255.60785055160522,  L-Loss: 0.32457315223291516, C-Loss: 25.544556200504303\n",
      "Epoch: 922, Loss: 256.4558081626892,  L-Loss: 0.3205590886063874, C-Loss: 25.629552900791168\n",
      "Epoch: 923, Loss: 254.34453630447388,  L-Loss: 0.31916689267382026, C-Loss: 25.418495267629623\n",
      "Epoch: 924, Loss: 258.1186022758484,  L-Loss: 0.33105336781591177, C-Loss: 25.795307904481888\n",
      "Epoch: 925, Loss: 257.24548721313477,  L-Loss: 0.32314967503771186, C-Loss: 25.708391189575195\n",
      "Epoch: 926, Loss: 255.0509557723999,  L-Loss: 0.32819768553599715, C-Loss: 25.488685756921768\n",
      "Epoch: 927, Loss: 256.96626901626587,  L-Loss: 0.32769530825316906, C-Loss: 25.680242091417313\n",
      "Epoch: 928, Loss: 258.1039514541626,  L-Loss: 0.33357040118426085, C-Loss: 25.793716371059418\n",
      "Epoch: 929, Loss: 257.3960762023926,  L-Loss: 0.3254267112351954, C-Loss: 25.723336160182953\n",
      "Epoch: 930, Loss: 256.45771741867065,  L-Loss: 0.32575379591435194, C-Loss: 25.629484087228775\n",
      "Epoch: 931, Loss: 257.63374042510986,  L-Loss: 0.32455965178087354, C-Loss: 25.747146129608154\n",
      "Epoch: 932, Loss: 255.31174182891846,  L-Loss: 0.3337494721636176, C-Loss: 25.514486759901047\n",
      "Epoch: 933, Loss: 258.3144907951355,  L-Loss: 0.3229884351603687, C-Loss: 25.81529998779297\n",
      "Epoch: 934, Loss: 254.18079376220703,  L-Loss: 0.32834788830950856, C-Loss: 25.40166202187538\n",
      "Epoch: 935, Loss: 257.61484813690186,  L-Loss: 0.32604506239295006, C-Loss: 25.74518260359764\n",
      "Epoch: 936, Loss: 257.3200001716614,  L-Loss: 0.3248151345178485, C-Loss: 25.715759247541428\n",
      "Epoch: 937, Loss: 256.2865056991577,  L-Loss: 0.32993633672595024, C-Loss: 25.612153708934784\n",
      "Epoch: 938, Loss: 258.72180461883545,  L-Loss: 0.32638063887134194, C-Loss: 25.855861455202103\n",
      "Epoch: 939, Loss: 256.15694856643677,  L-Loss: 0.3265795926563442, C-Loss: 25.599366009235382\n",
      "Epoch: 940, Loss: 257.0986976623535,  L-Loss: 0.32952642627060413, C-Loss: 25.693393170833588\n",
      "Epoch: 941, Loss: 258.6410484313965,  L-Loss: 0.32625420670956373, C-Loss: 25.84779191017151\n",
      "Epoch: 942, Loss: 258.38964557647705,  L-Loss: 0.3275643941015005, C-Loss: 25.82258626818657\n",
      "Epoch: 943, Loss: 256.90893173217773,  L-Loss: 0.3319381237961352, C-Loss: 25.674296259880066\n",
      "Epoch: 944, Loss: 257.2518072128296,  L-Loss: 0.3188574225641787, C-Loss: 25.70923787355423\n",
      "Epoch: 945, Loss: 260.4881896972656,  L-Loss: 0.33686354709789157, C-Loss: 26.03197556734085\n",
      "Epoch: 946, Loss: 258.7588014602661,  L-Loss: 0.33165436144918203, C-Loss: 25.859297782182693\n",
      "Epoch: 947, Loss: 260.3465852737427,  L-Loss: 0.35619369987398386, C-Loss: 26.016848981380463\n",
      "Epoch: 948, Loss: 264.9541883468628,  L-Loss: 0.3538509728386998, C-Loss: 26.477726340293884\n",
      "Epoch: 949, Loss: 264.7347083091736,  L-Loss: 0.3735623122192919, C-Loss: 26.45479279756546\n",
      "Epoch: 950, Loss: 272.3485951423645,  L-Loss: 0.351531183347106, C-Loss: 27.2172828912735\n",
      "Epoch: 951, Loss: 260.6571159362793,  L-Loss: 0.3492000577971339, C-Loss: 26.0482517182827\n",
      "Epoch: 952, Loss: 259.3328433036804,  L-Loss: 0.31817149790003896, C-Loss: 25.917375683784485\n",
      "Epoch: 953, Loss: 256.9067792892456,  L-Loss: 0.32797139417380095, C-Loss: 25.674279391765594\n",
      "Epoch: 954, Loss: 254.43402433395386,  L-Loss: 0.311692216899246, C-Loss: 25.427817791700363\n",
      "Epoch: 955, Loss: 260.6152205467224,  L-Loss: 0.33237912878394127, C-Loss: 26.04490301012993\n",
      "Epoch: 956, Loss: 253.15144205093384,  L-Loss: 0.3189310603775084, C-Loss: 25.299197643995285\n",
      "Epoch: 957, Loss: 259.3075771331787,  L-Loss: 0.33113598357886076, C-Loss: 25.914200961589813\n",
      "Epoch: 958, Loss: 258.20803785324097,  L-Loss: 0.320347064640373, C-Loss: 25.80478659272194\n",
      "Epoch: 959, Loss: 257.7903618812561,  L-Loss: 0.3329032389447093, C-Loss: 25.76239103078842\n",
      "Epoch: 960, Loss: 258.1440076828003,  L-Loss: 0.3172363596968353, C-Loss: 25.79853904247284\n",
      "Epoch: 961, Loss: 257.25634479522705,  L-Loss: 0.3267831401899457, C-Loss: 25.709295451641083\n",
      "Epoch: 962, Loss: 256.71255016326904,  L-Loss: 0.31139663280919194, C-Loss: 25.655685275793076\n",
      "Epoch: 963, Loss: 257.27850818634033,  L-Loss: 0.3272258583456278, C-Loss: 25.711489409208298\n",
      "Epoch: 964, Loss: 255.74383401870728,  L-Loss: 0.3264442984946072, C-Loss: 25.558061182498932\n",
      "Epoch: 965, Loss: 255.4145245552063,  L-Loss: 0.3431108961813152, C-Loss: 25.52429696917534\n",
      "Epoch: 966, Loss: 257.6749596595764,  L-Loss: 0.3293317318893969, C-Loss: 25.75102949142456\n",
      "Epoch: 967, Loss: 257.4566559791565,  L-Loss: 0.34006831562146544, C-Loss: 25.728661954402924\n",
      "Epoch: 968, Loss: 261.37144708633423,  L-Loss: 0.3466516216285527, C-Loss: 26.119812190532684\n",
      "Epoch: 969, Loss: 264.65595149993896,  L-Loss: 0.35095132840797305, C-Loss: 26.448047548532486\n",
      "Epoch: 970, Loss: 262.1807565689087,  L-Loss: 0.3398486655205488, C-Loss: 26.201083064079285\n",
      "Epoch: 971, Loss: 262.65657234191895,  L-Loss: 0.3566554831340909, C-Loss: 26.247824639081955\n",
      "Epoch: 972, Loss: 261.0367474555969,  L-Loss: 0.33548813592642546, C-Loss: 26.08690059185028\n",
      "Epoch: 973, Loss: 262.9402689933777,  L-Loss: 0.35449997102841735, C-Loss: 26.27630180120468\n",
      "Epoch: 974, Loss: 259.9394187927246,  L-Loss: 0.32852850714698434, C-Loss: 25.97751548886299\n",
      "Epoch: 975, Loss: 256.43533420562744,  L-Loss: 0.34454196598380804, C-Loss: 25.626306504011154\n",
      "Epoch: 976, Loss: 260.14866876602173,  L-Loss: 0.34752522502094507, C-Loss: 25.997490882873535\n",
      "Epoch: 977, Loss: 254.22804927825928,  L-Loss: 0.33806841913610697, C-Loss: 25.405901551246643\n",
      "Epoch: 978, Loss: 259.1804895401001,  L-Loss: 0.3603642168454826, C-Loss: 25.900030612945557\n",
      "Epoch: 979, Loss: 262.77165603637695,  L-Loss: 0.3255221596919, C-Loss: 26.260889530181885\n",
      "Epoch: 980, Loss: 261.39030838012695,  L-Loss: 0.3346877242438495, C-Loss: 26.122296571731567\n",
      "Epoch: 981, Loss: 258.7712593078613,  L-Loss: 0.32830147352069616, C-Loss: 25.860711097717285\n",
      "Epoch: 982, Loss: 258.19338274002075,  L-Loss: 0.3185574859380722, C-Loss: 25.803410410881042\n",
      "Epoch: 983, Loss: 260.142240524292,  L-Loss: 0.32361883064731956, C-Loss: 25.99804323911667\n",
      "Epoch: 984, Loss: 261.69902658462524,  L-Loss: 0.3193512153811753, C-Loss: 26.153935074806213\n",
      "Epoch: 985, Loss: 263.8123617172241,  L-Loss: 0.32419461384415627, C-Loss: 26.365026384592056\n",
      "Epoch: 986, Loss: 263.89831495285034,  L-Loss: 0.32396520348265767, C-Loss: 26.37363302707672\n",
      "Epoch: 987, Loss: 262.2437882423401,  L-Loss: 0.3225298523902893, C-Loss: 26.20825219154358\n",
      "Epoch: 988, Loss: 259.5508408546448,  L-Loss: 0.33337291795760393, C-Loss: 25.938415378332138\n",
      "Epoch: 989, Loss: 259.21317195892334,  L-Loss: 0.318170553073287, C-Loss: 25.90540862083435\n",
      "Epoch: 990, Loss: 255.99551725387573,  L-Loss: 0.3201378248631954, C-Loss: 25.58354488015175\n",
      "Epoch: 991, Loss: 256.5194215774536,  L-Loss: 0.3067612871527672, C-Loss: 25.63660377264023\n",
      "Epoch: 992, Loss: 254.9051628112793,  L-Loss: 0.31630868557840586, C-Loss: 25.474700897932053\n",
      "Epoch: 993, Loss: 255.26363229751587,  L-Loss: 0.302297864574939, C-Loss: 25.511248230934143\n",
      "Epoch: 994, Loss: 253.90153074264526,  L-Loss: 0.3017414375208318, C-Loss: 25.3750661611557\n",
      "Epoch: 995, Loss: 258.1467008590698,  L-Loss: 0.3027099436149001, C-Loss: 25.799534618854523\n",
      "Epoch: 996, Loss: 257.16000843048096,  L-Loss: 0.3090274091809988, C-Loss: 25.700549364089966\n",
      "Epoch: 997, Loss: 260.8853602409363,  L-Loss: 0.3039690963923931, C-Loss: 26.07333755493164\n",
      "Epoch: 998, Loss: 262.72655296325684,  L-Loss: 0.3156834039837122, C-Loss: 26.256871342658997\n",
      "Epoch: 999, Loss: 256.70009756088257,  L-Loss: 0.30638394178822637, C-Loss: 25.65469056367874\n",
      "Epoch: 1000, Loss: 254.01190757751465,  L-Loss: 0.31119002448394895, C-Loss: 25.385631203651428\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training!\")\n",
    "for epoch in range(num_epochs+1): \n",
    "    # Training.\n",
    "    net.train()\n",
    "    loss_tracker = 0.0\n",
    "    latent_loss_tracker = 0.0\n",
    "    cor_loss_tracker = 0.0\n",
    "    for x, y in train_dataloader:\n",
    "        optimizer.zero_grad()      \n",
    "\n",
    "        # Pass x, y to network. Retrieve both encodings, and decoding of ys encoding.\n",
    "        fx_x, fe_y, fd_z = net(x, y)\n",
    "        # Calc loss.\n",
    "        l_loss, c_loss = net.losses(fx_x, fe_y, fd_z, y)\n",
    "        # Normalize losses by batch.\n",
    "        l_loss /= x.shape[0]\n",
    "        c_loss /= x.shape[0]\n",
    "        loss = net.beta*l_loss + net.alpha*c_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_tracker+=loss.item()\n",
    "        latent_loss_tracker+=l_loss.item()\n",
    "        cor_loss_tracker+=c_loss.item()\n",
    "    writer.add_scalar('train/loss', loss_tracker, epoch)\n",
    "    writer.add_scalar('train/latent_loss', latent_loss_tracker, epoch)\n",
    "    writer.add_scalar('train/corr_loss', cor_loss_tracker, epoch)\n",
    "    \n",
    "    # Evaluation\n",
    "    net.eval()\n",
    "    loss_tracker = 0.0\n",
    "    latent_loss_tracker = 0.0\n",
    "    cor_loss_tracker = 0.0\n",
    "    acc_track = 0.0\n",
    "    for x, y in test_dataloader:\n",
    "        # evaluation only requires x. As its just Fd(Fx(x))\n",
    "        fx_x, fe_y = net.Fx(x), net.Fe(y)\n",
    "        fd_z = net.Fd(fx_x)\n",
    "\n",
    "        l_loss, c_loss = net.losses(fx_x, fe_y, fd_z, y)\n",
    "        # Normalize losses by batch.\n",
    "        l_loss /= x.shape[0]\n",
    "        c_loss /= x.shape[0]\n",
    "        loss = net.beta*l_loss + net.alpha*c_loss\n",
    "        \n",
    "        latent_loss_tracker += l_loss.item()\n",
    "        cor_loss_tracker += c_loss.item()\n",
    "        loss_tracker += loss.item()\n",
    "        lab_preds = torch.round(net.Fd(net.Fx(x))).cpu().detach().numpy()\n",
    "        \n",
    "    print(f\"Epoch: {epoch}, Loss: {loss_tracker},  L-Loss: {latent_loss_tracker}, C-Loss: {cor_loss_tracker}\")\n",
    "    torch.save(net.state_dict(), f'./models/scene/scene_c2ae/v3_{epoch}.pt')\n",
    "    writer.add_scalar('val/loss', loss_tracker, epoch)\n",
    "    writer.add_scalar('val/latent_loss', latent_loss_tracker, epoch)\n",
    "    writer.add_scalar('val/corr_loss', cor_loss_tracker, epoch)\n",
    "    \n",
    "    # Log metrics on whole dataset.\n",
    "    mets = eval_metrics(net, [ham_los, accuracy_score, micro_f1, micro_p, micro_r, macro_f1, macro_p, macro_r], \n",
    "                        [test_dataset, train_dataset], torch.device('cuda'))\n",
    "    for k, v in mets['dataset_1'].items():\n",
    "        writer.add_scalar(f'train/{k}', v, epoch)\n",
    "    for k, v in mets['dataset_0'].items():\n",
    "        writer.add_scalar(f'val/{k}', v, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picking best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_net = load_model(C2AE, './models/scene/scene_c2ae/v3_299.pt', Fx=Fx_scene, Fe=Fe_scene, Fd=Fd_scene, device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_0': {'ham_los': 0.10089186176142698,\n",
       "  'accuracy_score': 0.612876254180602,\n",
       "  'micro_f1': 0.6978297161936561,\n",
       "  'micro_p': 0.7620783956244302,\n",
       "  'micro_r': 0.6435719784449576,\n",
       "  'macro_f1': 0.7001454295863437,\n",
       "  'macro_p': 0.7675026918519365,\n",
       "  'macro_r': 0.6530980687586226},\n",
       " 'dataset_1': {'ham_los': 0.05560143132397467,\n",
       "  'accuracy_score': 0.7663088356729976,\n",
       "  'micro_f1': 0.8319467554076538,\n",
       "  'micro_p': 0.8944543828264758,\n",
       "  'micro_r': 0.7776049766718507,\n",
       "  'macro_f1': 0.8430357000544705,\n",
       "  'macro_p': 0.9024568196453421,\n",
       "  'macro_r': 0.8004112815170829}}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mets = eval_metrics(net, [ham_los, accuracy_score, micro_f1, micro_p, micro_r, macro_f1, macro_p, macro_r], [test_dataset, train_dataset], device)\n",
    "mets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
